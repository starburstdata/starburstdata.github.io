<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>Starburst | First dbt-trino data pipeline</title>
    <meta name="viewport" content="width=device-width">
    <meta property="og:type" content="website">
    <meta property="og:title" content="Starburst - First dbt-trino data pipeline">
    <meta property="og:description" content="Your hub to all knowledge about Starburst products.">
    <meta property="og:image" content="/assets/img/starburst-og-image.png">

    <link rel="stylesheet" href="/assets/fontawesome/css/all.css">
    <link rel="stylesheet" href="/assets/css/bootstrap.min.css">
    <link rel="stylesheet" href="/assets/css/mdb.min.css">
    <link rel="stylesheet" href="/assets/css/highlight.css">
    <link rel="stylesheet" href="/assets/css/fonts.css">
    <link rel="stylesheet" href="/assets/css/style.css">
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-114610397-1"></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-114610397-1');
</script>

<script>
  var ALGOLIA_INSIGHTS_SRC = "https://cdn.jsdelivr.net/npm/search-insights@2.2.1";

  !function(e,a,t,n,s,i,c){e.AlgoliaAnalyticsObject=s,e[s]=e[s]||function(){
  (e[s].queue=e[s].queue||[]).push(arguments)},i=a.createElement(t),c=a.getElementsByTagName(t)[0],
  i.async=1,i.src=n,c.parentNode.insertBefore(i,c)
  }(window,document,"script",ALGOLIA_INSIGHTS_SRC,"aa");
</script>
<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>First dbt-trino data pipeline | Starburst</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="First dbt-trino data pipeline" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="This is part two of the lakehouse ETL with dbt and Trino series. Start at the introduction if you haven’t already. Now that you have set up all the required infrastructure, go through all the steps needed to install dbt and start building data pipelines. Intro to dbt-trino The dbt-trino adapter uses Trino as an underlying query engine to perform query federation across disperse data sources. Trino connects to multiple and diverse data sources (available connectors) via one dbt connection, and processes SQL queries. Transformations defined in dbt are passed to Trino, which handles these SQL transformation queries, and translates them to read data, create tables or views, and manipulate data in the connected data sources. Installing dbt and bootstrapping your project dbt can be installed through executing pip install dbt-trino. You need to have Python 3.7+ installed. After installing, you can run dbt --version to verify the dbt installation. It should result in something like the following: Core: - installed: 1.3.0 - latest: 1.3.0 - Up to date! Plugins: - trino: 1.3.1 - Up to date! Now, bootstrap the dbt project by executing dbt init. If you’ve just cloned or downloaded an existing dbt project, like in the case of a blog, dbt init can still help you set up your connection profile so that you can start working quickly. It prompts you for connection information, and to add a profile (using the profile name from the project) to your local profiles.yml, or create the file if it doesn’t already exist. More about configuring profiles is available from the official dbt documentation. Take, for example, the following configuration where you persist your flows into the datalake catalog (or database) and analytics schema on the Trino server running on port 8080 using the user admin. Note that in this development setup you are not using any authentication mechanism, so method is set to none. With the threads configuration, you define how many simultaneous queries to run, in other words, how fast you want your project to refresh. my_dbt_trino_project: target: dev outputs: dev: type: trino method: none user: admin database: datalake host: localhost port: 8080 schema: analytics threads: 1 All profiles.yml configuration options specific to dbt-trino can be found on the dbt-trino GitHub repository. Your first model The core construct of dbt is a model. A model is a SQL file within your project in the models folder that contains a SELECT query. The results of this select query materializes in your database as a VIEW or TABLE. For example, you can select all customers from your webshop database by creating a src_customers.sql file in your models. SELECT * FROM webshop.public.customers Now, when executing dbt run, dbt persists a table onto the datalake.analytics schema called src_customers. Running dbt run again replaces the existing view with a potential new definition if you change the query. Run this query in your favorite database client to validate the results of your model. SELECT * FROM datalake.analytics.src_customers; Adding your data sources As you can see above, you are sourcing directly from the operational PostgreSQL database. However, directly referencing to a database table in your models is a bad practice. To fix that, you need to define a dbt source. Sources define all external objects your project needs to get things done. Add a new sources.yml file in your models folder with the following content: version: 2 sources: - name: webshop database: webshop schema: public tables: - name: customers In the src_customers.sql, you can now refer to this source instead of the hard-coded location created earlier. That saves us from having to change all these locations everywhere when they change or you want to fetch them from a test database instead of the production database. Adding the prefix src helps to quickly identify which models are built straight from sources. SELECT * FROM {{ source(&#39;webshop&#39;, &#39;customers&#39;) }} Note the double curly braces {{ … }}, which indicate that the code fragment in between is evaluated by dbt before sending the query to your Trino instance. The source macro, or function, takes the database and schema from the first argument called source_name, and the name of the object from the second argument called table_name. The end result, which is the compiled query, is the same as the query above without the source macro. Adding EL to the T of dbt Traditionally, dbt is used for database transformations only, hence the name data transformation tool. It leaves the extract and load to other tools, for example Airbyte or Fivetran. Now, with the data federation capabilities of Trino, EL (extract and load) is added to the T (Transform) capabilities of dbt. Any data can be added as if it was located within the same database, as long as there is a Trino connector for it. Think about having any relational or NoSQL databases, message queues, or API’s immediately available without having to perform an expensive and complicated extract and load process. You have already loaded a table directly from our PostgreSQL database into the datalake without any additional tools required. Now, add another source–the clickstream data. For example, what if you want to know how many times a customer has visited our website before making a buy decision. Our clickstream data is readily available under the website catalog. First, you add a new source website to the sources.yml file: version: 2 sources: - name: webshop ... - name: website database: website schema: clickstream tables: - name: clicks Create a model file src_clicks.sql under the models folder: with source as ( SELECT * FROM {{ source(&#39;website&#39;, &#39;clicks&#39;) }} ), renamed as ( SELECT visitorid, useragent, language, event, cast(from_iso8601_timestamp(eventtime) AS timestamp(6) with time zone) AS eventtime, page, referrer FROM source ) SELECT * FROM renamed Execute dbt run again to materialize a newly created view. dbt implicitly builds your DAG A crucial concept in data pipelines is a DAG (Direct Acrylic Graph). A DAG defines all the steps the data pipeline has to perform from source to target. Each step of a DAG performs its job when all its parents have finished and triggers the start of its direct children (the dependents). Most tools, like Apache Airflow, take a very explicit approach on constructing DAGs. dbt, however, constructs the DAG implicitly. Every step of the DAG is a simple SQL file (called a model in dbt). You can refer to other models using the ref macro, for example {{ ref(‘src_customers’)}}. Let’s say, for example, you want to know how many times each customer visits the website before making a buying decision. For that, you need to join your webshop data with the clickstream data. However, clickstream data tends to be big and not so easy to analyze. For example, the user might have researched products before actually registering or logging into the webshop. To solve this, you want to introduce the concept of sessionization, and try to associate these sessions with an actual user. Each visitor of the website gets a unique identifier that is stored in a long-lasting cookie. You also have a sessions table in the webshop where you can link this unique identifier to an actual user in your webshop. With this data, you can also identify the clicks performed prior to logging into the webshop. Below, you can see the lineage DAG of models generated by dbt. × First you need to add the sessions table to our sources: version: 2 sources: - name: webshop database: webshop schema: public tables: - name: customers - name: sessions Again, you add a simple model called src_sessions.sql that is just performing a select on our source: with source as ( SELECT * FROM {{ source(&#39;webshop&#39;, &#39;sessions&#39;) }} ), renamed as ( SELECT cookie_id, cast(from_unixtime(started_ts/1000) AS timestamp(6)) AS session_started, customer_id FROM source ) SELECT * FROM renamed Now, build this by creating a new model sessionized_clicks.sql. First identify some rules about our sessionization: A session is a sequence of clicks, in which no two consecutive clicks are more than one hour apart. Once a user logs in, you associate also past sessions with the user. Trino supports numerous SQL functions and advanced operators that can be used in dbt models. The query used in the following model uses some of Trino’s more sophisticated features. Although complicated, they are necessary and useful in the hands of a data engineer. One such feature, used to implement sessions, is WINDOW operations. The WINDOW clause allows you to look from the current record to the group of records it belongs to. Some of the use cases are to detect the first or last record, or the maximum or minimum (any aggregation) within that group. It is different from a GROUP BY in the sense that it doesn’t group or reduce the number of records. The model is also making use of macro (more on that in a section below) called star. It generates a comma-separated list of all fields that exist in the from relation, excluding any fields listed in the except argument. The construction is identical to SELECT * FROM {{ref(‘my_model’)}}, replacing star (*) with the star macro: WITH sessions AS ( SELECT date_diff(&#39;hour&#39;, lag(c.eventtime) OVER w, c.eventtime) &gt; 1 AS new_session, {{ dbt_utils.star(ref(&quot;src_clicks&quot;), &quot;c&quot;) }}, {{ dbt_utils.star(ref(&quot;customer_sessions&quot;), &quot;s&quot;, [&quot;session_started&quot;, &quot;session_ended&quot;]) }}, first_value(c.referrer) ignore nulls OVER (PARTITION BY s.customer_id ORDER BY c.eventtime ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS channel, row_number() OVER w AS clickid, min(eventtime) OVER w AS session_started, max(eventtime) OVER w AS session_ended FROM {{ ref(&quot;src_clicks&quot;) }} c JOIN {{ ref(&quot;customer_sessions&quot;) }} s ON c.visitorid = s.cookie_id AND c.eventtime BETWEEN s.session_started AND s.session_ended WINDOW w AS ( PARTITION BY c.visitorid ORDER BY c.eventtime ) ), sequenced_sessions AS ( SELECT {{ dbt_utils.star(ref(&quot;src_clicks&quot;)) }}, sum(if(new_session, 1, 0)) OVER w AS session_sequence, clickid, customer_id, session_started, session_ended, channel FROM sessions WINDOW w AS ( PARTITION BY visitorid ORDER BY eventtime ) ) SELECT visitorid || &#39;_&#39; || cast(session_sequence as varchar) || &#39;_&#39; || cast(clickid as varchar) AS clickid, visitorid || &#39;_&#39; || cast(session_sequence as varchar) AS sessionid, customer_id, session_started, session_ended, channel, {{ dbt_utils.star(ref(&quot;src_clicks&quot;)) }} FROM sequenced_sessions Materializations (view, table, ephemeral) To manage the performance of your data pipeline, you should wisely choose which models should be materialized as a view, which ones as a table, or just reused within an existing SQL statement. As a general guideline, it is wise to make tables of all the data exposed to actual users, for example dashboards. Here the sessionization is using a window and adding a session_id to each click. You don’t want this expensive operation to be performed every time you use the sessionized_clicks object. So it should be persisted as a table instead of a view. Just adapt the sessionized_clicks.sql model and add a config on top: {{ config(materialized=&#39;table&#39;) }} Now, when you execute dbt run, dbt persists this model as a table by wrapping your query within a CREATE TABLE sessionized_clicks AS ... statement. ephemeral models are not directly built into the database. Instead, dbt interpolates the code from this model into dependent models as a common table expression. Is our sessionization logic correct dbt makes it super easy to add data tests. Let’s say you want to test if your logic is correct. There are some generic tests like unique and not_null defined in schema.yml. Tests check if values in a given column are unique or not null. The typical errors made when working on the sessionization logic are you messed something up and your sessions overlap. This should never be the case. Add a dbt test to validate this. After modifying your model, you can easily run the test to see if your logic is correct. Create assert_no_overlapping_sessions.sql in the tests folder. SELECT sc1.session_started, sc1.session_ended, sc1.session_ended, sc2.session_started, sc1.visitorid, sc2.visitorid FROM {{ ref(&#39;sessionized_clicks&#39;) }} sc1 JOIN {{ ref(&#39;sessionized_clicks&#39;) }} sc2 ON sc1.session_started &gt; sc2.session_ended AND sc1.session_ended &lt; sc2.session_started AND sc1.visitorid = sc2.visitorid Now, you can run dbt test --select sessionized_clicks to test and validate the model. Using dbt macros dbt comes with powerful feature called macros. The well-maintained package dbt-utils contains macros that can be (re)used across dbt projects. Starburst maintains dbt-trino-utils. This dbt package contains macros that: Can be (re)used across dbt projects running on Trino or Starburst databases. Define implementations of dispatched macros from other packages that can be used on Trino or Starburst databases. To use dbt_utils or trino_utils, define both packages in the packages.yml file: packages: - package: dbt-labs/dbt_utils version: {SEE DBT HUB FOR NEWEST VERSION} - package: starburstdata/trino_utils version: {SEE DBT HUB FOR NEWEST VERSION} Next, tell the supported package to also look for the trino_utils macros by adding the relevant dispatches to your dbt_project.yml: dispatch: - macro_namespace: dbt_utils search_order: [&#39;trino_utils&#39;, &#39;dbt_utils&#39;] Once packages are defined, run dbt deps which pulls the packages defined in packages.yml A sample use case might be dropping and cleaning databases from objects which are no longer used. To do so simply run: dbt run-operation trino__drop_old_relations To preview the cleaning results, add --args &quot;{dry_run: true}&quot; at the end of the command above. Adding static data with seeds dbt also allows you to insert the content of CSV files (named seeds in dbt) directly into a table using the dbt seed command. This is particularly useful if you need to keep a list of mappings or values with your project. For example, you have a list comprised of campaigns, countries, and age groups. Columns campaign_id identifies campaign, country where the campaign was run, and the age_group a target group for the campaign. You can simply create a csv campaigns.csv and put it into the seeds folder. campaign_id,country,age_group 1,US,&quot;18-24&quot; 2,Europe,&quot;18-24&quot; 3,US,&quot;25-40&quot; 4,Europe,&quot;25-40&quot; 5,US,&quot;41-60&quot; After performing the dbt seed command you can reference the seed in our models using the familiar syntax:{{ ref(“campaigns”) }}. Now, it’s time to make it even faster with incremental refreshing." />
<meta property="og:description" content="This is part two of the lakehouse ETL with dbt and Trino series. Start at the introduction if you haven’t already. Now that you have set up all the required infrastructure, go through all the steps needed to install dbt and start building data pipelines. Intro to dbt-trino The dbt-trino adapter uses Trino as an underlying query engine to perform query federation across disperse data sources. Trino connects to multiple and diverse data sources (available connectors) via one dbt connection, and processes SQL queries. Transformations defined in dbt are passed to Trino, which handles these SQL transformation queries, and translates them to read data, create tables or views, and manipulate data in the connected data sources. Installing dbt and bootstrapping your project dbt can be installed through executing pip install dbt-trino. You need to have Python 3.7+ installed. After installing, you can run dbt --version to verify the dbt installation. It should result in something like the following: Core: - installed: 1.3.0 - latest: 1.3.0 - Up to date! Plugins: - trino: 1.3.1 - Up to date! Now, bootstrap the dbt project by executing dbt init. If you’ve just cloned or downloaded an existing dbt project, like in the case of a blog, dbt init can still help you set up your connection profile so that you can start working quickly. It prompts you for connection information, and to add a profile (using the profile name from the project) to your local profiles.yml, or create the file if it doesn’t already exist. More about configuring profiles is available from the official dbt documentation. Take, for example, the following configuration where you persist your flows into the datalake catalog (or database) and analytics schema on the Trino server running on port 8080 using the user admin. Note that in this development setup you are not using any authentication mechanism, so method is set to none. With the threads configuration, you define how many simultaneous queries to run, in other words, how fast you want your project to refresh. my_dbt_trino_project: target: dev outputs: dev: type: trino method: none user: admin database: datalake host: localhost port: 8080 schema: analytics threads: 1 All profiles.yml configuration options specific to dbt-trino can be found on the dbt-trino GitHub repository. Your first model The core construct of dbt is a model. A model is a SQL file within your project in the models folder that contains a SELECT query. The results of this select query materializes in your database as a VIEW or TABLE. For example, you can select all customers from your webshop database by creating a src_customers.sql file in your models. SELECT * FROM webshop.public.customers Now, when executing dbt run, dbt persists a table onto the datalake.analytics schema called src_customers. Running dbt run again replaces the existing view with a potential new definition if you change the query. Run this query in your favorite database client to validate the results of your model. SELECT * FROM datalake.analytics.src_customers; Adding your data sources As you can see above, you are sourcing directly from the operational PostgreSQL database. However, directly referencing to a database table in your models is a bad practice. To fix that, you need to define a dbt source. Sources define all external objects your project needs to get things done. Add a new sources.yml file in your models folder with the following content: version: 2 sources: - name: webshop database: webshop schema: public tables: - name: customers In the src_customers.sql, you can now refer to this source instead of the hard-coded location created earlier. That saves us from having to change all these locations everywhere when they change or you want to fetch them from a test database instead of the production database. Adding the prefix src helps to quickly identify which models are built straight from sources. SELECT * FROM {{ source(&#39;webshop&#39;, &#39;customers&#39;) }} Note the double curly braces {{ … }}, which indicate that the code fragment in between is evaluated by dbt before sending the query to your Trino instance. The source macro, or function, takes the database and schema from the first argument called source_name, and the name of the object from the second argument called table_name. The end result, which is the compiled query, is the same as the query above without the source macro. Adding EL to the T of dbt Traditionally, dbt is used for database transformations only, hence the name data transformation tool. It leaves the extract and load to other tools, for example Airbyte or Fivetran. Now, with the data federation capabilities of Trino, EL (extract and load) is added to the T (Transform) capabilities of dbt. Any data can be added as if it was located within the same database, as long as there is a Trino connector for it. Think about having any relational or NoSQL databases, message queues, or API’s immediately available without having to perform an expensive and complicated extract and load process. You have already loaded a table directly from our PostgreSQL database into the datalake without any additional tools required. Now, add another source–the clickstream data. For example, what if you want to know how many times a customer has visited our website before making a buy decision. Our clickstream data is readily available under the website catalog. First, you add a new source website to the sources.yml file: version: 2 sources: - name: webshop ... - name: website database: website schema: clickstream tables: - name: clicks Create a model file src_clicks.sql under the models folder: with source as ( SELECT * FROM {{ source(&#39;website&#39;, &#39;clicks&#39;) }} ), renamed as ( SELECT visitorid, useragent, language, event, cast(from_iso8601_timestamp(eventtime) AS timestamp(6) with time zone) AS eventtime, page, referrer FROM source ) SELECT * FROM renamed Execute dbt run again to materialize a newly created view. dbt implicitly builds your DAG A crucial concept in data pipelines is a DAG (Direct Acrylic Graph). A DAG defines all the steps the data pipeline has to perform from source to target. Each step of a DAG performs its job when all its parents have finished and triggers the start of its direct children (the dependents). Most tools, like Apache Airflow, take a very explicit approach on constructing DAGs. dbt, however, constructs the DAG implicitly. Every step of the DAG is a simple SQL file (called a model in dbt). You can refer to other models using the ref macro, for example {{ ref(‘src_customers’)}}. Let’s say, for example, you want to know how many times each customer visits the website before making a buying decision. For that, you need to join your webshop data with the clickstream data. However, clickstream data tends to be big and not so easy to analyze. For example, the user might have researched products before actually registering or logging into the webshop. To solve this, you want to introduce the concept of sessionization, and try to associate these sessions with an actual user. Each visitor of the website gets a unique identifier that is stored in a long-lasting cookie. You also have a sessions table in the webshop where you can link this unique identifier to an actual user in your webshop. With this data, you can also identify the clicks performed prior to logging into the webshop. Below, you can see the lineage DAG of models generated by dbt. × First you need to add the sessions table to our sources: version: 2 sources: - name: webshop database: webshop schema: public tables: - name: customers - name: sessions Again, you add a simple model called src_sessions.sql that is just performing a select on our source: with source as ( SELECT * FROM {{ source(&#39;webshop&#39;, &#39;sessions&#39;) }} ), renamed as ( SELECT cookie_id, cast(from_unixtime(started_ts/1000) AS timestamp(6)) AS session_started, customer_id FROM source ) SELECT * FROM renamed Now, build this by creating a new model sessionized_clicks.sql. First identify some rules about our sessionization: A session is a sequence of clicks, in which no two consecutive clicks are more than one hour apart. Once a user logs in, you associate also past sessions with the user. Trino supports numerous SQL functions and advanced operators that can be used in dbt models. The query used in the following model uses some of Trino’s more sophisticated features. Although complicated, they are necessary and useful in the hands of a data engineer. One such feature, used to implement sessions, is WINDOW operations. The WINDOW clause allows you to look from the current record to the group of records it belongs to. Some of the use cases are to detect the first or last record, or the maximum or minimum (any aggregation) within that group. It is different from a GROUP BY in the sense that it doesn’t group or reduce the number of records. The model is also making use of macro (more on that in a section below) called star. It generates a comma-separated list of all fields that exist in the from relation, excluding any fields listed in the except argument. The construction is identical to SELECT * FROM {{ref(‘my_model’)}}, replacing star (*) with the star macro: WITH sessions AS ( SELECT date_diff(&#39;hour&#39;, lag(c.eventtime) OVER w, c.eventtime) &gt; 1 AS new_session, {{ dbt_utils.star(ref(&quot;src_clicks&quot;), &quot;c&quot;) }}, {{ dbt_utils.star(ref(&quot;customer_sessions&quot;), &quot;s&quot;, [&quot;session_started&quot;, &quot;session_ended&quot;]) }}, first_value(c.referrer) ignore nulls OVER (PARTITION BY s.customer_id ORDER BY c.eventtime ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS channel, row_number() OVER w AS clickid, min(eventtime) OVER w AS session_started, max(eventtime) OVER w AS session_ended FROM {{ ref(&quot;src_clicks&quot;) }} c JOIN {{ ref(&quot;customer_sessions&quot;) }} s ON c.visitorid = s.cookie_id AND c.eventtime BETWEEN s.session_started AND s.session_ended WINDOW w AS ( PARTITION BY c.visitorid ORDER BY c.eventtime ) ), sequenced_sessions AS ( SELECT {{ dbt_utils.star(ref(&quot;src_clicks&quot;)) }}, sum(if(new_session, 1, 0)) OVER w AS session_sequence, clickid, customer_id, session_started, session_ended, channel FROM sessions WINDOW w AS ( PARTITION BY visitorid ORDER BY eventtime ) ) SELECT visitorid || &#39;_&#39; || cast(session_sequence as varchar) || &#39;_&#39; || cast(clickid as varchar) AS clickid, visitorid || &#39;_&#39; || cast(session_sequence as varchar) AS sessionid, customer_id, session_started, session_ended, channel, {{ dbt_utils.star(ref(&quot;src_clicks&quot;)) }} FROM sequenced_sessions Materializations (view, table, ephemeral) To manage the performance of your data pipeline, you should wisely choose which models should be materialized as a view, which ones as a table, or just reused within an existing SQL statement. As a general guideline, it is wise to make tables of all the data exposed to actual users, for example dashboards. Here the sessionization is using a window and adding a session_id to each click. You don’t want this expensive operation to be performed every time you use the sessionized_clicks object. So it should be persisted as a table instead of a view. Just adapt the sessionized_clicks.sql model and add a config on top: {{ config(materialized=&#39;table&#39;) }} Now, when you execute dbt run, dbt persists this model as a table by wrapping your query within a CREATE TABLE sessionized_clicks AS ... statement. ephemeral models are not directly built into the database. Instead, dbt interpolates the code from this model into dependent models as a common table expression. Is our sessionization logic correct dbt makes it super easy to add data tests. Let’s say you want to test if your logic is correct. There are some generic tests like unique and not_null defined in schema.yml. Tests check if values in a given column are unique or not null. The typical errors made when working on the sessionization logic are you messed something up and your sessions overlap. This should never be the case. Add a dbt test to validate this. After modifying your model, you can easily run the test to see if your logic is correct. Create assert_no_overlapping_sessions.sql in the tests folder. SELECT sc1.session_started, sc1.session_ended, sc1.session_ended, sc2.session_started, sc1.visitorid, sc2.visitorid FROM {{ ref(&#39;sessionized_clicks&#39;) }} sc1 JOIN {{ ref(&#39;sessionized_clicks&#39;) }} sc2 ON sc1.session_started &gt; sc2.session_ended AND sc1.session_ended &lt; sc2.session_started AND sc1.visitorid = sc2.visitorid Now, you can run dbt test --select sessionized_clicks to test and validate the model. Using dbt macros dbt comes with powerful feature called macros. The well-maintained package dbt-utils contains macros that can be (re)used across dbt projects. Starburst maintains dbt-trino-utils. This dbt package contains macros that: Can be (re)used across dbt projects running on Trino or Starburst databases. Define implementations of dispatched macros from other packages that can be used on Trino or Starburst databases. To use dbt_utils or trino_utils, define both packages in the packages.yml file: packages: - package: dbt-labs/dbt_utils version: {SEE DBT HUB FOR NEWEST VERSION} - package: starburstdata/trino_utils version: {SEE DBT HUB FOR NEWEST VERSION} Next, tell the supported package to also look for the trino_utils macros by adding the relevant dispatches to your dbt_project.yml: dispatch: - macro_namespace: dbt_utils search_order: [&#39;trino_utils&#39;, &#39;dbt_utils&#39;] Once packages are defined, run dbt deps which pulls the packages defined in packages.yml A sample use case might be dropping and cleaning databases from objects which are no longer used. To do so simply run: dbt run-operation trino__drop_old_relations To preview the cleaning results, add --args &quot;{dry_run: true}&quot; at the end of the command above. Adding static data with seeds dbt also allows you to insert the content of CSV files (named seeds in dbt) directly into a table using the dbt seed command. This is particularly useful if you need to keep a list of mappings or values with your project. For example, you have a list comprised of campaigns, countries, and age groups. Columns campaign_id identifies campaign, country where the campaign was run, and the age_group a target group for the campaign. You can simply create a csv campaigns.csv and put it into the seeds folder. campaign_id,country,age_group 1,US,&quot;18-24&quot; 2,Europe,&quot;18-24&quot; 3,US,&quot;25-40&quot; 4,Europe,&quot;25-40&quot; 5,US,&quot;41-60&quot; After performing the dbt seed command you can reference the seed in our models using the familiar syntax:{{ ref(“campaigns”) }}. Now, it’s time to make it even faster with incremental refreshing." />
<link rel="canonical" href="https://docs.starburst.io/blog_dbt/2022-11-30-dbt2-first-dbt-data-pipeline.html" />
<meta property="og:url" content="https://docs.starburst.io/blog_dbt/2022-11-30-dbt2-first-dbt-data-pipeline.html" />
<meta property="og:site_name" content="Starburst" />
<meta property="og:image" content="https://docs.starburst.io/assets/img/logo/dbt.svg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-11-30T00:00:00-06:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://docs.starburst.io/assets/img/logo/dbt.svg" />
<meta property="twitter:title" content="First dbt-trino data pipeline" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2022-11-30T00:00:00-06:00","datePublished":"2022-11-30T00:00:00-06:00","description":"This is part two of the lakehouse ETL with dbt and Trino series. Start at the introduction if you haven’t already. Now that you have set up all the required infrastructure, go through all the steps needed to install dbt and start building data pipelines. Intro to dbt-trino The dbt-trino adapter uses Trino as an underlying query engine to perform query federation across disperse data sources. Trino connects to multiple and diverse data sources (available connectors) via one dbt connection, and processes SQL queries. Transformations defined in dbt are passed to Trino, which handles these SQL transformation queries, and translates them to read data, create tables or views, and manipulate data in the connected data sources. Installing dbt and bootstrapping your project dbt can be installed through executing pip install dbt-trino. You need to have Python 3.7+ installed. After installing, you can run dbt --version to verify the dbt installation. It should result in something like the following: Core: - installed: 1.3.0 - latest: 1.3.0 - Up to date! Plugins: - trino: 1.3.1 - Up to date! Now, bootstrap the dbt project by executing dbt init. If you’ve just cloned or downloaded an existing dbt project, like in the case of a blog, dbt init can still help you set up your connection profile so that you can start working quickly. It prompts you for connection information, and to add a profile (using the profile name from the project) to your local profiles.yml, or create the file if it doesn’t already exist. More about configuring profiles is available from the official dbt documentation. Take, for example, the following configuration where you persist your flows into the datalake catalog (or database) and analytics schema on the Trino server running on port 8080 using the user admin. Note that in this development setup you are not using any authentication mechanism, so method is set to none. With the threads configuration, you define how many simultaneous queries to run, in other words, how fast you want your project to refresh. my_dbt_trino_project: target: dev outputs: dev: type: trino method: none user: admin database: datalake host: localhost port: 8080 schema: analytics threads: 1 All profiles.yml configuration options specific to dbt-trino can be found on the dbt-trino GitHub repository. Your first model The core construct of dbt is a model. A model is a SQL file within your project in the models folder that contains a SELECT query. The results of this select query materializes in your database as a VIEW or TABLE. For example, you can select all customers from your webshop database by creating a src_customers.sql file in your models. SELECT * FROM webshop.public.customers Now, when executing dbt run, dbt persists a table onto the datalake.analytics schema called src_customers. Running dbt run again replaces the existing view with a potential new definition if you change the query. Run this query in your favorite database client to validate the results of your model. SELECT * FROM datalake.analytics.src_customers; Adding your data sources As you can see above, you are sourcing directly from the operational PostgreSQL database. However, directly referencing to a database table in your models is a bad practice. To fix that, you need to define a dbt source. Sources define all external objects your project needs to get things done. Add a new sources.yml file in your models folder with the following content: version: 2 sources: - name: webshop database: webshop schema: public tables: - name: customers In the src_customers.sql, you can now refer to this source instead of the hard-coded location created earlier. That saves us from having to change all these locations everywhere when they change or you want to fetch them from a test database instead of the production database. Adding the prefix src helps to quickly identify which models are built straight from sources. SELECT * FROM {{ source(&#39;webshop&#39;, &#39;customers&#39;) }} Note the double curly braces {{ … }}, which indicate that the code fragment in between is evaluated by dbt before sending the query to your Trino instance. The source macro, or function, takes the database and schema from the first argument called source_name, and the name of the object from the second argument called table_name. The end result, which is the compiled query, is the same as the query above without the source macro. Adding EL to the T of dbt Traditionally, dbt is used for database transformations only, hence the name data transformation tool. It leaves the extract and load to other tools, for example Airbyte or Fivetran. Now, with the data federation capabilities of Trino, EL (extract and load) is added to the T (Transform) capabilities of dbt. Any data can be added as if it was located within the same database, as long as there is a Trino connector for it. Think about having any relational or NoSQL databases, message queues, or API’s immediately available without having to perform an expensive and complicated extract and load process. You have already loaded a table directly from our PostgreSQL database into the datalake without any additional tools required. Now, add another source–the clickstream data. For example, what if you want to know how many times a customer has visited our website before making a buy decision. Our clickstream data is readily available under the website catalog. First, you add a new source website to the sources.yml file: version: 2 sources: - name: webshop ... - name: website database: website schema: clickstream tables: - name: clicks Create a model file src_clicks.sql under the models folder: with source as ( SELECT * FROM {{ source(&#39;website&#39;, &#39;clicks&#39;) }} ), renamed as ( SELECT visitorid, useragent, language, event, cast(from_iso8601_timestamp(eventtime) AS timestamp(6) with time zone) AS eventtime, page, referrer FROM source ) SELECT * FROM renamed Execute dbt run again to materialize a newly created view. dbt implicitly builds your DAG A crucial concept in data pipelines is a DAG (Direct Acrylic Graph). A DAG defines all the steps the data pipeline has to perform from source to target. Each step of a DAG performs its job when all its parents have finished and triggers the start of its direct children (the dependents). Most tools, like Apache Airflow, take a very explicit approach on constructing DAGs. dbt, however, constructs the DAG implicitly. Every step of the DAG is a simple SQL file (called a model in dbt). You can refer to other models using the ref macro, for example {{ ref(‘src_customers’)}}. Let’s say, for example, you want to know how many times each customer visits the website before making a buying decision. For that, you need to join your webshop data with the clickstream data. However, clickstream data tends to be big and not so easy to analyze. For example, the user might have researched products before actually registering or logging into the webshop. To solve this, you want to introduce the concept of sessionization, and try to associate these sessions with an actual user. Each visitor of the website gets a unique identifier that is stored in a long-lasting cookie. You also have a sessions table in the webshop where you can link this unique identifier to an actual user in your webshop. With this data, you can also identify the clicks performed prior to logging into the webshop. Below, you can see the lineage DAG of models generated by dbt. × First you need to add the sessions table to our sources: version: 2 sources: - name: webshop database: webshop schema: public tables: - name: customers - name: sessions Again, you add a simple model called src_sessions.sql that is just performing a select on our source: with source as ( SELECT * FROM {{ source(&#39;webshop&#39;, &#39;sessions&#39;) }} ), renamed as ( SELECT cookie_id, cast(from_unixtime(started_ts/1000) AS timestamp(6)) AS session_started, customer_id FROM source ) SELECT * FROM renamed Now, build this by creating a new model sessionized_clicks.sql. First identify some rules about our sessionization: A session is a sequence of clicks, in which no two consecutive clicks are more than one hour apart. Once a user logs in, you associate also past sessions with the user. Trino supports numerous SQL functions and advanced operators that can be used in dbt models. The query used in the following model uses some of Trino’s more sophisticated features. Although complicated, they are necessary and useful in the hands of a data engineer. One such feature, used to implement sessions, is WINDOW operations. The WINDOW clause allows you to look from the current record to the group of records it belongs to. Some of the use cases are to detect the first or last record, or the maximum or minimum (any aggregation) within that group. It is different from a GROUP BY in the sense that it doesn’t group or reduce the number of records. The model is also making use of macro (more on that in a section below) called star. It generates a comma-separated list of all fields that exist in the from relation, excluding any fields listed in the except argument. The construction is identical to SELECT * FROM {{ref(‘my_model’)}}, replacing star (*) with the star macro: WITH sessions AS ( SELECT date_diff(&#39;hour&#39;, lag(c.eventtime) OVER w, c.eventtime) &gt; 1 AS new_session, {{ dbt_utils.star(ref(&quot;src_clicks&quot;), &quot;c&quot;) }}, {{ dbt_utils.star(ref(&quot;customer_sessions&quot;), &quot;s&quot;, [&quot;session_started&quot;, &quot;session_ended&quot;]) }}, first_value(c.referrer) ignore nulls OVER (PARTITION BY s.customer_id ORDER BY c.eventtime ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS channel, row_number() OVER w AS clickid, min(eventtime) OVER w AS session_started, max(eventtime) OVER w AS session_ended FROM {{ ref(&quot;src_clicks&quot;) }} c JOIN {{ ref(&quot;customer_sessions&quot;) }} s ON c.visitorid = s.cookie_id AND c.eventtime BETWEEN s.session_started AND s.session_ended WINDOW w AS ( PARTITION BY c.visitorid ORDER BY c.eventtime ) ), sequenced_sessions AS ( SELECT {{ dbt_utils.star(ref(&quot;src_clicks&quot;)) }}, sum(if(new_session, 1, 0)) OVER w AS session_sequence, clickid, customer_id, session_started, session_ended, channel FROM sessions WINDOW w AS ( PARTITION BY visitorid ORDER BY eventtime ) ) SELECT visitorid || &#39;_&#39; || cast(session_sequence as varchar) || &#39;_&#39; || cast(clickid as varchar) AS clickid, visitorid || &#39;_&#39; || cast(session_sequence as varchar) AS sessionid, customer_id, session_started, session_ended, channel, {{ dbt_utils.star(ref(&quot;src_clicks&quot;)) }} FROM sequenced_sessions Materializations (view, table, ephemeral) To manage the performance of your data pipeline, you should wisely choose which models should be materialized as a view, which ones as a table, or just reused within an existing SQL statement. As a general guideline, it is wise to make tables of all the data exposed to actual users, for example dashboards. Here the sessionization is using a window and adding a session_id to each click. You don’t want this expensive operation to be performed every time you use the sessionized_clicks object. So it should be persisted as a table instead of a view. Just adapt the sessionized_clicks.sql model and add a config on top: {{ config(materialized=&#39;table&#39;) }} Now, when you execute dbt run, dbt persists this model as a table by wrapping your query within a CREATE TABLE sessionized_clicks AS ... statement. ephemeral models are not directly built into the database. Instead, dbt interpolates the code from this model into dependent models as a common table expression. Is our sessionization logic correct dbt makes it super easy to add data tests. Let’s say you want to test if your logic is correct. There are some generic tests like unique and not_null defined in schema.yml. Tests check if values in a given column are unique or not null. The typical errors made when working on the sessionization logic are you messed something up and your sessions overlap. This should never be the case. Add a dbt test to validate this. After modifying your model, you can easily run the test to see if your logic is correct. Create assert_no_overlapping_sessions.sql in the tests folder. SELECT sc1.session_started, sc1.session_ended, sc1.session_ended, sc2.session_started, sc1.visitorid, sc2.visitorid FROM {{ ref(&#39;sessionized_clicks&#39;) }} sc1 JOIN {{ ref(&#39;sessionized_clicks&#39;) }} sc2 ON sc1.session_started &gt; sc2.session_ended AND sc1.session_ended &lt; sc2.session_started AND sc1.visitorid = sc2.visitorid Now, you can run dbt test --select sessionized_clicks to test and validate the model. Using dbt macros dbt comes with powerful feature called macros. The well-maintained package dbt-utils contains macros that can be (re)used across dbt projects. Starburst maintains dbt-trino-utils. This dbt package contains macros that: Can be (re)used across dbt projects running on Trino or Starburst databases. Define implementations of dispatched macros from other packages that can be used on Trino or Starburst databases. To use dbt_utils or trino_utils, define both packages in the packages.yml file: packages: - package: dbt-labs/dbt_utils version: {SEE DBT HUB FOR NEWEST VERSION} - package: starburstdata/trino_utils version: {SEE DBT HUB FOR NEWEST VERSION} Next, tell the supported package to also look for the trino_utils macros by adding the relevant dispatches to your dbt_project.yml: dispatch: - macro_namespace: dbt_utils search_order: [&#39;trino_utils&#39;, &#39;dbt_utils&#39;] Once packages are defined, run dbt deps which pulls the packages defined in packages.yml A sample use case might be dropping and cleaning databases from objects which are no longer used. To do so simply run: dbt run-operation trino__drop_old_relations To preview the cleaning results, add --args &quot;{dry_run: true}&quot; at the end of the command above. Adding static data with seeds dbt also allows you to insert the content of CSV files (named seeds in dbt) directly into a table using the dbt seed command. This is particularly useful if you need to keep a list of mappings or values with your project. For example, you have a list comprised of campaigns, countries, and age groups. Columns campaign_id identifies campaign, country where the campaign was run, and the age_group a target group for the campaign. You can simply create a csv campaigns.csv and put it into the seeds folder. campaign_id,country,age_group 1,US,&quot;18-24&quot; 2,Europe,&quot;18-24&quot; 3,US,&quot;25-40&quot; 4,Europe,&quot;25-40&quot; 5,US,&quot;41-60&quot; After performing the dbt seed command you can reference the seed in our models using the familiar syntax:{{ ref(“campaigns”) }}. Now, it’s time to make it even faster with incremental refreshing.","headline":"First dbt-trino data pipeline","image":"https://docs.starburst.io/assets/img/logo/dbt.svg","mainEntityOfPage":{"@type":"WebPage","@id":"https://docs.starburst.io/blog_dbt/2022-11-30-dbt2-first-dbt-data-pipeline.html"},"publisher":{"@type":"Organization","logo":{"@type":"ImageObject","url":"https://docs.starburst.io/assets/img/logo/starburst-reverse.png"}},"url":"https://docs.starburst.io/blog_dbt/2022-11-30-dbt2-first-dbt-data-pipeline.html"}</script>
<!-- End Jekyll SEO tag -->

</head>
<body>


<header class="main-header navbar-expand-sm">
  <div class="navbar fixed-top navbar-dark">
    <div class="navbar-left-container">
      <a class="navbar-brand" href="https://www.starburst.io/">
        <img src="/assets/img/logo/starburst_KO-T.png" height="32" alt="Starburst">
      </a>
      <span class="navbar-divider"></span>
      <a href="/" class="header-text">Documentation</a>
    </div>
    
    <div class="nav-item dropdown" id="site-search">
  <div id="dropdownSearchDisplay" aria-labelledby="dropdownSearch">
    <div id="algolia-search">
      <div id="searchbox"></div>
      <div id="refinement-list">
        <h6>Filter:</h6>
      </div>
      <div id="hits"></div>
      <div id="stats"></div>
    </div>
  </div>
</div>

    
    <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>
  </div>
    <nav class="primary-nav">
      <div class="collapse navbar-collapse" id="navbarSupportedContent">
        <ul class="navbar-layout navbar-nav mr-auto">
          <li class="nav-item dropdown">
            <a id="get-started"
               class="nav-link dropdown-toggle" 
              aria-haspopup="true" aria-label="Get started" data-is-click="false"
              href="/get-started/index.html">Get started</a>
            <div class="dropdown-menu dropdown-docs">
              <a class="dropdown-item" href="/get-started/concepts.html">Concepts</a>
              <a class="dropdown-item" href="/get-started/architecture.html">Architecture</a>
              <a class="dropdown-item" href="/get-started/data-sources-catalogs.html">Data sources and catalogs</a>
              <a class="dropdown-item" href="/get-started/security.html">Security</a>
              <a class="dropdown-item" href="/get-started/choose-your-starburst-product.html">Choose your Starburst product</a>
              <a class="dropdown-item" href="/data-consumer/index.html">Data consumer</a>
              <a class="dropdown-item" href="/data-engineer/index.html">Data engineer</a>
              <a class="dropdown-item" href="/platform-administrator/index.html">Platform administrator</a>
            </div>
          </li>
          <li class="nav-item dropdown">
            <a id="starburst-galaxy"
               class="nav-link dropdown-toggle" 
              aria-haspopup="true" aria-label="Starburst Galaxy" data-is-click="false"
              href="/starburst-galaxy/index.html">Starburst Galaxy</a>
            <div class="dropdown-menu dropdown-docs">
              <a class="dropdown-item" href="/starburst-galaxy/query/index.html">Query</a>
              <a class="dropdown-item" href="/starburst-galaxy/catalogs/index.html">Catalogs</a>
              <a class="dropdown-item" href="/starburst-galaxy/catalog-explorer/index.html">Catalog explorer</a>
              <a class="dropdown-item" href="/starburst-galaxy/clusters/index.html">Clusters</a>
              <a class="dropdown-item" href="/starburst-galaxy/sql/index.html">SQL</a>
              <a class="dropdown-item" href="/starburst-galaxy/admin/index.html">Admin</a>
              <a class="dropdown-item" href="/starburst-galaxy/access-control/index.html">Access control</a>
              <a class="dropdown-item" href="/starburst-galaxy/cloud-settings/index.html">Cloud settings</a>
              <a class="dropdown-item" href="/starburst-galaxy/security/index.html">Security</a>
              <a class="dropdown-item" href="/starburst-galaxy/sso/index.html">Single sign-on</a>
              <a class="dropdown-item" href="/starburst-galaxy/api.html">API</a>
              <a class="dropdown-item" href="/starburst-galaxy/tutorials/index.html">Tutorials</a>
            </div>
          </li>
          <li class="nav-item dropdown">
            <a id="starburst-enterprise"
               class="nav-link dropdown-toggle" 
              aria-haspopup="true" aria-label="Get started" data-is-click="false"
              href="/starburst-enterprise/index.html">Starburst Enterprise</a>
            <div class="dropdown-menu dropdown-docs">
              <a class="dropdown-item" href="/starburst-enterprise/try/index.html">Try Starburst Enterprise</a>
              <a class="dropdown-item" href="/starburst-enterprise/web-ui/index.html">Web UI</a>
              <a class="dropdown-item" href="/starburst-enterprise/sql.html">SQL</a>
              <a class="dropdown-item" href="/starburst-enterprise/admin-topics/index.html">Administration</a>
              <a class="dropdown-item" href="/starburst-enterprise/k8s/index.html">Kubernetes deployments</a>
              <a class="dropdown-item" href="/starburst-enterprise/starburst-admin/index.html">Starburst Admin</a>
              <a class="dropdown-item" href="/latest/index.html">Reference documentation</a>
            </div>
          </li>
          <li class="nav-item dropdown">
            <a id="ecosystems"
               class="nav-link dropdown-toggle" 
              aria-haspopup="true" aria-label="Get started" data-is-click="false"
              href="/ecosystems/index.html">Ecosystems</a>
            <div class="dropdown-menu dropdown-docs">
              <a class="dropdown-item" href="/ecosystems/amazon/index.html">Amazon AWS</a>
              <a class="dropdown-item" href="/ecosystems/google/index.html">Google Cloud</a>
              <a class="dropdown-item" href="/ecosystems/microsoft/index.html">Microsoft Azure</a>
              <a class="dropdown-item" href="/ecosystems/redhat/index.html">Red Hat OpenShift</a>
            </div>
          </li>
          <li class="nav-item dropdown">
            <a id="resources"
               class="nav-link dropdown-toggle" 
              aria-haspopup="true" aria-label="resources" data-is-click="false"
              href="/resources.html">Resources</a>
            <div class="dropdown-menu dropdown-docs">
              <a class="dropdown-item" href="/support.html">Support</a>
              <a class="dropdown-item" href="/security/index.html">Security</a>
              <a class="dropdown-item" href="/blog/index.html">Developer blog</a>
              <a class="dropdown-item" href="/videos/index.html">Video library</a>
              <a class="dropdown-item" href="/glossary.html">Glossary</a>
              <a class="dropdown-item" href="https://www.trinoforum.org/">Trino forum</a>
            </div>
          </li>
        </ul>
      </div>
    </nav>
</header>

    <div class="landing-page">
        <div class="sep-hero">
  <div class="container sep-parent">
    <div class="row">
      <div class="col-md-12">
        <h1><a href="/blog/">Starburst developer blog</a></h1>
        <p class="lead">The latest news from our users, engineers, writers, and
        product folks for all our peers and friends out there.</p>
        <p>Want even more updates and information? Go to the
          <a href="https://blog.starburst.io/">Starburst company blog</a>.</p>
      </div>
    </div>
  </div>
</div>

  


<div class="content container-fluid post-container clearfix spacer-30">

  <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
    <div class="container">
      <div class="row">

        <div class="col-xl-3">
          <h3>Contents</h3>
          <ul class="list-group">
            
              
                <a class="list-group-item" href="/blog/2022-11-30-dbt0-introduction.html">Building lakehouse with dbt and Trino</a>
              
            
            
              
                <a class="list-group-item" href="/blog_dbt/2022-11-30-dbt1-trino-setup.html">Setting up Trino for dbt</a>
              
            
              
                <li class="list-group-item active">First dbt-trino data pipeline</li>
              
            
              
                <a class="list-group-item" href="/blog_dbt/2022-11-30-dbt3-refresh-your-data-faster.html">Refresh your data faster using incremental models</a>
              
            
          </ul>
        </div>

        <div class="col-xl-9">
          <header class="post-header">
            <h1 class="post-title p-name" itemprop="name headline">
              First dbt-trino data pipeline</h1>
            <p class="post-meta">
              <time class="dt-published" abbrtime="2022-11-30T00:00:00-06:00" itemprop="datePublished">
                Nov 30, 2022
              </time> |

     Michiel De Smet
     
     
     <a href="https://github.com/mdesmet" target="_blank"><i class="fab fa-github"></i></a>
     
     ,
     


     Przemek Denkiewicz
     
     <a href="https://twitter.com/hovaesco" target="_blank"><i class="fab fa-twitter"></i></a>
     
     
     <a href="https://github.com/hovaesco" target="_blank"><i class="fab fa-github"></i></a>
     
     
</p>
          </header>

          <div class="content width clearfix" itemprop="articleBody"><img src="../assets/img/logo/dbt.svg" style="float: right;"><p><em>This is part two of the lakehouse ETL with dbt and Trino series. <a href="/blog/2022-11-30-dbt0-introduction.html">Start at the
introduction</a> if you haven’t
already.</em></p>

<p>Now that you have <a href="/blog_dbt/2022-11-30-dbt1-trino-setup.html">set up all the required infrastructure</a>, go through all the steps needed to
install dbt and start building data pipelines.</p>

<h2 id="intro-to-dbt-trino">Intro to dbt-trino</h2>

<p>The <a href="https://github.com/starburstdata/dbt-trino/">dbt-trino</a> adapter uses Trino
as an underlying query engine to perform query federation across disperse data
sources. Trino connects to multiple and diverse data sources (<a href="https://trino.io/docs/current/connector.html">available
connectors</a>) via one dbt
connection, and processes SQL queries. Transformations defined in dbt are passed
to Trino, which handles these SQL transformation queries, and translates them to
read data, create tables or views, and manipulate data in the connected data
sources.</p>

<p><img src="../assets/img/blog/dbt-trino-architecture.png" alt="How dbt works with Starburst" class="img-fluid img-screenshot" description="" width="px" style="" /></p>

<h2 id="installing-dbt-and-bootstrapping-your-project">Installing dbt and bootstrapping your project</h2>

<p>dbt can be installed through executing <code class="language-plaintext highlighter-rouge">pip install dbt-trino</code>. You need to have
Python 3.7+ installed.</p>

<p>After installing, you can run <code class="language-plaintext highlighter-rouge">dbt --version</code> to verify the dbt installation. It
should result in something like the following:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Core:
  - installed: 1.3.0
  - latest:    1.3.0 - Up to <span class="nb">date</span><span class="o">!</span>

Plugins:
  - trino: 1.3.1 - Up to <span class="nb">date</span><span class="o">!</span>
</code></pre></div></div>

<p>Now, bootstrap the dbt project by executing <code class="language-plaintext highlighter-rouge">dbt init</code>. If you’ve just cloned or
downloaded an existing dbt project, like in the case of a blog, <code class="language-plaintext highlighter-rouge">dbt init</code> can
still help you set up your connection profile so that you can start working
quickly. It prompts you for connection information, and to add a profile (using
the profile name from the project) to your local <code class="language-plaintext highlighter-rouge">profiles.yml</code>, or create the
file if it doesn’t already exist. More about configuring profiles is available
from <a href="https://docs.getdbt.com/dbt-cli/configure-your-profile">the official dbt
documentation</a>.</p>

<p>Take, for example, the following configuration where you persist your flows into
the <code class="language-plaintext highlighter-rouge">datalake</code> catalog (or database) and <code class="language-plaintext highlighter-rouge">analytics</code> schema on the Trino server
running on port <code class="language-plaintext highlighter-rouge">8080</code> using the user <code class="language-plaintext highlighter-rouge">admin</code>. Note that in this development
setup you are not using any authentication mechanism, so <code class="language-plaintext highlighter-rouge">method</code> is set to
<code class="language-plaintext highlighter-rouge">none</code>. With the <code class="language-plaintext highlighter-rouge">threads</code> configuration, you define how many simultaneous
queries to run, in other words, how fast you want your project to refresh.</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">my_dbt_trino_project</span><span class="pi">:</span>
  <span class="na">target</span><span class="pi">:</span> <span class="s">dev</span>
  <span class="na">outputs</span><span class="pi">:</span>
    <span class="na">dev</span><span class="pi">:</span>
      <span class="na">type</span><span class="pi">:</span> <span class="s">trino</span>
      <span class="na">method</span><span class="pi">:</span> <span class="s">none</span>
      <span class="na">user</span><span class="pi">:</span> <span class="s">admin</span>
      <span class="na">database</span><span class="pi">:</span> <span class="s">datalake</span>
      <span class="na">host</span><span class="pi">:</span> <span class="s">localhost</span>
      <span class="na">port</span><span class="pi">:</span> <span class="m">8080</span>
      <span class="na">schema</span><span class="pi">:</span> <span class="s">analytics</span>
      <span class="na">threads</span><span class="pi">:</span> <span class="m">1</span>
</code></pre></div></div>

<p>All <code class="language-plaintext highlighter-rouge">profiles.yml</code> configuration options specific to dbt-trino can be found on
<a href="https://github.com/starburstdata/dbt-trino/#configuring-your-profile">the dbt-trino GitHub
repository</a>.</p>

<h2 id="your-first-model">Your first model</h2>

<p>The core construct of dbt is a model. A model is a SQL file within your project
in the <code class="language-plaintext highlighter-rouge">models</code> folder that contains a <code class="language-plaintext highlighter-rouge">SELECT</code> query. The results of this
select query materializes in your database as a <code class="language-plaintext highlighter-rouge">VIEW</code> or <code class="language-plaintext highlighter-rouge">TABLE</code>.</p>

<p>For example, you can select all customers from your webshop database by creating
a <code class="language-plaintext highlighter-rouge">src_customers.sql</code> file in your models.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">webshop</span><span class="p">.</span><span class="k">public</span><span class="p">.</span><span class="n">customers</span>
</code></pre></div></div>

<p>Now, when executing <code class="language-plaintext highlighter-rouge">dbt run</code>, dbt persists a table onto the
<code class="language-plaintext highlighter-rouge">datalake.analytics</code> schema called <code class="language-plaintext highlighter-rouge">src_customers</code>. Running <code class="language-plaintext highlighter-rouge">dbt run</code> again
replaces the existing view with a potential new definition if you change the
query.</p>

<p>Run this query in your favorite database client to validate the results of your
model.</p>

<div class="language-sql highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">datalake</span><span class="p">.</span><span class="n">analytics</span><span class="p">.</span><span class="n">src_customers</span><span class="p">;</span>
</code></pre></div></div>

<h2 id="adding-your-data-sources">Adding your data sources</h2>

<p>As you can see above, you are sourcing directly from the operational PostgreSQL
database. However, directly referencing to a database table in your models is a
bad practice. To fix that, you need to define a
<a href="https://docs.getdbt.com/docs/build/sources">dbt source</a>. Sources define all
external objects your project needs to get things done.</p>

<p>Add a new <code class="language-plaintext highlighter-rouge">sources.yml</code> file in your <code class="language-plaintext highlighter-rouge">models</code> folder with the following
content:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">version</span><span class="pi">:</span> <span class="m">2</span>

<span class="na">sources</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">webshop</span>
    <span class="na">database</span><span class="pi">:</span> <span class="s">webshop</span>
    <span class="na">schema</span><span class="pi">:</span> <span class="s">public</span>
    <span class="na">tables</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">customers</span>
</code></pre></div></div>

<p>In the <code class="language-plaintext highlighter-rouge">src_customers.sql</code>, you can now refer to this source instead of the
hard-coded location created earlier. That saves us from having to change all
these locations everywhere when they change or you want to fetch them from a
test database instead of the production database. Adding the prefix <code class="language-plaintext highlighter-rouge">src</code> helps
to quickly identify which models are built straight from sources.</p>

<pre class="highlight">
<code>SELECT * FROM {{ source('webshop', 'customers') }}</code>
</pre>

<p>Note the double curly braces {{ … }}, which indicate that
the code fragment in between is evaluated by dbt before sending the query to
your Trino instance. <a href="https://docs.getdbt.com/reference/dbt-jinja-functions/source">The
source</a> macro, or
function, takes the database and schema from the first argument called
<code class="language-plaintext highlighter-rouge">source_name</code>, and the name of the object from the second argument called
<code class="language-plaintext highlighter-rouge">table_name</code>. The end result, which is the compiled query, is the same as the
query above without the <code class="language-plaintext highlighter-rouge">source</code> macro.</p>

<h2 id="adding-el-to-the-t-of-dbt">Adding EL to the T of dbt</h2>

<p>Traditionally, dbt is used for database transformations only, hence the name
data transformation tool. It leaves the extract and load to other tools, for
example Airbyte or Fivetran. Now, with the data federation capabilities of
Trino, EL (extract and load) is added to the T (Transform) capabilities of dbt.
Any data can be added as if it was located within the same database, as long as
there is a Trino connector for it. Think about having any relational or NoSQL
databases, message queues, or API’s immediately available without having to
perform an expensive and complicated extract and load process.</p>

<p>You have already loaded a table directly from our PostgreSQL database into the
datalake without any additional tools required. Now, add another source–the clickstream data. For example, what if you want to know how many times a
customer has visited our website before making a buy decision. Our clickstream
data is readily available under the <code class="language-plaintext highlighter-rouge">website</code> catalog.</p>

<p>First, you add a new source <code class="language-plaintext highlighter-rouge">website</code> to the <code class="language-plaintext highlighter-rouge">sources.yml</code> file:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">version</span><span class="pi">:</span> <span class="m">2</span>

<span class="na">sources</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">webshop</span>
    <span class="s">...</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">website</span>
    <span class="na">database</span><span class="pi">:</span> <span class="s">website</span>
    <span class="na">schema</span><span class="pi">:</span> <span class="s">clickstream</span>
    <span class="na">tables</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">clicks</span>
</code></pre></div></div>

<p>Create a model file <code class="language-plaintext highlighter-rouge">src_clicks.sql</code> under the models folder:</p>

<pre class="highlight">
<code>with source as (

    SELECT * FROM {{ source('website', 'clicks') }}

),

renamed as (

    SELECT

        visitorid,
        useragent,
        language,
        event,
        cast(from_iso8601_timestamp(eventtime) AS timestamp(6) with time zone) AS eventtime,
        page,
        referrer

    FROM source

)

SELECT * FROM renamed</code>
</pre>

<p>Execute <code class="language-plaintext highlighter-rouge">dbt run</code> again to materialize a newly created view.</p>

<h2 id="dbt-implicitly-builds-your-dag">dbt implicitly builds your DAG</h2>

<p>A crucial concept in data pipelines is a DAG (Direct Acrylic Graph). A DAG
defines all the steps the data pipeline has to perform from source to target.
Each step of a DAG performs its job when all its parents have finished and
triggers the start of its direct children (the dependents).</p>

<p>Most tools, like Apache Airflow, take a very explicit approach on constructing
DAGs. dbt, however, constructs the DAG implicitly.</p>

<p>Every step of the DAG is a simple SQL file (called a <code class="language-plaintext highlighter-rouge">model</code> in dbt). You can
refer to other models using the
<a href="https://docs.getdbt.com/reference/dbt-jinja-functions/ref">ref</a> macro,
for example {{ ref(‘src_customers’)}}.</p>

<p>Let’s say, for example, you want to know how many times each customer
visits the website before making a buying decision. For that, you need to join
your webshop data with the clickstream data.</p>

<p>However, clickstream data tends to be big and not so easy to analyze. For
example, the user might have researched products before actually registering or
logging into the webshop. To solve this, you want to introduce the concept of
<strong>sessionization</strong>, and try to associate these sessions with an actual user.
Each visitor of the website gets a unique identifier that is stored in a
long-lasting cookie. You also have a sessions table in the webshop where you can
link this unique identifier to an actual user in your webshop. With this data,
you can also identify the clicks performed prior to logging into the webshop.
Below, you can see the lineage DAG of models generated by dbt.</p>

<p><button type="button" class="button-img" data-toggle="modal" data-target="#lineage">
    <img src="../assets/img/blog/dbt-lineage.png" alt="lineage image" class="img-fluid" description="" width="px" /><br />
  </button>
  <!-- The Modal --></p>
<div class="modal fade" id="lineage" tabindex="-1" role="dialog" aria-labelledby="basicModal" aria-hidden="true">
    <div class="modal-dialog modal-lg">
      <!-- Modal content -->
      <div class="modal-content" id="lineage">
          <div class="modal-header" style="border:none;">
              <button type="button" class="close" data-dismiss="modal" aria-label="Close">
              <span aria-hidden="true">×</span>
              </button>
          </div>
          <img src="../assets/img/blog/dbt-lineage.png" class="img-fluid center-block" />
      </div>
    </div>
  </div>

<p>First you need to add the sessions table to our sources:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">version</span><span class="pi">:</span> <span class="m">2</span>

<span class="na">sources</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">webshop</span>
    <span class="na">database</span><span class="pi">:</span> <span class="s">webshop</span>
    <span class="na">schema</span><span class="pi">:</span> <span class="s">public</span>
    <span class="na">tables</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">customers</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">sessions</span>
</code></pre></div></div>

<p>Again, you add a simple model called <code class="language-plaintext highlighter-rouge">src_sessions.sql</code> that is just performing
a select on our source:</p>

<pre class="highlight">
<code>with source as (

    SELECT * FROM {{ source('webshop', 'sessions') }}

),

renamed as (

    SELECT
        cookie_id,
        cast(from_unixtime(started_ts/1000) AS timestamp(6)) AS session_started,
        customer_id

    FROM source

)

SELECT * FROM renamed</code>
</pre>

<p>Now, build this by creating a new model <code class="language-plaintext highlighter-rouge">sessionized_clicks.sql</code>. First identify
some rules about our sessionization:</p>

<ul>
  <li>A session is a sequence of clicks, in which no two consecutive clicks
are more than one hour apart.</li>
  <li>Once a user logs in, you associate also past sessions with the user.</li>
</ul>

<p>Trino supports numerous <a href="https://trino.io/docs/current/functions.html">SQL functions and advanced operators
</a> that can be used in dbt models.</p>

<p>The query used in the following model uses some of Trino’s more sophisticated
features. Although complicated, they are necessary and useful in the
hands of a data engineer. One such feature, used to implement sessions, is
<a href="https://trino.io/docs/current/functions/window.html">WINDOW operations</a>. The
<code class="language-plaintext highlighter-rouge">WINDOW</code> clause allows you to look from the current record to the group of
records it belongs to. Some of the use cases are to detect the first or last
record, or the maximum or minimum (any aggregation) within that group. It is
different from a <code class="language-plaintext highlighter-rouge">GROUP BY</code> in the sense that it doesn’t group or reduce the
number of records.</p>

<p>The model is also making use of macro (more on that in a section below) called
<code class="language-plaintext highlighter-rouge">star</code>. It generates a comma-separated list of all fields that exist in the from
relation, excluding any fields listed in the except argument. The construction
is identical to SELECT * FROM {{ref(‘my_model’)}},
replacing star (*) with the star macro:</p>

<pre class="highlight">
<code>WITH sessions AS (

    SELECT

        date_diff('hour', lag(c.eventtime) OVER w, c.eventtime) &gt; 1 AS new_session,
        {{ dbt_utils.star(ref("src_clicks"), "c") }},
        {{ dbt_utils.star(ref("customer_sessions"), "s", ["session_started", "session_ended"]) }},
        first_value(c.referrer) ignore nulls OVER (PARTITION BY s.customer_id ORDER BY c.eventtime ASC ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS channel,
        row_number() OVER w AS clickid,
        min(eventtime) OVER w AS session_started,
        max(eventtime) OVER w AS session_ended

    FROM {{ ref("src_clicks") }} c
    JOIN {{ ref("customer_sessions") }} s ON c.visitorid = s.cookie_id AND c.eventtime BETWEEN s.session_started AND s.session_ended
    WINDOW w AS (
        PARTITION BY c.visitorid ORDER BY c.eventtime
    )

),

sequenced_sessions AS (

    SELECT
        {{ dbt_utils.star(ref("src_clicks")) }},
        sum(if(new_session, 1, 0)) OVER w AS session_sequence,
        clickid,
        customer_id,
        session_started,
        session_ended,
        channel
    FROM sessions
    WINDOW w AS (
        PARTITION BY visitorid ORDER BY eventtime
    )
)

SELECT
    visitorid || '_' || cast(session_sequence as varchar) || '_' || cast(clickid as varchar) AS clickid,
    visitorid || '_' || cast(session_sequence as varchar) AS sessionid,
    customer_id,
    session_started,
    session_ended,
    channel,
    {{ dbt_utils.star(ref("src_clicks")) }}
FROM sequenced_sessions
</code>
</pre>

<h2 id="materializations-view-table-ephemeral">Materializations (view, table, ephemeral)</h2>

<p>To manage the performance of your data pipeline, you should wisely choose which
models should be
<a href="https://docs.getdbt.com/docs/build/materializations">materialized</a> as a view,
which ones as a table, or just reused within an existing SQL statement.</p>

<p>As a general guideline, it is wise to make tables of all the data exposed
to actual users, for example dashboards.</p>

<p>Here the sessionization is using a window and adding a <code class="language-plaintext highlighter-rouge">session_id</code> to each
click. You don’t want this expensive operation to be performed every time you
use the <code class="language-plaintext highlighter-rouge">sessionized_clicks</code> object. So it should be persisted as a table
instead of a view.</p>

<p>Just adapt the <code class="language-plaintext highlighter-rouge">sessionized_clicks.sql</code> model and add a config on top:</p>

<pre class="highlight">
<code>{{ config(materialized='table') }}</code>
</pre>

<p>Now, when you execute <code class="language-plaintext highlighter-rouge">dbt run</code>, dbt persists this model as a table by wrapping
your query within a <code class="language-plaintext highlighter-rouge">CREATE TABLE sessionized_clicks AS ...</code> statement.</p>

<p><code class="language-plaintext highlighter-rouge">ephemeral</code> models are not directly built into the database. Instead, dbt
interpolates the code from this model into dependent models as a common table
expression.</p>

<h2 id="is-our-sessionization-logic-correct">Is our sessionization logic correct</h2>

<p>dbt makes it super easy to add <a href="https://docs.getdbt.com/docs/build/tests">data
tests</a>. Let’s say you want to test if
your logic is correct. There are some generic tests like <code class="language-plaintext highlighter-rouge">unique</code> and <code class="language-plaintext highlighter-rouge">not_null</code>
defined in <code class="language-plaintext highlighter-rouge">schema.yml</code>. Tests check if values in a given column are unique or
not null.</p>

<p>The typical errors made when working on the sessionization logic are you messed
something up and your sessions overlap. This should never be the case.</p>

<p>Add a dbt test to validate this. After modifying your model, you can easily
run the test to see if your logic is correct.</p>

<p>Create <code class="language-plaintext highlighter-rouge">assert_no_overlapping_sessions.sql</code> in the <code class="language-plaintext highlighter-rouge">tests</code> folder.</p>

<pre class="highlight">
<code>SELECT
    sc1.session_started,
    sc1.session_ended,
    sc1.session_ended,
    sc2.session_started,
    sc1.visitorid,
    sc2.visitorid
FROM {{ ref('sessionized_clicks') }} sc1
JOIN {{ ref('sessionized_clicks') }} sc2
ON sc1.session_started &gt; sc2.session_ended
AND sc1.session_ended &lt; sc2.session_started
AND sc1.visitorid = sc2.visitorid
</code>
</pre>

<p>Now, you can run <code class="language-plaintext highlighter-rouge">dbt test --select sessionized_clicks</code> to test and validate the
model.</p>

<h2 id="using-dbt-macros">Using dbt macros</h2>

<p>dbt comes with powerful feature called macros. The well-maintained package
<code class="language-plaintext highlighter-rouge">dbt-utils</code> contains macros that can be (re)used across dbt projects.</p>

<p>Starburst maintains <a href="https://github.com/starburstdata/dbt-trino-utils">dbt-trino-utils</a>.
This dbt package contains macros that:</p>

<ul>
  <li>Can be (re)used across dbt projects running on Trino or Starburst databases.</li>
  <li>Define implementations of dispatched macros from other packages that can be
used on Trino or Starburst databases.</li>
</ul>

<p>To use <code class="language-plaintext highlighter-rouge">dbt_utils</code> or <code class="language-plaintext highlighter-rouge">trino_utils</code>, define both packages in the <code class="language-plaintext highlighter-rouge">packages.yml</code>
file:</p>

<div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">packages</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">package</span><span class="pi">:</span> <span class="s">dbt-labs/dbt_utils</span>
    <span class="na">version</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">SEE DBT HUB FOR NEWEST VERSION</span><span class="pi">}</span>
  <span class="pi">-</span> <span class="na">package</span><span class="pi">:</span> <span class="s">starburstdata/trino_utils</span>
    <span class="na">version</span><span class="pi">:</span> <span class="pi">{</span><span class="nv">SEE DBT HUB FOR NEWEST VERSION</span><span class="pi">}</span>
</code></pre></div></div>

<p>Next, tell the supported package to also look for the <code class="language-plaintext highlighter-rouge">trino_utils</code> macros by
adding the relevant dispatches to your <code class="language-plaintext highlighter-rouge">dbt_project.yml</code>:</p>

<div class="language-yml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">dispatch</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="na">macro_namespace</span><span class="pi">:</span> <span class="s">dbt_utils</span>
    <span class="na">search_order</span><span class="pi">:</span> <span class="pi">[</span><span class="s1">'</span><span class="s">trino_utils'</span><span class="pi">,</span> <span class="s1">'</span><span class="s">dbt_utils'</span><span class="pi">]</span>
</code></pre></div></div>

<p>Once packages are defined, run <code class="language-plaintext highlighter-rouge">dbt deps</code> which pulls the packages defined in
<code class="language-plaintext highlighter-rouge">packages.yml</code></p>

<p>A sample use case might be dropping and cleaning databases from objects which
are no longer used. To do so simply run:</p>

<div class="language-shell highlighter-rouge"><div class="highlight"><pre class="highlight"><code>dbt run-operation trino__drop_old_relations
</code></pre></div></div>

<p>To preview the cleaning results, add <code class="language-plaintext highlighter-rouge">--args "{dry_run: true}"</code> at the end of
the command above.</p>

<h2 id="adding-static-data-with-seeds">Adding static data with seeds</h2>

<p>dbt also allows you to insert the content of CSV files (named
<a href="https://docs.getdbt.com/docs/build/seeds">seeds</a> in dbt) directly into a table
using the <code class="language-plaintext highlighter-rouge">dbt seed</code> command. This is particularly useful if you need to keep a
list of mappings or values with your project.</p>

<p>For example, you have a list comprised of campaigns, countries, and age groups.
Columns <code class="language-plaintext highlighter-rouge">campaign_id</code> identifies campaign, <code class="language-plaintext highlighter-rouge">country</code> where the campaign was run,
and the <code class="language-plaintext highlighter-rouge">age_group</code> a target group for the campaign.</p>

<p>You can simply create a csv <code class="language-plaintext highlighter-rouge">campaigns.csv</code> and put it into the <code class="language-plaintext highlighter-rouge">seeds</code> folder.</p>

<pre><code class="language-csv">campaign_id,country,age_group
1,US,"18-24"
2,Europe,"18-24"
3,US,"25-40"
4,Europe,"25-40"
5,US,"41-60"
</code></pre>

<p>After performing the <code class="language-plaintext highlighter-rouge">dbt seed</code> command you can reference the seed in our
models using the familiar syntax:{{ ref(“campaigns”) }}.</p>

<p>Now, it’s time to <a href="/blog_dbt/2022-11-30-dbt3-refresh-your-data-faster.html">make it even faster with incremental refreshing</a>.</p>

          </div>
        </div>
      </div>
    </div>

    <a class="u-url" href="/blog_dbt/2022-11-30-dbt2-first-dbt-data-pipeline.html" hidden></a>
  </article>

</div>



    </div>


<div style="margin-bottom: 50px"></div><footer class="page-footer">
  <div class="container">
    <div class="row">
      <div class="col-md-6">
        <p style="font-weight:900">Resources</b></p>
        <ul>
          <li class="footer-item"><a href="/videos/index.html">Video library</a></li>
          <li class="footer-item"><a href="/glossary.html">Glossary</a></li>
          <li class="footer-item"><a href="https://www.starburst.io/info/oreilly-trino-guide/" target="_blank">Free O'Reilly book - Trino: The Definitive Guide</a></li>
          <li class="footer-item"><a href="https://trino.io/broadcast/" target="_blank">Trino Community Broadcast</a></li>
          <li class="footer-item"><a href="https://trinoforum.org" target="_blank">Trino Forum</a></li>
          <li class="footer-item"><a href="https://blog.starburstdata.com/" target="_blank">Starburst blog</a></li>
        </ul>
      </div>
      <div class="col-md-3">
        <p style="font-weight:900">Contact and more</p>
        <ul>
          <li class="footer-item"><a href="https://www.starburst.io" target="_blank">Starburst</a></li>
          <li class="footer-item"><a href="https://www.starburst.io/#download" target="_blank">Start a trial</a></li>
          <li class="footer-item"><a href="/support.html" target="_blank">Get support</a></li>
          <li class="footer-item"><a href="https://www.starburst.io/contact/" target="_blank">Contact us</a></li>
        </ul>
      </div>
      <div class="col-md-3" style="text-align:right;">
        <a href="https://www.starburst.io/" target="_blank"><img src="/assets/img/logo/starburst-reverse.png" height="60" alt=" Starburst" style="margin-bottom:20px;"></a>
        <li class="footer-item" style="padding-right:10px;">
          <a href="/disclaimers.html#copyright">Copyright © 2017-2022<br> Starburst Data</a>
        </li>
        <li class="footer-item" style="padding-right:10px;">
          <a href="/disclaimers.html#trademarks">Trademark information</a>
        </li>
      </div>
    </div>
    <div class="row">
      <div class="col-md-12 center spacer-30">
          <a href="https://twitter.com/starburstdata" target="_blank" class="footer-icon"><i class="fab fa-twitter"></i></a>
          <a href="https://linkedin.com/starburstdata" target="_blank" class="footer-icon"><i class="fab fa-linkedin"></i></a>
          <a href="https://www.youtube.com/channel/UCXjkuWSO9CV_cSI3Mvo4a4w" target="_blank" class="footer-icon"><i class="fab fa-youtube"></i></a>
          <a href="https://github.com/starburstdata" target="_blank" class="footer-icon"><i class="fab fa-github"></i></a>
      </div>
    </div>
  </div>
</footer>
  <script type="text/javascript" src="/assets/js/jquery.min.js"></script>
  <script type="text/javascript" src="/assets/js/popper.min.js"></script>
  <script type="text/javascript" src="/assets/js/bootstrap.min.js"></script>
  <script type="text/javascript" src="/assets/js/mdb.min.js"></script>
  <script type="text/javascript" src="/assets/js/custom.js"></script>
  <script type="text/javascript" src="/assets/js/algolia.js"></script>
  <script type="text/javascript" src="/assets/js/search-box.js"></script>
  <script type="text/javascript" src="/assets/js/search-results.js"></script>
</body>
</html>
