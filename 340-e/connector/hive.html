

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>10.24. Hive Connector &mdash; Starburst Enterprise Presto</title>
  

  
  

  

  
  
    

  

  
  
    <link rel="stylesheet" href="../_static/css/starburst.css" type="text/css" />
  

  

  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="Starburst Enterprise Presto" href="../index.html"/>
        <link rel="up" title="10. Connectors" href="../connector.html"/>
        <link rel="next" title="10.26. Hive Connector Security Configuration" href="hive-security.html"/>
        <link rel="prev" title="10.23. Google Sheets Connector" href="googlesheets.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../index.html" class="icon icon-home"> Starburst Enterprise Presto
          

          
          </a>

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
                <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../overview.html">1. Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">2. Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../client.html">3. Clients</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mission-control.html">4. Mission Control</a></li>
<li class="toctree-l1"><a class="reference internal" href="../aws.html">5. Amazon Web Services</a></li>
<li class="toctree-l1"><a class="reference internal" href="../kubernetes.html">6. Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../security.html">7. Security</a></li>
<li class="toctree-l1"><a class="reference internal" href="../admin.html">8. Administration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimizer.html">9. Query Optimizer</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../connector.html">10. Connectors</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="starburst-connectors.html">10.1. Starburst connectors overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-db2.html">10.2. Starburst IBM DB2 connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-generic-jdbc.html">10.3. Starburst Generic JDBC connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-hive.html">10.4. Starburst Hive connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-hive-security.html">10.5. Starburst Hive connector security</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-hive-ibm-cos.html">10.6. IBM Cloud Object Storage support for the Hive connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-hive-mapr.html">10.7. MapR Hive support</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-hive-cdp.html">10.8. Cloudera Data Platform support</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-delta-lake.html">10.9. Starburst Delta Lake connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-kafka.html">10.10. Starburst Kafka connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-mysql.html">10.11. Starburst MySQL connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-oracle.html">10.12. Starburst Oracle connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-postgresql.html">10.13. Starburst PostgreSQL connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-snowflake.html">10.14. Starburst Snowflake connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-sqlserver.html">10.15. Starburst SQL Server connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-teradata.html">10.16. Starburst Teradata connectors</a></li>
<li class="toctree-l2"><a class="reference internal" href="accumulo.html">10.17. Accumulo Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="bigquery.html">10.18. BigQuery Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="blackhole.html">10.19. Black Hole Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="cassandra.html">10.20. Cassandra Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="druid.html">10.21. Druid Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="elasticsearch.html">10.22. Elasticsearch Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="googlesheets.html">10.23. Google Sheets Connector</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">10.24. Hive Connector</a><ul>
<li class="toctree-l3"><a class="reference internal" href="hive-security.html">10.26. Security</a></li>
<li class="toctree-l3"><a class="reference internal" href="hive-s3.html">Amazon S3</a></li>
<li class="toctree-l3"><a class="reference internal" href="hive-azure.html">10.28. Azure Storage</a></li>
<li class="toctree-l3"><a class="reference internal" href="hive-gcs-tutorial.html">10.25. GCS Tutorial</a></li>
<li class="toctree-l3"><a class="reference internal" href="hive-caching.html">10.27. Storage Caching</a></li>
<li class="toctree-l3"><a class="reference internal" href="hive-alluxio.html">10.29. Alluxio</a></li>
<li class="toctree-l3"><a class="reference internal" href="#overview">Overview</a></li>
<li class="toctree-l3"><a class="reference internal" href="#requirements">Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#supported-file-types">Supported File Types</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#metastore-configuration-for-avro">Metastore Configuration for Avro</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#supported-table-types">Supported Table Types</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#transactional-and-acid-tables">Transactional and ACID Tables</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#materialized-views">Materialized Views</a></li>
<li class="toctree-l3"><a class="reference internal" href="#configuration">Configuration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#multiple-hive-clusters">Multiple Hive Clusters</a></li>
<li class="toctree-l4"><a class="reference internal" href="#hdfs-configuration">HDFS Configuration</a></li>
<li class="toctree-l4"><a class="reference internal" href="#hdfs-username-and-permissions">HDFS Username and Permissions</a></li>
<li class="toctree-l4"><a class="reference internal" href="#accessing-hadoop-clusters-protected-with-kerberos-authentication">Accessing Hadoop clusters protected with Kerberos authentication</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hive-configuration-properties">Hive Configuration Properties</a></li>
<li class="toctree-l3"><a class="reference internal" href="#metastore-configuration-properties">Metastore Configuration Properties</a></li>
<li class="toctree-l3"><a class="reference internal" href="#thrift-metastore-configuration-properties">Thrift Metastore Configuration Properties</a></li>
<li class="toctree-l3"><a class="reference internal" href="#aws-glue-catalog-configuration-properties">AWS Glue Catalog Configuration Properties</a></li>
<li class="toctree-l3"><a class="reference internal" href="#google-cloud-storage-configuration">Google Cloud Storage Configuration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#gcs-configuration-properties">GCS Configuration properties</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#table-statistics">Table Statistics</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#updating-table-and-partition-statistics">Updating table and partition statistics</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#schema-evolution">Schema Evolution</a></li>
<li class="toctree-l3"><a class="reference internal" href="#avro-schema-evolution">Avro Schema Evolution</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#limitations">Limitations</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#procedures">Procedures</a></li>
<li class="toctree-l3"><a class="reference internal" href="#special-columns">Special Columns</a></li>
<li class="toctree-l3"><a class="reference internal" href="#special-tables">Special Tables</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#table-properties">Table Properties</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#examples">Examples</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#cleaning-up">Cleaning up</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#hive-connector-limitations">Hive Connector Limitations</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#hive-3-related-limitations">Hive 3 Related Limitations</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="hive-gcs-tutorial.html">10.25. Hive Connector GCS Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="hive-security.html">10.26. Hive Connector Security Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="hive-caching.html">10.27. Hive Connector Storage Caching</a></li>
<li class="toctree-l2"><a class="reference internal" href="hive-azure.html">10.28. Hive Connector with Azure Storage</a></li>
<li class="toctree-l2"><a class="reference internal" href="hive-alluxio.html">10.29. Hive Connector with Alluxio</a></li>
<li class="toctree-l2"><a class="reference internal" href="jmx.html">10.30. JMX Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="kafka.html">10.31. Kafka Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="kafka-tutorial.html">10.32. Kafka Connector Tutorial</a></li>
<li class="toctree-l2"><a class="reference internal" href="kinesis.html">10.33. Kinesis Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="kudu.html">10.34. Kudu Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="localfile.html">10.35. Local File Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="memory.html">10.36. Memory Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="mongodb.html">10.37. MongoDB Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="memsql.html">10.38. MemSQL Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="mysql.html">10.39. MySQL Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="oracle.html">10.40. Oracle Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="phoenix.html">10.41. Phoenix Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="pinot.html">10.42. Pinot Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="postgresql.html">10.43. PostgreSQL Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="prometheus.html">10.44. Prometheus Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="redis.html">10.45. Redis Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="redshift.html">10.46. Redshift Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="sqlserver.html">10.47. SQL Server Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="system.html">10.48. System Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="thrift.html">10.49. Thrift Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="tpcds.html">10.50. TPCDS Connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="tpch.html">10.51. TPCH Connector</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../functions.html">11. Functions and Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../language.html">12. SQL Language</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sql.html">13. SQL Statement Syntax</a></li>
<li class="toctree-l1"><a class="reference internal" href="../migration.html">14. Migration</a></li>
<li class="toctree-l1"><a class="reference internal" href="../develop.html">15. Developer Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versions.html">16. Versions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release.html">17. Release Notes</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../404.html">404 - Nothing to See Here</a></li>
</ul>

            
          

        </div>
        <div style="margin-top: 1em; margin-left: 2em;">
          Version <a href="../versions.html">340-e STS and others</a>
          <br><br>
        <span>
  <select name="versions" id="versions" onChange="window.location.href=this.value">
    <option value="./">Choose another version</option>
    <option value="/338-e/">Latest LTS (338-e)</option>
    <option value="/332-e/">332-e LTS</option>
    <option value="/323-e/">323-e LTS</option>
    <option value="/340-e/">Latest STS (340-e)</option>
    <option value="/339-e/">339-e STS </option>
  </select>
</span>
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="https://www.starburstdata.com/">
          <img class="logo"style="background-color: transparent; border-radius: 0%; width: auto; height: auto ;padding: 0px;"
          src="../_static/img/starburst-darkbg.png"/></a>
        <span class="optional">
          <a href="../index.html">Starburst Enterprise Presto</a>
          <a href="../versions.html" style="font-size: small;margin-left: 0.5em;">340-e STS and others</a>
          <a href="https://www.starburstdata.com/oreilly-presto-guide-download/?utm_campaign=O%27Reilly%20Presto%20Book&utm_source=starburst&utm_medium=docs">
            <img class="logo"style="background-color: transparent; border-radius: 0%; width: auto; height: auto ;padding: 0px; margin-left: 0.5em;"
          src="../_static/img/ptdg-banner.png"/></a>
          </span>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          

 



<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Docs</a> &raquo;</li>
      
        <li><a href="../connector.html"><span class="section-number">10. </span>Connectors</a> &raquo;</li>
      
    <li><span class="section-number">10.24. </span>Hive Connector</li>
    <li class="wy-breadcrumbs-aside">
    </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="hive-connector">
<h1><span class="section-number">10.24. </span>Hive Connector<a class="headerlink" href="#hive-connector" title="Permalink to this headline">#</a></h1>
<div class="toctree-wrapper compound">
</div>
<div class="section" id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this headline">#</a></h2>
<p>The Hive connector allows querying data stored in an
<a class="reference external" href="https://hive.apache.org/">Apache Hive</a>
data warehouse. Hive is a combination of three components:</p>
<ul class="simple">
<li><p>Data files in varying formats, that are typically stored in the
Hadoop Distributed File System (HDFS) or in object storage systems
such as Amazon S3.</p></li>
<li><p>Metadata about how the data files are mapped to schemas and tables.
This metadata is stored in a database, such as MySQL, and is accessed
via the Hive metastore service.</p></li>
<li><p>A query language called HiveQL. This query language is executed
on a distributed computing framework such as MapReduce or Tez.</p></li>
</ul>
<p>Presto only uses the first two components: the data and the metadata.
It does not use HiveQL or any part of Hiveâ€™s execution environment.</p>
</div>
<div class="section" id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline">#</a></h2>
<p>The Hive connector requires a Hive metastore service (HMS), or a compatible
implementation of the Hive metastore, such as
<a class="reference external" href="https://aws.amazon.com/glue/">AWS Glue Data Catalog</a>.</p>
<p>Apache Hadoop 2.x and 3.x are supported, along with derivative distributions,
including Cloudera CDH 5 and Hortonworks Data Platform (HDP).</p>
<p>Many distributed storage systems including HDFS,
<a class="reference internal" href="hive-s3.html"><span class="doc">Amazon S3</span></a> or S3-compatible systems,
<a class="reference external" href="#google-cloud-storage-configuration">Google Cloud Storage</a>,
and <a class="reference internal" href="hive-azure.html"><span class="doc">Azure Storage</span></a>.</p>
<p>The coordinator and all workers must have network access to the Hive metastore
and the storage system.</p>
</div>
<div class="section" id="supported-file-types">
<h2>Supported File Types<a class="headerlink" href="#supported-file-types" title="Permalink to this headline">#</a></h2>
<p>The following file types are supported for the Hive connector:</p>
<ul class="simple">
<li><p>ORC</p></li>
<li><p>Parquet</p></li>
<li><p>Avro</p></li>
<li><p>RCText (RCFile using <code class="docutils literal notranslate"><span class="pre">ColumnarSerDe</span></code>)</p></li>
<li><p>RCBinary (RCFile using <code class="docutils literal notranslate"><span class="pre">LazyBinaryColumnarSerDe</span></code>)</p></li>
<li><p>SequenceFile</p></li>
<li><p>JSON (using <code class="docutils literal notranslate"><span class="pre">org.apache.hive.hcatalog.data.JsonSerDe</span></code>)</p></li>
<li><p>CSV (using <code class="docutils literal notranslate"><span class="pre">org.apache.hadoop.hive.serde2.OpenCSVSerde</span></code>)</p></li>
<li><p>TextFile</p></li>
</ul>
<div class="section" id="metastore-configuration-for-avro">
<h3>Metastore Configuration for Avro<a class="headerlink" href="#metastore-configuration-for-avro" title="Permalink to this headline">#</a></h3>
<p>In order to enable first-class support for Avro tables when using
Hive 3.x, you need to add the following property definition to the Hive metastore
configuration file <code class="docutils literal notranslate"><span class="pre">hive-site.xml</span></code> (and restart the metastore service):</p>
<div class="highlight-xml notranslate"><div class="highlight"><pre><span></span><span class="nt">&lt;property&gt;</span>
     <span class="c">&lt;!-- https://community.hortonworks.com/content/supportkb/247055/errorjavalangunsupportedoperationexception-storage.html --&gt;</span>
     <span class="nt">&lt;name&gt;</span>metastore.storage.schema.reader.impl<span class="nt">&lt;/name&gt;</span>
     <span class="nt">&lt;value&gt;</span>org.apache.hadoop.hive.metastore.SerDeStorageSchemaReader<span class="nt">&lt;/value&gt;</span>
 <span class="nt">&lt;/property&gt;</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="supported-table-types">
<h2>Supported Table Types<a class="headerlink" href="#supported-table-types" title="Permalink to this headline">#</a></h2>
<div class="section" id="transactional-and-acid-tables">
<h3>Transactional and ACID Tables<a class="headerlink" href="#transactional-and-acid-tables" title="Permalink to this headline">#</a></h3>
<p>When connecting to a Hive metastore version 3.x, the Hive connector supports reading
from insert-only and ACID tables, with full support for partitioning and bucketing.
Writing to and creation of transactional tables is not supported.</p>
<p>ACID tables created with <a class="reference external" href="https://cwiki.apache.org/confluence/display/Hive/Streaming+Data+Ingest">Hive Streaming Ingest</a>
are not supported.</p>
</div>
</div>
<div class="section" id="materialized-views">
<h2>Materialized Views<a class="headerlink" href="#materialized-views" title="Permalink to this headline">#</a></h2>
<p>The Hive connector supports reading from Hive materialized views.
In Presto, these views are presented as regular, read-only tables.</p>
</div>
<div class="section" id="configuration">
<h2>Configuration<a class="headerlink" href="#configuration" title="Permalink to this headline">#</a></h2>
<p>Create <code class="docutils literal notranslate"><span class="pre">etc/catalog/hive.properties</span></code> with the following contents
to mount the <code class="docutils literal notranslate"><span class="pre">hive-hadoop2</span></code> connector as the <code class="docutils literal notranslate"><span class="pre">hive</span></code> catalog,
replacing <code class="docutils literal notranslate"><span class="pre">example.net:9083</span></code> with the correct host and port
for your Hive metastore Thrift service:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>connector.name=hive-hadoop2
hive.metastore.uri=thrift://example.net:9083
</pre></div>
</div>
<div class="section" id="multiple-hive-clusters">
<h3>Multiple Hive Clusters<a class="headerlink" href="#multiple-hive-clusters" title="Permalink to this headline">#</a></h3>
<p>You can have as many catalogs as you need, so if you have additional
Hive clusters, simply add another properties file to <code class="docutils literal notranslate"><span class="pre">etc/catalog</span></code>
with a different name, making sure it ends in <code class="docutils literal notranslate"><span class="pre">.properties</span></code>. For
example, if you name the property file <code class="docutils literal notranslate"><span class="pre">sales.properties</span></code>, Presto
creates a catalog named <code class="docutils literal notranslate"><span class="pre">sales</span></code> using the configured connector.</p>
</div>
<div class="section" id="hdfs-configuration">
<h3>HDFS Configuration<a class="headerlink" href="#hdfs-configuration" title="Permalink to this headline">#</a></h3>
<p>For basic setups, Presto configures the HDFS client automatically and
does not require any configuration files. In some cases, such as when using
federated HDFS or NameNode high availability, it is necessary to specify
additional HDFS client options in order to access your HDFS cluster. To do so,
add the <code class="docutils literal notranslate"><span class="pre">hive.config.resources</span></code> property to reference your HDFS config files:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>hive.config.resources=/etc/hadoop/conf/core-site.xml,/etc/hadoop/conf/hdfs-site.xml
</pre></div>
</div>
<p>Only specify additional configuration files if necessary for your setup.
We recommend reducing the configuration files to have the minimum
set of required properties, as additional properties may cause problems.</p>
<p>The configuration files must exist on all Presto nodes. If you are
referencing existing Hadoop config files, make sure to copy them to
any Presto nodes that are not running Hadoop.</p>
</div>
<div class="section" id="hdfs-username-and-permissions">
<h3>HDFS Username and Permissions<a class="headerlink" href="#hdfs-username-and-permissions" title="Permalink to this headline">#</a></h3>
<p>Before running any <code class="docutils literal notranslate"><span class="pre">CREATE</span> <span class="pre">TABLE</span></code> or <code class="docutils literal notranslate"><span class="pre">CREATE</span> <span class="pre">TABLE</span> <span class="pre">AS</span></code> statements
for Hive tables in Presto, you need to check that the user Presto is
using to access HDFS has access to the Hive warehouse directory. The Hive
warehouse directory is specified by the configuration variable
<code class="docutils literal notranslate"><span class="pre">hive.metastore.warehouse.dir</span></code> in <code class="docutils literal notranslate"><span class="pre">hive-site.xml</span></code>, and the default
value is <code class="docutils literal notranslate"><span class="pre">/user/hive/warehouse</span></code>.</p>
<p>When not using Kerberos with HDFS, Presto accesses HDFS using the
OS user of the Presto process. For example, if Presto is running as
<code class="docutils literal notranslate"><span class="pre">nobody</span></code>, it accesses HDFS as <code class="docutils literal notranslate"><span class="pre">nobody</span></code>. You can override this
username by setting the <code class="docutils literal notranslate"><span class="pre">HADOOP_USER_NAME</span></code> system property in the
Presto <a class="reference internal" href="../installation/deployment.html#presto-jvm-config"><span class="std std-ref">JVM Config</span></a>, replacing <code class="docutils literal notranslate"><span class="pre">hdfs_user</span></code> with the
appropriate username:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>-DHADOOP_USER_NAME=hdfs_user
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">hive</span></code> user generally works, since Hive is often started with
the <code class="docutils literal notranslate"><span class="pre">hive</span></code> user and this user has access to the Hive warehouse.</p>
<p>Whenever you change the user Presto is using to access HDFS, remove
<code class="docutils literal notranslate"><span class="pre">/tmp/presto-*</span></code> on HDFS, as the new user may not have access to
the existing temporary directories.</p>
</div>
<div class="section" id="accessing-hadoop-clusters-protected-with-kerberos-authentication">
<h3>Accessing Hadoop clusters protected with Kerberos authentication<a class="headerlink" href="#accessing-hadoop-clusters-protected-with-kerberos-authentication" title="Permalink to this headline">#</a></h3>
<p>Kerberos authentication is supported for both HDFS and the Hive metastore.
However, Kerberos authentication by ticket cache is not yet supported.</p>
<p>The properties that apply to Hive connector security are listed in the
<a class="reference internal" href="#hive-configuration-properties">Hive Configuration Properties</a> table. Please see the
<a class="reference internal" href="hive-security.html"><span class="doc">Hive Connector Security Configuration</span></a> section for a more detailed discussion of the
security options in the Hive connector.</p>
</div>
</div>
<div class="section" id="hive-configuration-properties">
<h2>Hive Configuration Properties<a class="headerlink" href="#hive-configuration-properties" title="Permalink to this headline">#</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 41%" />
<col style="width: 49%" />
<col style="width: 10%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Default</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.config.resources</span></code></p></td>
<td><p>An optional comma-separated list of HDFS
configuration files. These files must exist on the
machines running Presto. Only specify this if
absolutely necessary to access HDFS.
Example: <code class="docutils literal notranslate"><span class="pre">/etc/hdfs-site.xml</span></code></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.recursive-directories</span></code></p></td>
<td><p>Enable reading data from subdirectories of table or
partition locations. If disabled, subdirectories are
ignored. This is equivalent to the
<code class="docutils literal notranslate"><span class="pre">hive.mapred.supports.subdirectories</span></code> property in Hive.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.ignore-absent-partitions</span></code></p></td>
<td><p>Ignore partitions when the file system location does not
exist rather than failing the query. This skips data that
may be expected to be part of the table.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.storage-format</span></code></p></td>
<td><p>The default file format used when creating new tables.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ORC</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.compression-codec</span></code></p></td>
<td><p>The compression codec to use when writing files.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GZIP</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.force-local-scheduling</span></code></p></td>
<td><p>Force splits to be scheduled on the same node as the Hadoop
DataNode process serving the split data.  This is useful for
installations where Presto is collocated with every
DataNode.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.respect-table-format</span></code></p></td>
<td><p>Should new partitions be written using the existing table
format or the default Presto format?</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.immutable-partitions</span></code></p></td>
<td><p>Can new data be inserted into existing partitions?</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.create-empty-bucket-files</span></code></p></td>
<td><p>Should empty files be created for buckets that have no data?</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.max-partitions-per-writers</span></code></p></td>
<td><p>Maximum number of partitions per writer.</p></td>
<td><p>100</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.max-partitions-per-scan</span></code></p></td>
<td><p>Maximum number of partitions for a single table scan.</p></td>
<td><p>100,000</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.hdfs.authentication.type</span></code></p></td>
<td><p>HDFS authentication type.
Possible values are <code class="docutils literal notranslate"><span class="pre">NONE</span></code> or <code class="docutils literal notranslate"><span class="pre">KERBEROS</span></code>.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">NONE</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.hdfs.impersonation.enabled</span></code></p></td>
<td><p>Enable HDFS end user impersonation.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.hdfs.presto.principal</span></code></p></td>
<td><p>The Kerberos principal that Presto will use when connecting
to HDFS.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.hdfs.presto.keytab</span></code></p></td>
<td><p>HDFS client keytab location.</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.security</span></code></p></td>
<td><p>See <a class="reference internal" href="hive-security.html"><span class="doc">Hive Connector Security Configuration</span></a>.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">security.config-file</span></code></p></td>
<td><p>Path of config file to use when <code class="docutils literal notranslate"><span class="pre">hive.security=file</span></code>.
See <a class="reference internal" href="hive-security.html#hive-file-based-authorization"><span class="std std-ref">File Based Authorization</span></a> for details.</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.non-managed-table-writes-enabled</span></code></p></td>
<td><p>Enable writes to non-managed (external) Hive tables.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.non-managed-table-creates-enabled</span></code></p></td>
<td><p>Enable creating non-managed (external) Hive tables.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.collect-column-statistics-on-write</span></code></p></td>
<td><p>Enables automatic column level statistics collection
on write. See <a class="reference external" href="#table-statistics">Table Statistics</a> for
details.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3select-pushdown.enabled</span></code></p></td>
<td><p>Enable query pushdown to AWS S3 Select service.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.s3select-pushdown.max-connections</span></code></p></td>
<td><p>Maximum number of simultaneously open connections to S3 for
<a class="reference internal" href="hive-s3.html#s3selectpushdown"><span class="std std-ref">S3 Select Pushdown</span></a>.</p></td>
<td><p>500</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.file-status-cache-tables</span></code></p></td>
<td><p>Cache directory listing for specific tables. Examples:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">fruit.apple,fruit.orange</span></code> to cache listings only for
tables <code class="docutils literal notranslate"><span class="pre">apple</span></code> and <code class="docutils literal notranslate"><span class="pre">orange</span></code> in schema <code class="docutils literal notranslate"><span class="pre">fruit</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">fruit.*,vegetable.*</span></code> to cache listings for all tables
in schemas <code class="docutils literal notranslate"><span class="pre">fruit</span></code> and <code class="docutils literal notranslate"><span class="pre">vegetable</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">*</span></code> to cache listings for all tables in all schemas</p></li>
</ul>
</td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.file-status-cache-size</span></code></p></td>
<td><p>Maximum total number of cached file status entries.</p></td>
<td><p>1,000,000</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.file-status-cache-expire-time</span></code></p></td>
<td><p>How long a cached directory listing should be considered
valid.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">1m</span></code></p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="metastore-configuration-properties">
<h2>Metastore Configuration Properties<a class="headerlink" href="#metastore-configuration-properties" title="Permalink to this headline">#</a></h2>
<p>The required Hive metastore can be configured with a number of properties.
Specific properties can be used to further configure the
<a class="reference external" href="#thrift-metastore-configuration-properties">Thrift</a> or
<a class="reference external" href="#aws-glue-catalog-configuration-properties">Glue</a> metastore.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 35%" />
<col style="width: 54%" />
<col style="width: 11%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Default</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore</span></code></p></td>
<td><p>The type of Hive metastore to use. Presto currently supports
the default Hive Thrift metastore (<code class="docutils literal notranslate"><span class="pre">thrift</span></code>), and the AWS
Glue Catalog (<code class="docutils literal notranslate"><span class="pre">glue</span></code>) as metadata sources.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">thrift</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore-cache-ttl</span></code></p></td>
<td><p>Duration how long cached metastore data should be considered
valid.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">0s</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore-cache-maximum-size</span></code></p></td>
<td><p>Hive metastore cache maximum size.</p></td>
<td><p>10000</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore-refresh-interval</span></code></p></td>
<td><p>Asynchronously refresh cached metastore data after access
if it is older than this but is not yet expired, allowing
subsequent accesses to see fresh data.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore-refresh-max-threads</span></code></p></td>
<td><p>Maximum threads used to refresh cached metastore data.</p></td>
<td><p>100</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="thrift-metastore-configuration-properties">
<h2>Thrift Metastore Configuration Properties<a class="headerlink" href="#thrift-metastore-configuration-properties" title="Permalink to this headline">#</a></h2>
<table class="docutils align-default">
<colgroup>
<col style="width: 46%" />
<col style="width: 45%" />
<col style="width: 9%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Default</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.uri</span></code></p></td>
<td><p>The URI(s) of the Hive metastore to connect to using the
Thrift protocol. If multiple URIs are provided, the first
URI is used by default, and the rest of the URIs are
fallback metastores. This property is required.
Example: <code class="docutils literal notranslate"><span class="pre">thrift://192.0.2.3:9083</span></code> or
<code class="docutils literal notranslate"><span class="pre">thrift://192.0.2.3:9083,thrift://192.0.2.4:9083</span></code></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.username</span></code></p></td>
<td><p>The username Presto uses to access the Hive metastore.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.authentication.type</span></code></p></td>
<td><p>Hive metastore authentication type.
Possible values are <code class="docutils literal notranslate"><span class="pre">NONE</span></code> or <code class="docutils literal notranslate"><span class="pre">KERBEROS</span></code>
(defaults to <code class="docutils literal notranslate"><span class="pre">NONE</span></code>).</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.thrift.impersonation.enabled</span></code></p></td>
<td><p>Enable Hive metastore end user impersonation.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.thrift.delegation-token.cache-ttl</span></code></p></td>
<td><p>Time to live delegation token cache for metastore.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">1h</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.thrift.delegation-token.cache-maximum-size</span></code></p></td>
<td><p>Delegation token cache maximum size.</p></td>
<td><p>1,000</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.thrift.client.ssl.enabled</span></code></p></td>
<td><p>Use SSL when connecting to metastore.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.thrift.client.ssl.key</span></code></p></td>
<td><p>Path to PEM private key and client certificate (key store).</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.thrift.client.ssl.key-password</span></code></p></td>
<td><p>Password for the PEM private key.</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.thrift.client.ssl.trust-certificate</span></code></p></td>
<td><p>Path to the PEM server certificate chain (trust store).
Required when SSL is enabled.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.service.principal</span></code></p></td>
<td><p>The Kerberos principal of the Hive metastore service.</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.client.principal</span></code></p></td>
<td><p>The Kerberos principal that Presto uses when connecting
to the Hive metastore service.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.client.keytab</span></code></p></td>
<td><p>Hive metastore client keytab location.</p></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="aws-glue-catalog-configuration-properties">
<h2>AWS Glue Catalog Configuration Properties<a class="headerlink" href="#aws-glue-catalog-configuration-properties" title="Permalink to this headline">#</a></h2>
<p>In order to use a Glue catalog, ensure to configure the metastore with
<code class="docutils literal notranslate"><span class="pre">hive.metastore=glue</span></code> and provide further details with the following
properties:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 46%" />
<col style="width: 54%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.region</span></code></p></td>
<td><p>AWS region of the Glue Catalog. This is required when not
running in EC2, or when the catalog is in a different region.
Example: <code class="docutils literal notranslate"><span class="pre">us-east-1</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.endpoint-url</span></code></p></td>
<td><p>Glue API endpoint URL (optional).
Example: <code class="docutils literal notranslate"><span class="pre">https://glue.us-east-1.amazonaws.com</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.pin-client-to-current-region</span></code></p></td>
<td><p>Pin Glue requests to the same region as the EC2 instance
where Presto is running, defaults to <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.max-connections</span></code></p></td>
<td><p>Max number of concurrent connections to Glue,
defaults to <code class="docutils literal notranslate"><span class="pre">5</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.default-warehouse-dir</span></code></p></td>
<td><p>Default warehouse directory for schemas created without an
explicit <code class="docutils literal notranslate"><span class="pre">location</span></code> property.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.catalogid</span></code></p></td>
<td><p>Glue Catalog ID (optional).</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.aws-credentials-provider</span></code></p></td>
<td><p>Fully qualified name of the Java class to use for obtaining
AWS credentials. Can be used to supply a custom credentials
provider.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.aws-access-key</span></code></p></td>
<td><p>AWS access key to use to connect to the Glue Catalog. If
specified along with <code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.aws-secret-key</span></code>,
this parameter takes precedence over
<code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.iam-role</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.aws-secret-key</span></code></p></td>
<td><p>AWS secret key to use to connect to the Glue Catalog. If
specified along with <code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.aws-access-key</span></code>,
this parameter takes precedence over
<code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.iam-role</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.catalogid</span></code></p></td>
<td><p>The ID of the Glue Catalog in which the metadata database
resides.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.iam-role</span></code></p></td>
<td><p>ARN of an IAM role to assume when connecting to the Glue
Catalog.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.external-id</span></code></p></td>
<td><p>External ID for the IAM role trust policy when connecting
to the Glue Catalog.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.partitions-segments</span></code></p></td>
<td><p>Number of segments for partitioned Glue tables, defaults
to <code class="docutils literal notranslate"><span class="pre">5</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.metastore.glue.get-partition-threads</span></code></p></td>
<td><p>Number of threads for parallel partition fetches from Glue,
defaults to <code class="docutils literal notranslate"><span class="pre">20</span></code>.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="google-cloud-storage-configuration">
<h2>Google Cloud Storage Configuration<a class="headerlink" href="#google-cloud-storage-configuration" title="Permalink to this headline">#</a></h2>
<p>The Hive connector can access data stored in GCS, using the <code class="docutils literal notranslate"><span class="pre">gs://</span></code> URI prefix.
Please refer to the <a class="reference internal" href="hive-gcs-tutorial.html"><span class="doc">Hive Connector GCS Tutorial</span></a> for step-by-step instructions.</p>
<div class="section" id="gcs-configuration-properties">
<h3>GCS Configuration properties<a class="headerlink" href="#gcs-configuration-properties" title="Permalink to this headline">#</a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 40%" />
<col style="width: 60%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hive.gcs.json-key-file-path</span></code></p></td>
<td><p>JSON key file used to authenticate with Google Cloud Storage.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">hive.gcs.use-access-token</span></code></p></td>
<td><p>Use client-provided OAuth token to access Google Cloud Storage.
This is mutually exclusive with a global JSON key file.</p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="table-statistics">
<h2>Table Statistics<a class="headerlink" href="#table-statistics" title="Permalink to this headline">#</a></h2>
<p>When writing data, the Hive connector always collects basic statistics
(<code class="docutils literal notranslate"><span class="pre">numFiles</span></code>, <code class="docutils literal notranslate"><span class="pre">numRows</span></code>, <code class="docutils literal notranslate"><span class="pre">rawDataSize</span></code>, <code class="docutils literal notranslate"><span class="pre">totalSize</span></code>)
and by default will also collect column level statistics:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 16%" />
<col style="width: 84%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Column Type</p></th>
<th class="head"><p>Collectible Statistics</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">TINYINT</span></code></p></td>
<td><p>number of nulls, number of distinct values, min/max values</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">SMALLINT</span></code></p></td>
<td><p>number of nulls, number of distinct values, min/max values</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">INTEGER</span></code></p></td>
<td><p>number of nulls, number of distinct values, min/max values</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">BIGINT</span></code></p></td>
<td><p>number of nulls, number of distinct values, min/max values</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code></p></td>
<td><p>number of nulls, number of distinct values, min/max values</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">REAL</span></code></p></td>
<td><p>number of nulls, number of distinct values, min/max values</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">DECIMAL</span></code></p></td>
<td><p>number of nulls, number of distinct values, min/max values</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">DATE</span></code></p></td>
<td><p>number of nulls, number of distinct values, min/max values</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">TIMESTAMP</span></code></p></td>
<td><p>number of nulls, number of distinct values, min/max values</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code></p></td>
<td><p>number of nulls, number of distinct values</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">CHAR</span></code></p></td>
<td><p>number of nulls, number of distinct values</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">VARBINARY</span></code></p></td>
<td><p>number of nulls</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">BOOLEAN</span></code></p></td>
<td><p>number of nulls, number of true/false values</p></td>
</tr>
</tbody>
</table>
<div class="section" id="updating-table-and-partition-statistics">
<span id="hive-analyze"></span><h3>Updating table and partition statistics<a class="headerlink" href="#updating-table-and-partition-statistics" title="Permalink to this headline">#</a></h3>
<p>If your queries are complex and include joining large data sets,
running <a class="reference internal" href="../sql/analyze.html"><span class="doc">ANALYZE</span></a> on tables/partitions may improve query performance
by collecting statistical information about the data.</p>
<p>When analyzing a partitioned table, the partitions to analyze can be specified
via the optional <code class="docutils literal notranslate"><span class="pre">partitions</span></code> property, which is an array containing
the values of the partition keys in the order they are declared in the table schema:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">ANALYZE</span> <span class="k">table_name</span> <span class="k">WITH</span> <span class="p">(</span>
    <span class="n">partitions</span> <span class="o">=</span> <span class="nb">ARRAY</span><span class="p">[</span>
        <span class="nb">ARRAY</span><span class="p">[</span><span class="s1">&#39;p1_value1&#39;</span><span class="p">,</span> <span class="s1">&#39;p1_value2&#39;</span><span class="p">],</span>
        <span class="nb">ARRAY</span><span class="p">[</span><span class="s1">&#39;p2_value1&#39;</span><span class="p">,</span> <span class="s1">&#39;p2_value2&#39;</span><span class="p">]])</span>
</pre></div>
</div>
<p>This query will collect statistics for two partitions with keys
<code class="docutils literal notranslate"><span class="pre">p1_value1,</span> <span class="pre">p1_value2</span></code> and <code class="docutils literal notranslate"><span class="pre">p2_value1,</span> <span class="pre">p2_value2</span></code>.</p>
<p>On wide tables, collecting statistics for all columns can be expensive and can have a
detrimental effect on query planning. It is also typically unnecessary - statistics are
only useful on specific columns, like join keys, predicates, grouping keys. One can
specify a subset of columns to be analyzed via the optional <code class="docutils literal notranslate"><span class="pre">columns</span></code> property:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">ANALYZE</span> <span class="k">table_name</span> <span class="k">WITH</span> <span class="p">(</span>
    <span class="n">partitions</span> <span class="o">=</span> <span class="nb">ARRAY</span><span class="p">[</span><span class="nb">ARRAY</span><span class="p">[</span><span class="s1">&#39;p2_value1&#39;</span><span class="p">,</span> <span class="s1">&#39;p2_value2&#39;</span><span class="p">]],</span>
    <span class="n">columns</span> <span class="o">=</span> <span class="nb">ARRAY</span><span class="p">[</span><span class="s1">&#39;col_1&#39;</span><span class="p">,</span> <span class="s1">&#39;col_2&#39;</span><span class="p">])</span>
</pre></div>
</div>
<p>This query collects statistics for columns <code class="docutils literal notranslate"><span class="pre">col_1</span></code> and <code class="docutils literal notranslate"><span class="pre">col_2</span></code> for the partition
with keys <code class="docutils literal notranslate"><span class="pre">p2_value1,</span> <span class="pre">p2_value2</span></code>.</p>
<p>Note that if statistics were previously collected for all columns, they need to be dropped
before re-analyzing just a subset:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CALL</span> <span class="k">system</span><span class="p">.</span><span class="n">drop_stats</span><span class="p">(</span><span class="k">schema_name</span><span class="p">,</span> <span class="k">table_name</span><span class="p">)</span>
</pre></div>
</div>
<p>You can also drop statistics for selected partitions only:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CALL</span> <span class="k">system</span><span class="p">.</span><span class="n">drop_stats</span><span class="p">(</span><span class="k">schema_name</span><span class="p">,</span> <span class="k">table_name</span><span class="p">,</span> <span class="nb">ARRAY</span><span class="p">[</span><span class="nb">ARRAY</span><span class="p">[</span><span class="s1">&#39;p2_value1&#39;</span><span class="p">,</span> <span class="s1">&#39;p2_value2&#39;</span><span class="p">]])</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="schema-evolution">
<h2>Schema Evolution<a class="headerlink" href="#schema-evolution" title="Permalink to this headline">#</a></h2>
<p>Hive allows the partitions in a table to have a different schema than the
table. This occurs when the column types of a table are changed after
partitions already exist (that use the original column types). The Hive
connector supports this by allowing the same conversions as Hive:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">varchar</span></code> to and from <code class="docutils literal notranslate"><span class="pre">tinyint</span></code>, <code class="docutils literal notranslate"><span class="pre">smallint</span></code>, <code class="docutils literal notranslate"><span class="pre">integer</span></code> and <code class="docutils literal notranslate"><span class="pre">bigint</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">real</span></code> to <code class="docutils literal notranslate"><span class="pre">double</span></code></p></li>
<li><p>Widening conversions for integers, such as <code class="docutils literal notranslate"><span class="pre">tinyint</span></code> to <code class="docutils literal notranslate"><span class="pre">smallint</span></code></p></li>
</ul>
<p>Any conversion failure results in null, which is the same behavior
as Hive. For example, converting the string <code class="docutils literal notranslate"><span class="pre">'foo'</span></code> to a number,
or converting the string <code class="docutils literal notranslate"><span class="pre">'1234'</span></code> to a <code class="docutils literal notranslate"><span class="pre">tinyint</span></code> (which has a
maximum value of <code class="docutils literal notranslate"><span class="pre">127</span></code>).</p>
</div>
<div class="section" id="avro-schema-evolution">
<h2>Avro Schema Evolution<a class="headerlink" href="#avro-schema-evolution" title="Permalink to this headline">#</a></h2>
<p>Presto supports querying and manipulating Hive tables with the Avro storage
format, which has the schema set based on an Avro schema file/literal. Presto is
also capable of creating the tables in Presto by infering the schema from a
valid Avro schema file located locally, or remotely in HDFS/Web server.</p>
<p>To specify that the Avro schema should be used for interpreting tableâ€™s data one must use <code class="docutils literal notranslate"><span class="pre">avro_schema_url</span></code> table property.
The schema can be placed remotely in
HDFS (e.g. <code class="docutils literal notranslate"><span class="pre">avro_schema_url</span> <span class="pre">=</span> <span class="pre">'hdfs://user/avro/schema/avro_data.avsc'</span></code>),
S3 (e.g. <code class="docutils literal notranslate"><span class="pre">avro_schema_url</span> <span class="pre">=</span> <span class="pre">'s3n:///schema_bucket/schema/avro_data.avsc'</span></code>),
a web server (e.g. <code class="docutils literal notranslate"><span class="pre">avro_schema_url</span> <span class="pre">=</span> <span class="pre">'http://example.org/schema/avro_data.avsc'</span></code>)
as well as local file system. This URL, where the schema is located, must be accessible from the
Hive metastore and Presto coordinator/worker nodes.</p>
<p>The table created in Presto using <code class="docutils literal notranslate"><span class="pre">avro_schema_url</span></code> behaves the same way as a Hive table with <code class="docutils literal notranslate"><span class="pre">avro.schema.url</span></code> or <code class="docutils literal notranslate"><span class="pre">avro.schema.literal</span></code> set.</p>
<p>Example:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">hive</span><span class="p">.</span><span class="n">avro</span><span class="p">.</span><span class="n">avro_data</span> <span class="p">(</span>
   <span class="n">id</span> <span class="nb">bigint</span>
 <span class="p">)</span>
<span class="k">WITH</span> <span class="p">(</span>
   <span class="n">format</span> <span class="o">=</span> <span class="s1">&#39;AVRO&#39;</span><span class="p">,</span>
   <span class="n">avro_schema_url</span> <span class="o">=</span> <span class="s1">&#39;/usr/local/avro_data.avsc&#39;</span>
<span class="p">)</span>
</pre></div>
</div>
<p>The columns listed in the DDL (<code class="docutils literal notranslate"><span class="pre">id</span></code> in the above example) is ignored if <code class="docutils literal notranslate"><span class="pre">avro_schema_url</span></code> is specified.
The table schema matches the schema in the Avro schema file. Before any read operation, the Avro schema is
accessed so the query result reflects any changes in schema. Thus Presto takes advantage of Avroâ€™s backward compatibility abilities.</p>
<p>If the schema of the table changes in the Avro schema file, the new schema can still be used to read old data.
Newly added/renamed fields <em>must</em> have a default value in the Avro schema file.</p>
<p>The schema evolution behavior is as follows:</p>
<ul class="simple">
<li><p>Column added in new schema:
Data created with an older schema produces a <em>default</em> value when table is using the new schema.</p></li>
<li><p>Column removed in new schema:
Data created with an older schema no longer outputs the data from the column that was removed.</p></li>
<li><p>Column is renamed in the new schema:
This is equivalent to removing the column and adding a new one, and data created with an older schema
produces a <em>default</em> value when table is using the new schema.</p></li>
<li><p>Changing type of column in the new schema:
If the type coercion is supported by Avro or the Hive connector, then the conversion happens.
An error is thrown for incompatible types.</p></li>
</ul>
<div class="section" id="limitations">
<h3>Limitations<a class="headerlink" href="#limitations" title="Permalink to this headline">#</a></h3>
<p>The following operations are not supported when <code class="docutils literal notranslate"><span class="pre">avro_schema_url</span></code> is set:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">CREATE</span> <span class="pre">TABLE</span> <span class="pre">AS</span></code> is not supported.</p></li>
<li><p>Using partitioning(<code class="docutils literal notranslate"><span class="pre">partitioned_by</span></code>) or bucketing(<code class="docutils literal notranslate"><span class="pre">bucketed_by</span></code>) columns are not supported in <code class="docutils literal notranslate"><span class="pre">CREATE</span> <span class="pre">TABLE</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">ALTER</span> <span class="pre">TABLE</span></code> commands modifying columns are not supported.</p></li>
</ul>
</div>
</div>
<div class="section" id="procedures">
<span id="hive-procedures"></span><h2>Procedures<a class="headerlink" href="#procedures" title="Permalink to this headline">#</a></h2>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">system.create_empty_partition(schema_name,</span> <span class="pre">table_name,</span> <span class="pre">partition_columns,</span> <span class="pre">partition_values)</span></code></p>
<p>Create an empty partition in the specified table.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">system.sync_partition_metadata(schema_name,</span> <span class="pre">table_name,</span> <span class="pre">mode,</span> <span class="pre">case_sensitive)</span></code></p>
<p>Check and update partitions list in metastore. There are three modes available:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ADD</span></code> : add any partitions that exist on the file system, but not in the metastore.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DROP</span></code>: drop any partitions that exist in the metastore, but not on the file system.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">FULL</span></code>: perform both <code class="docutils literal notranslate"><span class="pre">ADD</span></code> and <code class="docutils literal notranslate"><span class="pre">DROP</span></code>.</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">case_sensitive</span></code> argument is optional. The default value is <code class="docutils literal notranslate"><span class="pre">true</span></code> for compatibility
with Hiveâ€™s <code class="docutils literal notranslate"><span class="pre">MSCK</span> <span class="pre">REPAIR</span> <span class="pre">TABLE</span></code> behavior, which expects the partition column names in
file system paths to use lowercase (e.g. <code class="docutils literal notranslate"><span class="pre">col_x=SomeValue</span></code>). Partitions on the file system
not conforming to this convention are ignored, unless the argument is set to <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">system.drop_stats(schema_name,</span> <span class="pre">table_name,</span> <span class="pre">partition_values)</span></code></p>
<p>Drops statistics for a subset of partitions or the entire table. The partitions are specified as an
array whose elements are arrays of partition values (similar to the <code class="docutils literal notranslate"><span class="pre">partition_values</span></code> argument in
<code class="docutils literal notranslate"><span class="pre">create_empty_partition</span></code>). If <code class="docutils literal notranslate"><span class="pre">partition_values</span></code> argument is omitted, stats are dropped for the
entire table.</p>
</li>
</ul>
<ul id="register-partition">
<li><p><code class="docutils literal notranslate"><span class="pre">system.register_partition(schema_name,</span> <span class="pre">table_name,</span> <span class="pre">partition_columns,</span> <span class="pre">partition_values,</span> <span class="pre">location)</span></code></p>
<p>Registers existing location as a new partition in the metastore for the specified table.</p>
<p>Due to security reasons, the procedure is enabled only when <code class="docutils literal notranslate"><span class="pre">hive.allow-register-partition-procedure</span></code>
is set to <code class="docutils literal notranslate"><span class="pre">true</span></code>.</p>
</li>
</ul>
<ul id="unregister-partition">
<li><p><code class="docutils literal notranslate"><span class="pre">system.unregister_partition(schema_name,</span> <span class="pre">table_name,</span> <span class="pre">partition_columns,</span> <span class="pre">partition_values)</span></code></p>
<p>Unregisters given, existing partition in the metastore for the specified table.
The partition data is not deleted.</p>
</li>
</ul>
</div>
<div class="section" id="special-columns">
<h2>Special Columns<a class="headerlink" href="#special-columns" title="Permalink to this headline">#</a></h2>
<p>In addition to the defined columns, the Hive connector automatically exposes
metadata in a number of hidden columns in each table. You can use these columns
in your SQL statements like any other column, e.g., they can be selected
directly or used in conditional statements.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">$bucket</span></code>: Bucket number for this row</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">$path</span></code>: Full file system path name of the file for this row</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">$file_modified_time</span></code>: Date and time of the last modification of the file for this row</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">$file_size</span></code>: Size of the file for this row</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">$partition</span></code>: Partition name for this row</p></li>
</ul>
</div>
<div class="section" id="special-tables">
<h2>Special Tables<a class="headerlink" href="#special-tables" title="Permalink to this headline">#</a></h2>
<div class="section" id="table-properties">
<h3>Table Properties<a class="headerlink" href="#table-properties" title="Permalink to this headline">#</a></h3>
<p>The raw Hive table properties are available as a hidden table, containing a
separate column per table property, with a single row containing the property
values. The properties table name is the same as the table name with
<code class="docutils literal notranslate"><span class="pre">$properties</span></code> appended.</p>
<p>You can inspect the property names and values with a simple query:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">hive</span><span class="p">.</span><span class="n">web</span><span class="p">.</span><span class="ss">&quot;page_views$properties&quot;</span><span class="p">;</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="examples">
<h2>Examples<a class="headerlink" href="#examples" title="Permalink to this headline">#</a></h2>
<p>The Hive connector supports querying and manipulating Hive tables and schemas
(databases). While some uncommon operations need to be performed using
Hive directly, most operations can be performed using Presto.</p>
<p>Create a new Hive schema named <code class="docutils literal notranslate"><span class="pre">web</span></code> that stores tables in an
S3 bucket named <code class="docutils literal notranslate"><span class="pre">my-bucket</span></code>:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CREATE</span> <span class="k">SCHEMA</span> <span class="n">hive</span><span class="p">.</span><span class="n">web</span>
<span class="k">WITH</span> <span class="p">(</span><span class="k">location</span> <span class="o">=</span> <span class="s1">&#39;s3://my-bucket/&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Create a new Hive table named <code class="docutils literal notranslate"><span class="pre">page_views</span></code> in the <code class="docutils literal notranslate"><span class="pre">web</span></code> schema
that is stored using the ORC file format, partitioned by date and
country, and bucketed by user into <code class="docutils literal notranslate"><span class="pre">50</span></code> buckets. Note that Hive
requires the partition columns to be the last columns in the table:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">hive</span><span class="p">.</span><span class="n">web</span><span class="p">.</span><span class="n">page_views</span> <span class="p">(</span>
  <span class="n">view_time</span> <span class="k">timestamp</span><span class="p">,</span>
  <span class="n">user_id</span> <span class="nb">bigint</span><span class="p">,</span>
  <span class="n">page_url</span> <span class="nb">varchar</span><span class="p">,</span>
  <span class="n">ds</span> <span class="nb">date</span><span class="p">,</span>
  <span class="n">country</span> <span class="nb">varchar</span>
<span class="p">)</span>
<span class="k">WITH</span> <span class="p">(</span>
  <span class="n">format</span> <span class="o">=</span> <span class="s1">&#39;ORC&#39;</span><span class="p">,</span>
  <span class="n">partitioned_by</span> <span class="o">=</span> <span class="nb">ARRAY</span><span class="p">[</span><span class="s1">&#39;ds&#39;</span><span class="p">,</span> <span class="s1">&#39;country&#39;</span><span class="p">],</span>
  <span class="n">bucketed_by</span> <span class="o">=</span> <span class="nb">ARRAY</span><span class="p">[</span><span class="s1">&#39;user_id&#39;</span><span class="p">],</span>
  <span class="n">bucket_count</span> <span class="o">=</span> <span class="mi">50</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Drop a partition from the <code class="docutils literal notranslate"><span class="pre">page_views</span></code> table:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">DELETE</span> <span class="k">FROM</span> <span class="n">hive</span><span class="p">.</span><span class="n">web</span><span class="p">.</span><span class="n">page_views</span>
<span class="k">WHERE</span> <span class="n">ds</span> <span class="o">=</span> <span class="nb">DATE</span> <span class="s1">&#39;2016-08-09&#39;</span>
  <span class="k">AND</span> <span class="n">country</span> <span class="o">=</span> <span class="s1">&#39;US&#39;</span>
</pre></div>
</div>
<p>Add an empty partition to the <code class="docutils literal notranslate"><span class="pre">page_views</span></code> table:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CALL</span> <span class="k">system</span><span class="p">.</span><span class="n">create_empty_partition</span><span class="p">(</span>
    <span class="k">schema_name</span> <span class="o">=&gt;</span> <span class="s1">&#39;web&#39;</span><span class="p">,</span>
    <span class="k">table_name</span> <span class="o">=&gt;</span> <span class="s1">&#39;page_views&#39;</span><span class="p">,</span>
    <span class="n">partition_columns</span> <span class="o">=&gt;</span> <span class="nb">ARRAY</span><span class="p">[</span><span class="s1">&#39;ds&#39;</span><span class="p">,</span> <span class="s1">&#39;country&#39;</span><span class="p">],</span>
    <span class="n">partition_values</span> <span class="o">=&gt;</span> <span class="nb">ARRAY</span><span class="p">[</span><span class="s1">&#39;2016-08-09&#39;</span><span class="p">,</span> <span class="s1">&#39;US&#39;</span><span class="p">]);</span>
</pre></div>
</div>
<p>Drop stats for a partition of the <code class="docutils literal notranslate"><span class="pre">page_views</span></code> table:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CALL</span> <span class="k">system</span><span class="p">.</span><span class="n">drop_stats</span><span class="p">(</span>
    <span class="k">schema_name</span> <span class="o">=&gt;</span> <span class="s1">&#39;web&#39;</span><span class="p">,</span>
    <span class="k">table_name</span> <span class="o">=&gt;</span> <span class="s1">&#39;page_views&#39;</span><span class="p">,</span>
    <span class="n">partition_values</span> <span class="o">=&gt;</span> <span class="nb">ARRAY</span><span class="p">[</span><span class="s1">&#39;2016-08-09&#39;</span><span class="p">,</span> <span class="s1">&#39;US&#39;</span><span class="p">]);</span>
</pre></div>
</div>
<p>Query the <code class="docutils literal notranslate"><span class="pre">page_views</span></code> table:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">hive</span><span class="p">.</span><span class="n">web</span><span class="p">.</span><span class="n">page_views</span>
</pre></div>
</div>
<p>List the partitions of the <code class="docutils literal notranslate"><span class="pre">page_views</span></code> table:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">SELECT</span> <span class="o">*</span> <span class="k">FROM</span> <span class="n">hive</span><span class="p">.</span><span class="n">web</span><span class="p">.</span><span class="ss">&quot;page_views$partitions&quot;</span>
</pre></div>
</div>
<p>Create an external Hive table named <code class="docutils literal notranslate"><span class="pre">request_logs</span></code> that points at
existing data in S3:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CREATE</span> <span class="k">TABLE</span> <span class="n">hive</span><span class="p">.</span><span class="n">web</span><span class="p">.</span><span class="n">request_logs</span> <span class="p">(</span>
  <span class="n">request_time</span> <span class="k">timestamp</span><span class="p">,</span>
  <span class="n">url</span> <span class="nb">varchar</span><span class="p">,</span>
  <span class="n">ip</span> <span class="nb">varchar</span><span class="p">,</span>
  <span class="n">user_agent</span> <span class="nb">varchar</span>
<span class="p">)</span>
<span class="k">WITH</span> <span class="p">(</span>
  <span class="n">format</span> <span class="o">=</span> <span class="s1">&#39;TEXTFILE&#39;</span><span class="p">,</span>
  <span class="n">external_location</span> <span class="o">=</span> <span class="s1">&#39;s3://my-bucket/data/logs/&#39;</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Collect statistics for the <code class="docutils literal notranslate"><span class="pre">request_logs</span></code> table:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">ANALYZE</span> <span class="n">hive</span><span class="p">.</span><span class="n">web</span><span class="p">.</span><span class="n">request_logs</span><span class="p">;</span>
</pre></div>
</div>
<p>The examples shown here should work on Google Cloud Storage after replacing <code class="docutils literal notranslate"><span class="pre">s3://</span></code> with <code class="docutils literal notranslate"><span class="pre">gs://</span></code>.</p>
<div class="section" id="cleaning-up">
<h3>Cleaning up<a class="headerlink" href="#cleaning-up" title="Permalink to this headline">#</a></h3>
<p>Drop the external table <code class="docutils literal notranslate"><span class="pre">request_logs</span></code>. This only drops the metadata
for the table. The referenced data directory is not deleted:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">DROP</span> <span class="k">TABLE</span> <span class="n">hive</span><span class="p">.</span><span class="n">web</span><span class="p">.</span><span class="n">request_logs</span>
</pre></div>
</div>
<p>Drop a schema:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">DROP</span> <span class="k">SCHEMA</span> <span class="n">hive</span><span class="p">.</span><span class="n">web</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="hive-connector-limitations">
<h2>Hive Connector Limitations<a class="headerlink" href="#hive-connector-limitations" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="../sql/delete.html"><span class="doc">DELETE</span></a> is only supported if the <code class="docutils literal notranslate"><span class="pre">WHERE</span></code> clause matches entire partitions.</p></li>
<li><p><a class="reference internal" href="../sql/alter-schema.html"><span class="doc">ALTER SCHEMA</span></a> usage fails, since the Hive metastore does not support renaming schemas.</p></li>
</ul>
<div class="section" id="hive-3-related-limitations">
<h3>Hive 3 Related Limitations<a class="headerlink" href="#hive-3-related-limitations" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>For security reasons, the <code class="docutils literal notranslate"><span class="pre">sys</span></code> system catalog is not accessible.</p></li>
<li><p>Hiveâ€™s <code class="docutils literal notranslate"><span class="pre">timestamp</span> <span class="pre">with</span> <span class="pre">local</span> <span class="pre">zone</span></code> data type is not supported.
It is possible to read from a table with a column of this type, but the column
data is not accessible. Writing to such a table is not supported.</p></li>
<li><p>Due to Hive issues <a class="reference external" href="https://issues.apache.org/jira/browse/HIVE-21002">HIVE-21002</a>
and <a class="reference external" href="https://issues.apache.org/jira/browse/HIVE-22167">HIVE-22167</a>, Presto does
not correctly read <code class="docutils literal notranslate"><span class="pre">timestamp</span></code> values from Parquet, RCBinary, or Avro
file formats created by Hive 3.1 or later. When reading from these file formats,
Presto returns different results than Hive.</p></li>
</ul>
</div>
</div>
</div>


           </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="hive-security.html" style="box-shadow: none; border: none;" class="btn btn-neutral float-right" title="10.26. Hive Connector Security Configuration" accesskey="n">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="googlesheets.html" style="box-shadow: none; border: none;" class="btn btn-neutral" title="10.23. Google Sheets Connector" accesskey="p"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>

    </p>
  </div> 

</footer>

        </div>
      </div>

    </section>

  </div>

  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../',
            VERSION:'340',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  false
        };
    </script>
      <script type="text/javascript" src="../_static/jquery.js"></script>
      <script type="text/javascript" src="../_static/underscore.js"></script>
      <script type="text/javascript" src="../_static/doctools.js"></script>
      <script type="text/javascript" src="../_static/language_data.js"></script>

  

  
  
    <script type="text/javascript" src="../_static/js/theme.js"></script>
  

  
  
  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.StickyNav.enable();
      });
  </script>
   

</body>
</html>