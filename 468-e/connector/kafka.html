
<!DOCTYPE html>

<html lang="en" data-content_root="../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width,initial-scale=1">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="lang:clipboard.copy" content="Copy to clipboard">
  <meta name="lang:clipboard.copied" content="Copied to clipboard">
  <meta name="lang:search.language" content="en">
  <meta name="lang:search.pipeline.stopwords" content="True">
  <meta name="lang:search.pipeline.trimmer" content="True">
  <meta name="lang:search.result.none" content="No matching documents">
  <meta name="lang:search.result.one" content="1 matching document">
  <meta name="lang:search.result.other" content="# matching documents">
  <meta name="lang:search.tokenizer" content="[\s\-]+">

  
    <link href="https://fonts.gstatic.com/" rel="preconnect" crossorigin>
    <link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,500,700|Roboto:300,400,400i,700&display=fallback" rel="stylesheet">

    <style>
      body,
      input {
        font-family: "Roboto", "Helvetica Neue", Helvetica, Arial, sans-serif
      }

      code,
      kbd,
      pre {
        font-family: "Roboto Mono", "Courier New", Courier, monospace
      }
    </style>
  

  <link rel="stylesheet" href="../_static/stylesheets/application.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-palette.css"/>
  <link rel="stylesheet" href="../_static/stylesheets/application-fixes.css"/>
  
  <link rel="stylesheet" href="../_static/fonts/material-icons.css"/>
  
  <meta name="theme-color" content="000A2C">
  <script src="../_static/javascripts/modernizr.js"></script>
  
<script async src="https://www.googletagmanager.com/gtag/js?id=G-CY10FQPGJS"></script>
<script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
        dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-CY10FQPGJS');
</script>
  
  
    <title>Kafka connector &#8212; Starburst Enterprise</title>
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=bbebba6e" />
    <link rel="stylesheet" type="text/css" href="../_static/material.css?v=79c92029" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/algolia.css?v=0e0f969e" />
    <link rel="stylesheet" type="text/css" href="../_static/starburst.css?v=c0e612e9" />
    <link rel="stylesheet" type="text/css" href="../_static/search.css?v=87ff3654" />
    <link rel="stylesheet" type="text/css" href="../_static/sidebar.css?v=84a9f4d7" />
    <script src="../_static/documentation_options.js?v=a68ab161"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=e378d701"></script>
    <script src="../_static/main.js?v=5bbdfc95"></script>
    <script src="../_static/heap_analytics.js?v=eba036f6"></script>
    <link rel="icon" href="../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Kafka connector tutorial" href="kafka-tutorial.html" />
    <link rel="prev" title="Starburst Greenplum connector" href="starburst-greenplum.html" />

  
   

<link href="https://fonts.googleapis.com/css2?family=Barlow&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Montserrat&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Material+Symbols+Rounded" rel="stylesheet">
<link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" rel="stylesheet" >


<!-- Always link to the latest version, as canonical -->
<link rel="canonical" href="https://docs.starburst.io/latest/connector/kafka.html">

  </head>
  <body dir=ltr
        data-md-color-primary= data-md-color-accent=>
  
  <svg class="md-svg">
    <defs data-children-count="0">
      
      <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="__github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
      
    </defs>
  </svg>
  
  <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer">
  <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search">
  <label class="md-overlay" data-md-component="overlay" for="__drawer"></label>
  <a href="#connector/kafka" tabindex="1" class="md-skip"> Skip to content </a>
  
<header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex navheader">
      <div class="md-flex__cell md-flex__cell--shrink">
        <a href="https://www.starburst.io" title="Starburst Enterprise"
          class="md-header-nav__button md-logo">
            <img src="../_static/img/Starburst_Logo_White+Blue.svg"
              alt="Starburst Enterprise 468-e.6 LTS logo">
        </a>
      </div>
      <span class="header-divider"></span>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="__drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <div class="md-flex__ellipsis md-header-nav__title" data-md-component="title">
          <a href="/starburst-enterprise/index.html"
          class="md-header-nav__topic">
          Documentation: Starburst Enterprise 468-e.6 LTS</a>
          <span class="md-header-nav__topic"> Kafka connector </span>
        </div>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--search md-header-nav__button" for="__search"></label>
        <div id="algolia-search">
  <div id="searchbox"></div>
  <div id="product-list">
    <h6 class="filter-label">Product:</h6>
  </div>
  <div id="versionsRefinementList" id="version-list" style="display:none"></div>
  <div id="hits"></div>
  <div id="stats"></div>
</div>
      </div>
      
      
  
  <div class="md-flex__cell md-flex__cell--shrink dropdown">
    <button class="dropdownbutton">Choose version</button>
    <div class="dropdown-content md-hero">
          <a title="Latest LTS (468-e)" href="/468-e/">Latest LTS (468-e)</a>
      
          <a title="462-e LTS" href="/462-e/">462-e LTS</a>
      
          <a title="453-e LTS" href="/453-e/">453-e LTS</a>
      
          <a title="443-e LTS" href="/443-e/">443-e LTS</a>
      
          <a title="Latest STS (472-e)" href="/472-e/">Latest STS (472-e)</a>
      
          <a title="471-e STS" href="/471-e/">471-e STS</a>
      
    </div>
  </div>
  

    </div>
  </nav>
</header>


  
  <div class="md-container">
    
    
    
  <nav class="md-tabs" data-md-component="tabs">
    <div class="md-tabs__inner md-grid">
      <ul class="md-tabs__list">
            
            <li class="md-tabs__item"><a href="/introduction/index.html" class="md-tabs__link">Introduction</a></li>
            
            <li class="md-tabs__item"><a href="/clients/index.html" class="md-tabs__link">Clients</a></li>
            
            <li class="md-tabs__item"><a href="/starburst-galaxy/index.html" class="md-tabs__link">Starburst Galaxy</a></li>
            
            <li class="md-tabs__item"><a href="/starburst-enterprise/index.html" class="md-tabs__link">Starburst Enterprise</a></li>
            
            <li class="md-tabs__item"><a href="/resources.html" class="md-tabs__link">Resources</a></li>
          <li class="md-tabs__item"><a href="../non-object-storage-connectors.html" class="md-tabs__link">Non-object storage connectors</a></li>
      </ul>
    </div>
  </nav>
    <main class="md-main">
      <div class="md-main__inner md-grid" data-md-component="container">
        
          <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="__drawer">
    <a href="../index.html" title="Starburst Enterprise" class="md-nav__button md-logo">
      
        <img src="../_static/" alt=" logo" width="48" height="48">
      
    </a>
    <a href="../index.html"
       title="Starburst Enterprise">Starburst Enterprise 468-e.6 LTS</a>
  </label>
  
  
  <p class="caption" role="heading"><span class="caption-text">Get started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../get-started/index.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get-started/starburst-enterprise.html">What is Starburst Enterprise?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../get-started/try/try-sep.html">Try Starburst Enterprise</a></li>
<li class="toctree-l1"><a class="reference internal" href="../learn/index.html">Learn Starburst Enterprise</a></li>
<li class="toctree-l1"><a class="reference internal" href="../versions.html">Product versions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../release.html">Release notes</a></li>
<li class="toctree-l1"><a class="reference external" href="https://docs.starburst.io/support.html">Get support</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">For all users</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../overview/sep-ui.html">Starburst Enterprise web UI</a></li>
<li class="toctree-l1"><a class="reference internal" href="../client.html">Clients</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data-products.html">Data products</a></li>
<li class="toctree-l1"><a class="reference internal" href="../insights.html">Insights</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Use SQL</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../language.html">SQL language</a></li>
<li class="toctree-l1"><a class="reference internal" href="../sql.html">SQL statement syntax</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functions.html">Functions and operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../udf.html">SQL UDFs</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">For data engineers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../catalogs.html">Define catalogs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../object-storage.html">Object storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data-engineering/materialized-views.html">Materialized views</a></li>
<li class="toctree-l1"><a class="reference internal" href="../optimizer.html">Query optimizer</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Connect to data sources</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../connector.html">Connector overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../object-storage-connectors.html">Object storage connectors</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="../non-object-storage-connectors.html">Non-object storage connectors</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="cassandra.html">Cassandra connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-cosmosdb.html">Cosmos DB connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="bigquery.html">BigQuery connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-dynamodb.html">DynamoDB connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-db2.html">IBM Db2 connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="elasticsearch.html">Elasticsearch connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-generic-jdbc.html">Generic JDBC connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-greenplum.html">Greenplum connector</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Kafka connector</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#requirements">Requirements</a></li>
<li class="toctree-l3"><a class="reference internal" href="#configuration">Configuration</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#multiple-kafka-servers">Multiple Kafka servers</a></li>
<li class="toctree-l4"><a class="reference internal" href="#log-levels">Log levels</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#general-configuration-properties">General configuration properties</a></li>
<li class="toctree-l3"><a class="reference internal" href="#internal-columns">Internal columns</a></li>
<li class="toctree-l3"><a class="reference internal" href="#table-schema-and-schema-registry-usage">Table schema and schema registry usage</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#file-table-description-supplier">File table description supplier</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#kafka-table-names"><code class="docutils literal notranslate"><span class="pre">kafka.table-names</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#kafka-table-description-dir"><code class="docutils literal notranslate"><span class="pre">kafka.table-description-dir</span></code></a></li>
<li class="toctree-l5"><a class="reference internal" href="#table-definition-files">Table definition files</a></li>
<li class="toctree-l5"><a class="reference internal" href="#key-and-message-in-kafka">Key and message in Kafka</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#confluent-table-description-supplier">Confluent table description supplier</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#confluent-subject-to-table-name-mapping">Confluent subject to table name mapping</a></li>
<li class="toctree-l5"><a class="reference internal" href="#protobuf-specific-type-handling-in-confluent-table-description-supplier">Protobuf-specific type handling in Confluent table description supplier</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#oneof">oneof</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#kafka-inserts">Kafka inserts</a></li>
<li class="toctree-l3"><a class="reference internal" href="#type-mapping">Type mapping</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#row-encoding">Row encoding</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#raw-encoder">Raw encoder</a></li>
<li class="toctree-l5"><a class="reference internal" href="#csv-encoder">CSV encoder</a></li>
<li class="toctree-l5"><a class="reference internal" href="#json-encoder">JSON encoder</a></li>
<li class="toctree-l5"><a class="reference internal" href="#avro-encoder">Avro encoder</a></li>
<li class="toctree-l5"><a class="reference internal" href="#protobuf-encoder">Protobuf encoder</a></li>
</ul>
</li>
<li class="toctree-l4"><a class="reference internal" href="#row-decoding">Row decoding</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#raw-decoder">Raw decoder</a></li>
<li class="toctree-l5"><a class="reference internal" href="#csv-decoder">CSV decoder</a></li>
<li class="toctree-l5"><a class="reference internal" href="#json-decoder">JSON decoder</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#default-field-decoder">Default field decoder</a></li>
<li class="toctree-l6"><a class="reference internal" href="#date-and-time-decoders">Date and time decoders</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#avro-decoder">Avro decoder</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#avro-schema-evolution">Avro schema evolution</a></li>
</ul>
</li>
<li class="toctree-l5"><a class="reference internal" href="#protobuf-decoder">Protobuf decoder</a><ul>
<li class="toctree-l6"><a class="reference internal" href="#any">any</a></li>
<li class="toctree-l6"><a class="reference internal" href="#protobuf-schema-evolution">Protobuf schema evolution</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#sql-support">SQL support</a></li>
<li class="toctree-l3"><a class="reference internal" href="#performance">Performance</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#parallelism">Parallelism</a></li>
<li class="toctree-l4"><a class="reference internal" href="#starburst-cached-views">Starburst Cached Views</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#security">Security</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#password-credential-pass-through">Password credential pass-through</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tls-ssl-encryption">TLS/SSL encryption</a></li>
<li class="toctree-l4"><a class="reference internal" href="#tls-ssl-authentication">TLS/SSL authentication</a></li>
<li class="toctree-l4"><a class="reference internal" href="#sasl-authentication">SASL authentication</a><ul>
<li class="toctree-l5"><a class="reference internal" href="#password-authentication">Password authentication</a></li>
<li class="toctree-l5"><a class="reference internal" href="#kerberos-authentication">Kerberos authentication</a></li>
<li class="toctree-l5"><a class="reference internal" href="#oauth-2-0-authentication">OAuth 2.0 authentication</a></li>
<li class="toctree-l5"><a class="reference internal" href="#oauth-2-0-token-pass-through">OAuth 2.0 token pass-through</a></li>
<li class="toctree-l5"><a class="reference internal" href="#scram-authentication">SCRAM authentication</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#security-for-schema-registry-access">Security for schema registry access</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#id7">TLS/SSL authentication</a></li>
<li class="toctree-l4"><a class="reference internal" href="#basic-authentication">Basic authentication</a></li>
<li class="toctree-l4"><a class="reference internal" href="#id8">Kerberos authentication</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="#cloudera-schema-registry">Cloudera schema registry</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="kudu.html">Kudu connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-maxcompute.html">MaxCompute connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="mongodb.html">MongoDB connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="mysql.html">MySQL connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-neo4j.html">Neo4j connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-netezza.html">Netezza connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="oracle.html">Oracle connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="postgresql.html">PostgreSQL connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="redshift.html">Redshift connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-salesforce.html">Salesforce connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-sap-hana.html">SAP HANA connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="singlestore.html">SingleStore connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="snowflake.html">Snowflake connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-splunk.html">Splunk connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="sqlserver.html">SQL Server connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-synapse.html">Synapse connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="starburst-teradata.html">Teradata connector</a></li>
<li class="toctree-l2"><a class="reference internal" href="vertica.html">Vertica connector</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../utilities.html">Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../community-connectors.html">Community-supported connectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="starburst-connectors.html">Starburst connectors feature matrix</a></li>
<li class="toctree-l1"><a class="reference internal" href="../data-engineering/cost-and-performance/index.html">Monitor and manage cost and performance</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">For platform administrators</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../admin-topics.html">Administration topics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../admin.html">Performance, logging, and governance features</a></li>
<li class="toctree-l1"><a class="reference internal" href="../security.html">Security</a></li>
<li class="toctree-l1"><a class="reference internal" href="../starburst-rest-api.html">Starburst Enterprise REST API</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deploy in cloud ecosystems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../ecosystems/aws/index.html">AWS ecosystem</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ecosystems/google/index.html">Google Cloud</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ecosystems/microsoft/index.html">Microsoft Azure</a></li>
<li class="toctree-l1"><a class="reference internal" href="../ecosystems/redhat/index.html">Red Hat OpenShift</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">SEP deployment mechanisms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../license-requirements.html">Starburst Enterprise license</a></li>
<li class="toctree-l1"><a class="reference internal" href="../k8s.html">Deploy with Kubernetes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../starburst-admin.html">Deploy with Starburst Admin</a></li>
<li class="toctree-l1"><a class="reference internal" href="../aws.html">Deploy with CFT on AWS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../installation.html">Local installation</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Appendix</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../develop.html">Trino developer guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../appendix.html">Version-specific notices and information</a></li>
</ul>
  
  
</nav>
              </div>
            </div>
          </div>
          <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
            <div class="md-sidebar__scrollwrap">
              <div class="md-sidebar__inner">
                
<nav class="md-nav md-nav--secondary">
    <label class="md-nav__title" for="__toc">"Contents"</label>
  <ul class="md-nav__list" data-md-scrollfix="">
        <li class="md-nav__item"><a href="#connector-kafka--page-root" class="md-nav__link">Kafka connector</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#requirements" class="md-nav__link">Requirements</a>
        </li>
        <li class="md-nav__item"><a href="#configuration" class="md-nav__link">Configuration</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#multiple-kafka-servers" class="md-nav__link">Multiple Kafka servers</a>
        </li>
        <li class="md-nav__item"><a href="#log-levels" class="md-nav__link">Log levels</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#general-configuration-properties" class="md-nav__link">General configuration properties</a>
        </li>
        <li class="md-nav__item"><a href="#internal-columns" class="md-nav__link">Internal columns</a>
        </li>
        <li class="md-nav__item"><a href="#table-schema-and-schema-registry-usage" class="md-nav__link">Table schema and schema registry usage</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#file-table-description-supplier" class="md-nav__link">File table description supplier</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#kafka-table-names" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">kafka.table-names</span></code></a>
        </li>
        <li class="md-nav__item"><a href="#kafka-table-description-dir" class="md-nav__link"><code class="docutils literal notranslate"><span class="pre">kafka.table-description-dir</span></code></a>
        </li>
        <li class="md-nav__item"><a href="#table-definition-files" class="md-nav__link">Table definition files</a>
        </li>
        <li class="md-nav__item"><a href="#key-and-message-in-kafka" class="md-nav__link">Key and message in Kafka</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#confluent-table-description-supplier" class="md-nav__link">Confluent table description supplier</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#confluent-subject-to-table-name-mapping" class="md-nav__link">Confluent subject to table name mapping</a>
        </li>
        <li class="md-nav__item"><a href="#protobuf-specific-type-handling-in-confluent-table-description-supplier" class="md-nav__link">Protobuf-specific type handling in Confluent table description supplier</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#oneof" class="md-nav__link">oneof</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#kafka-inserts" class="md-nav__link">Kafka inserts</a>
        </li>
        <li class="md-nav__item"><a href="#type-mapping" class="md-nav__link">Type mapping</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#row-encoding" class="md-nav__link">Row encoding</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#raw-encoder" class="md-nav__link">Raw encoder</a>
        </li>
        <li class="md-nav__item"><a href="#csv-encoder" class="md-nav__link">CSV encoder</a>
        </li>
        <li class="md-nav__item"><a href="#json-encoder" class="md-nav__link">JSON encoder</a>
        </li>
        <li class="md-nav__item"><a href="#avro-encoder" class="md-nav__link">Avro encoder</a>
        </li>
        <li class="md-nav__item"><a href="#protobuf-encoder" class="md-nav__link">Protobuf encoder</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#row-decoding" class="md-nav__link">Row decoding</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#raw-decoder" class="md-nav__link">Raw decoder</a>
        </li>
        <li class="md-nav__item"><a href="#csv-decoder" class="md-nav__link">CSV decoder</a>
        </li>
        <li class="md-nav__item"><a href="#json-decoder" class="md-nav__link">JSON decoder</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#default-field-decoder" class="md-nav__link">Default field decoder</a>
        </li>
        <li class="md-nav__item"><a href="#date-and-time-decoders" class="md-nav__link">Date and time decoders</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#avro-decoder" class="md-nav__link">Avro decoder</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#avro-schema-evolution" class="md-nav__link">Avro schema evolution</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#protobuf-decoder" class="md-nav__link">Protobuf decoder</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#any" class="md-nav__link">any</a>
        </li>
        <li class="md-nav__item"><a href="#protobuf-schema-evolution" class="md-nav__link">Protobuf schema evolution</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#sql-support" class="md-nav__link">SQL support</a>
        </li>
        <li class="md-nav__item"><a href="#performance" class="md-nav__link">Performance</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#parallelism" class="md-nav__link">Parallelism</a>
        </li>
        <li class="md-nav__item"><a href="#starburst-cached-views" class="md-nav__link">Starburst Cached Views</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#security" class="md-nav__link">Security</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#password-credential-pass-through" class="md-nav__link">Password credential pass-through</a>
        </li>
        <li class="md-nav__item"><a href="#tls-ssl-encryption" class="md-nav__link">TLS/SSL encryption</a>
        </li>
        <li class="md-nav__item"><a href="#tls-ssl-authentication" class="md-nav__link">TLS/SSL authentication</a>
        </li>
        <li class="md-nav__item"><a href="#sasl-authentication" class="md-nav__link">SASL authentication</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#password-authentication" class="md-nav__link">Password authentication</a>
        </li>
        <li class="md-nav__item"><a href="#kerberos-authentication" class="md-nav__link">Kerberos authentication</a>
        </li>
        <li class="md-nav__item"><a href="#oauth-2-0-authentication" class="md-nav__link">OAuth 2.0 authentication</a>
        </li>
        <li class="md-nav__item"><a href="#oauth-2-0-token-pass-through" class="md-nav__link">OAuth 2.0 token pass-through</a>
        </li>
        <li class="md-nav__item"><a href="#scram-authentication" class="md-nav__link">SCRAM authentication</a>
        </li></ul>
            </nav>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#security-for-schema-registry-access" class="md-nav__link">Security for schema registry access</a><nav class="md-nav">
              <ul class="md-nav__list">
        <li class="md-nav__item"><a href="#id7" class="md-nav__link">TLS/SSL authentication</a>
        </li>
        <li class="md-nav__item"><a href="#basic-authentication" class="md-nav__link">Basic authentication</a>
        </li>
        <li class="md-nav__item"><a href="#id8" class="md-nav__link">Kerberos authentication</a>
        </li></ul>
            </nav>
        </li>
        <li class="md-nav__item"><a href="#cloudera-schema-registry" class="md-nav__link">Cloudera schema registry</a>
        </li></ul>
            </nav>
        </li>
  </ul>
</nav>
              </div>
            </div>
          </div>
        
        <div class="md-content">
          <article class="md-content__inner md-typeset" role="main">
            
  <section id="kafka-connector">
<h1 id="connector-kafka--page-root">Kafka connector<a class="headerlink" href="#connector-kafka--page-root" title="Link to this heading">#</a></h1>
<img class="connector-logo" src="../_static/img/kafka.png"/><div class="toctree-wrapper compound">
</div>
<p>This connector allows the use of <a class="reference external" href="https://kafka.apache.org/">Apache Kafka</a>
topics as tables in Starburst Enterprise. Each message is presented as a row in
SEP.</p>
<p>Topics can be live. Rows appear as data arrives, and disappear as
segments get dropped. This can result in strange behavior if accessing the
same table multiple times in a single query such as performing a self join.</p>
<p>For a detailed example, see the <a class="reference internal" href="kafka-tutorial.html"><span class="doc std std-doc">Kafka connector tutorial</span></a>.</p>
<p>SEP includes additional enterprise features that are built on top of the
existing Trino connector functionality. For more information on connector key
feature differences between Trino and SEP, see the <a class="reference internal" href="starburst-connectors.html#sb-connectors-stream-processing"><span class="std std-ref">connectors feature
matrix</span></a>.</p>
<section id="requirements">
<span id="kafka-requirements"></span><h2 id="requirements">Requirements<a class="headerlink" href="#requirements" title="Link to this heading">#</a></h2>
<p>To connect to Kafka, you need:</p>
<ul class="simple">
<li><p>Kafka broker version 0.10.0 or higher.</p></li>
<li><p>Network access from the SEP coordinator and workers to the Kafka nodes.
Port 9092 is the default port.</p></li>
<li><p>A valid <a class="reference internal" href="../license-requirements.html"><span class="doc std std-doc">Starburst Enterprise license</span></a>.</p></li>
</ul>
<p>When using Protobuf decoder with the <a class="reference internal" href="#confluent-table-description-supplier"><span class="std std-ref">Confluent table description
supplier</span></a>, the following additional steps
must be taken:</p>
<ul class="simple">
<li><p>Copy the <code class="docutils literal notranslate"><span class="pre">kafka-protobuf-provider</span></code> and <code class="docutils literal notranslate"><span class="pre">kafka-protobuf-types</span></code> JAR files from
<a class="reference external" href="https://packages.confluent.io/maven/io/confluent/">Confluent</a> for Confluent
version 7.3.1 to the Kafka connector plugin directory (<code class="docutils literal notranslate"><span class="pre">&lt;install</span> <span class="pre">directory&gt;/plugin/kafka</span></code>) on all nodes in the cluster. The plugin directory
depends on the <a class="reference internal" href="../installation.html"><span class="doc std std-doc">Local installation</span></a> method.</p></li>
<li><p>By copying those JARs and using them, you agree to the terms of the <a class="reference external" href="https://github.com/confluentinc/schema-registry/blob/master/LICENSE-ConfluentCommunity">Confluent
Community License
Agreement</a>
under which Confluent makes them available.</p></li>
</ul>
<p>These steps are not required if you are not using Protobuf and Confluent table
description supplier.</p>
</section>
<section id="configuration">
<h2 id="configuration">Configuration<a class="headerlink" href="#configuration" title="Link to this heading">#</a></h2>
<p>To configure the Kafka connector, create a catalog properties file that
specifies the Kafka connector by setting the <code class="docutils literal notranslate"><span class="pre">connector.name</span></code> to <code class="docutils literal notranslate"><span class="pre">kafka</span></code>.</p>
<p>For example, to access a database as the <code class="docutils literal notranslate"><span class="pre">example</span></code> catalog, create the file
<code class="docutils literal notranslate"><span class="pre">etc/catalog/example.properties</span></code>. Replace the connection properties as
appropriate for your setup.</p>
<p>When using specialized authentication methods, you must specify additional Kafka
client properties in order to access your Kafka cluster. To do so, add the
<code class="docutils literal notranslate"><span class="pre">kafka.config.resources</span></code> property to reference your Kafka config files. Note
that configs can be overwritten if defined explicitly in <code class="docutils literal notranslate"><span class="pre">kafka.properties</span></code>:</p>
<div class="highlight-properties notranslate"><div class="highlight"><pre><span></span><span class="na">connector.name</span><span class="o">=</span><span class="s">kafka</span>
<span class="na">kafka.table-names</span><span class="o">=</span><span class="s">table1,table2</span>
<span class="na">kafka.nodes</span><span class="o">=</span><span class="s">host1:port,host2:port</span>
<span class="na">kafka.config.resources</span><span class="o">=</span><span class="s">/etc/kafka-configuration.properties</span>
</pre></div>
</div>
<section id="multiple-kafka-servers">
<h3 id="multiple-kafka-servers">Multiple Kafka servers<a class="headerlink" href="#multiple-kafka-servers" title="Link to this heading">#</a></h3>
<p>You can have as many catalogs as you need. If you have additional
Kafka clusters, configure another catalog.</p>
<p>To add another catalog, add a new properties file to <code class="docutils literal notranslate"><span class="pre">etc/catalog</span></code>. For example,
if you name the property file <code class="docutils literal notranslate"><span class="pre">sales.properties</span></code>, SEP creates a catalog
named <code class="docutils literal notranslate"><span class="pre">sales</span></code>.</p>
</section>
<section id="log-levels">
<h3 id="log-levels">Log levels<a class="headerlink" href="#log-levels" title="Link to this heading">#</a></h3>
<p>Kafka consumer logging can be verbose and pollute SEP logs. To lower the
<a class="reference internal" href="../installation/deployment.html#log-levels"><span class="std std-ref">log level</span></a>, add the following to <code class="docutils literal notranslate"><span class="pre">etc/log.properties</span></code>:</p>
<div class="highlight-properties notranslate"><div class="highlight"><pre><span></span><span class="na">org.apache.kafka</span><span class="o">=</span><span class="s">WARN</span>
</pre></div>
</div>
</section>
</section>
<section id="general-configuration-properties">
<h2 id="general-configuration-properties">General configuration properties<a class="headerlink" href="#general-configuration-properties" title="Link to this heading">#</a></h2>
<p>The following table describes general catalog configuration properties for the
connector:</p>
<table>
<colgroup>
<col style="width: 27%"/>
<col style="width: 55%"/>
<col style="width: 18%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property name</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Default</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.buffer-size</span></code></p></td>
<td><p>Size of the internal data buffer for reading data from Kafka. The data
buffer must be able to hold at least one message and ideally can hold many
messages. There is one data buffer allocated per worker and data node.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">64KB</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.config.resources</span></code></p></td>
<td><p>A comma-separated list of Kafka client configuration files. These files must
exist on the machines running SEP. Only specify this if absolutely necessary
to access Kafka. Example: <code class="docutils literal notranslate"><span class="pre">/etc/kafka-configuration.properties</span></code></p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.default-schema</span></code></p></td>
<td><p>Defines the schema which contains all tables that were defined without a
qualifying schema name.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">default</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.hide-internal-columns</span></code></p></td>
<td><p>Controls whether internal columns are part of the table schema or not. In
addition to the data columns defined in a table description file, the
connector maintains a number of additional columns for each table. If these
columns are hidden, they can still be used in queries but do not show up in
<code class="docutils literal notranslate"><span class="pre">DESCRIBE</span> <span class="pre">&lt;table-name&gt;</span></code> or <code class="docutils literal notranslate"><span class="pre">SELECT</span> <span class="pre">*</span></code>.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.internal-column-prefix</span></code></p></td>
<td><p>Prefix for internal columns.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">_</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.messages-per-split</span></code></p></td>
<td><p>Number of messages that are processed by each SEP split.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">100000</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.nodes</span></code></p></td>
<td><p>A comma-separated list of <code class="docutils literal notranslate"><span class="pre">hostname:port</span></code> pairs for the Kafka data nodes. At
least one node must be defined. <strong>This property is required</strong>. SEP must
still be able to connect to all nodes of the cluster even if only a subset
is specified here, as segment files may be located only on a specific node.</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.protobuf-any-support-enabled</span></code></p></td>
<td><p>Enable support for encoding Protobuf <code class="docutils literal notranslate"><span class="pre">any</span></code> types to <code class="docutils literal notranslate"><span class="pre">JSON</span></code> by setting the
property to <code class="docutils literal notranslate"><span class="pre">true</span></code>.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.security-protocol</span></code></p></td>
<td><p>Protocol used to communicate with brokers. Valid values are: <code class="docutils literal notranslate"><span class="pre">PLAINTEXT</span></code>and
<code class="docutils literal notranslate"><span class="pre">SSL</span></code>.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">PLAINTEXT</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.ssl.endpoint-identification-algorithm</span></code></p></td>
<td><p>The endpoint identification algorithm used by clients to validate server
host name for connecting to the Kafka cluster. Use <code class="docutils literal notranslate"><span class="pre">disabled</span></code> to disable
server host name validation.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">https</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.ssl.key.password</span></code></p></td>
<td><p>Password for the private key in the keystore file used for connecting to the
Kafka cluster. This is only required for clients if two-way authentication
is configured. For example: <code class="docutils literal notranslate"><span class="pre">ssl.client.auth=required</span></code>.</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.ssl.keystore.location</span></code></p></td>
<td><p>Location of the keystore file used for connecting to the Kafka cluster.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.ssl.keystore.password</span></code></p></td>
<td><p>Password for the keystore file used for connecting to the Kafka cluster.
This property is required when using <code class="docutils literal notranslate"><span class="pre">kafka.ssl.keystore.location</span></code>.</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.ssl.keystore.type</span></code></p></td>
<td><p>File format of the keystore file. Valid values are <code class="docutils literal notranslate"><span class="pre">JKS</span></code> and <code class="docutils literal notranslate"><span class="pre">PKCS12</span></code>.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">JKS</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.ssl.truststore.location</span></code></p></td>
<td><p>Location of the truststore file used for connecting to the Kafka cluster.</p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.ssl.truststore.password</span></code></p></td>
<td><p>Password for the truststore file used for connecting to the Kafka cluster.
This property is required when using <code class="docutils literal notranslate"><span class="pre">kafka.ssl.truststore.location</span></code>.</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.ssl.truststore.type</span></code></p></td>
<td><p>File format of the truststore file. Valid values are JKS and PKCS12.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">JKS</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.timestamp-upper-bound-force-push-down-enabled</span></code></p></td>
<td><p>The upper bound predicate on <code class="docutils literal notranslate"><span class="pre">_timestamp</span></code> column is pushed down only for
topics using <code class="docutils literal notranslate"><span class="pre">LogAppendTime</span></code> mode. For topics using <code class="docutils literal notranslate"><span class="pre">CreateTime</span></code> mode, upper
bound pushdown must be explicitly enabled using the
<code class="docutils literal notranslate"><span class="pre">kafka.timestamp-upper-bound-force-push-down-enabled</span></code> configuration property
or <code class="docutils literal notranslate"><span class="pre">timestamp_upper_bound_force_push_down_enabled</span></code> session property.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="internal-columns">
<h2 id="internal-columns">Internal columns<a class="headerlink" href="#internal-columns" title="Link to this heading">#</a></h2>
<p>The internal column prefix can be configured using the
<code class="docutils literal notranslate"><span class="pre">kafka.internal-column-prefix</span></code> configuration property and defaults to <code class="docutils literal notranslate"><span class="pre">_</span></code>. A
different prefix affects the internal column names as described in the following
sections. For example, a value of <code class="docutils literal notranslate"><span class="pre">internal_</span></code> changes the partition ID column
name from <code class="docutils literal notranslate"><span class="pre">_partition_id</span></code> to <code class="docutils literal notranslate"><span class="pre">internal_partition_id</span></code>.</p>
<p>For each defined table, the connector maintains the following columns:</p>
<table>
<colgroup>
<col style="width: 27%"/>
<col style="width: 18%"/>
<col style="width: 55%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Column name</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">_partition_id</span></code></p></td>
<td><p>BIGINT</p></td>
<td><p>ID of the Kafka partition which contains this row.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">_partition_offset</span></code></p></td>
<td><p>BIGINT</p></td>
<td><p>Offset within the Kafka partition for this row.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">_segment_start</span></code></p></td>
<td><p>BIGINT</p></td>
<td><p>Lowest offset in the segment (inclusive) which contains this row. This
offset is partition specific.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">_segment_end</span></code></p></td>
<td><p>BIGINT</p></td>
<td><p>Highest offset in the segment (exclusive) which contains this row. The
offset is partition specific. This is the same value as <code class="docutils literal notranslate"><span class="pre">_segment_start</span></code> of
the next segment (if it exists).</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">_segment_count</span></code></p></td>
<td><p>BIGINT</p></td>
<td><p>Running count for the current row within the segment. For an uncompacted
topic, <code class="docutils literal notranslate"><span class="pre">_segment_start</span> <span class="pre">+</span> <span class="pre">_segment_count</span></code> is equal to <code class="docutils literal notranslate"><span class="pre">_partition_offset</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">_message_corrupt</span></code></p></td>
<td><p>BOOLEAN</p></td>
<td><p>True if the decoder could not decode the message for this row. When true,
data columns mapped from the message should be treated as invalid.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">_message</span></code></p></td>
<td><p>VARCHAR</p></td>
<td><p>Message bytes as a UTF-8 encoded string. This is only useful for a text
topic.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">_message_length</span></code></p></td>
<td><p>BIGINT</p></td>
<td><p>Number of bytes in the message.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">_headers</span></code></p></td>
<td><p>map(VARCHAR, array(VARBINARY))</p></td>
<td><p>Headers of the message where values with the same key are grouped as array.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">_key_corrupt</span></code></p></td>
<td><p>BOOLEAN</p></td>
<td><p>True if the key decoder could not decode the key for this row. When true,
data columns mapped from the key should be treated as invalid.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">_key</span></code></p></td>
<td><p>VARCHAR</p></td>
<td><p>Key bytes as a UTF-8 encoded string. This is only useful for textual keys.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">_key_length</span></code></p></td>
<td><p>BIGINT</p></td>
<td><p>Number of bytes in the key.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">_timestamp</span></code></p></td>
<td><p>TIMESTAMP</p></td>
<td><p>Message timestamp.</p></td>
</tr>
</tbody>
</table>
<p>For tables without a table definition file, the <code class="docutils literal notranslate"><span class="pre">_key_corrupt</span></code> and
<code class="docutils literal notranslate"><span class="pre">_message_corrupt</span></code> columns will always be <code class="docutils literal notranslate"><span class="pre">false</span></code>.</p>
</section>
<section id="table-schema-and-schema-registry-usage">
<span id="kafka-table-schema-registry"></span><h2 id="table-schema-and-schema-registry-usage">Table schema and schema registry usage<a class="headerlink" href="#table-schema-and-schema-registry-usage" title="Link to this heading">#</a></h2>
<p>The table schema for the messages can be supplied to the connector with a
configuration file or a schema registry. It also provides a mechanism for the
connector to discover tables.</p>
<p>You must configure the supplier with the <code class="docutils literal notranslate"><span class="pre">kafka.table-description-supplier</span></code>
property, setting it to <code class="docutils literal notranslate"><span class="pre">FILE</span></code> or <code class="docutils literal notranslate"><span class="pre">CONFLUENT</span></code>. Each table description
supplier has a separate set of configuration properties.</p>
<p>Refer to the following sections for more information. The <code class="docutils literal notranslate"><span class="pre">FILE</span></code> table
description supplier is the default, and the value is case insensitive.</p>
<section id="file-table-description-supplier">
<h3 id="file-table-description-supplier">File table description supplier<a class="headerlink" href="#file-table-description-supplier" title="Link to this heading">#</a></h3>
<p>To use the file-based table description supplier, set
<code class="docutils literal notranslate"><span class="pre">kafka.table-description-supplier</span></code> to <code class="docutils literal notranslate"><span class="pre">FILE</span></code>. In addition, you must configure
<code class="docutils literal notranslate"><span class="pre">kafka.table-names</span></code> and <code class="docutils literal notranslate"><span class="pre">kafka.table-description-dir</span></code> as described in the
following sections:</p>
<section id="kafka-table-names">
<h4 id="kafka-table-names"><code class="docutils literal notranslate"><span class="pre">kafka.table-names</span></code><a class="headerlink" href="#kafka-table-names" title="Link to this heading">#</a></h4>
<p>Comma-separated list of all tables provided by this catalog. A table name can be
unqualified (simple name), and is placed into the default schema, or it can be
qualified with a schema name (<code class="docutils literal notranslate"><span class="pre">&lt;schema-name&gt;.&lt;table-name&gt;</span></code>).</p>
<p>For each table defined here, a table description file may exist. If no table
description file exists, the table name is used as the topic name on Kafka, and
no data columns are mapped into the table. The table still contains all internal
columns.</p>
<p><strong>This property is required</strong>. At least one table must be defined.</p>
</section>
<section id="kafka-table-description-dir">
<h4 id="kafka-table-description-dir"><code class="docutils literal notranslate"><span class="pre">kafka.table-description-dir</span></code><a class="headerlink" href="#kafka-table-description-dir" title="Link to this heading">#</a></h4>
<p>References a folder within Trino deployment that holds one or more JSON files.
The file must end with <code class="docutils literal notranslate"><span class="pre">.json</span></code> which contain table description files.</p>
<p>This property is optional; the default is <code class="docutils literal notranslate"><span class="pre">etc/kafka</span></code>.</p>
</section>
<section id="table-definition-files">
<span id="id1"></span><h4 id="table-definition-files">Table definition files<a class="headerlink" href="#table-definition-files" title="Link to this heading">#</a></h4>
<p>Kafka maintains topics only as byte messages and leaves it to producers
and consumers to define how a message should be interpreted. For SEP,
this data must be mapped into columns to allow queries against the data.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For textual topics that contain JSON data, it is entirely possible to not use
any table definition files, but instead use the Trino <a class="reference internal" href="../functions/json.html"><span class="doc std std-doc">JSON functions and operators</span></a> to
parse the <code class="docutils literal notranslate"><span class="pre">_message</span></code> column which contains the bytes mapped into a UTF-8 string.
This is cumbersome and makes it difficult to write SQL queries. This only works
when reading data.</p>
</div>
<p>A table definition file consists of a JSON definition for a table. The name of
the file can be arbitrary but must end in <code class="docutils literal notranslate"><span class="pre">.json</span></code>. Place the file in the
directory configured with the <code class="docutils literal notranslate"><span class="pre">kafka.table-description-dir</span></code> property. The table
definition file must be accessible from all SEP nodes.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{
    "tableName": ...,
    "schemaName": ...,
    "topicName": ...,
    "key": {
        "dataFormat": ...,
        "fields": [
            ...
        ]
    },
    "message": {
        "dataFormat": ...,
        "fields": [
            ...
       ]
    }
}
</pre></div>
</div>
<table>
<colgroup>
<col style="width: 27%"/>
<col style="width: 18%"/>
<col style="width: 18%"/>
<col style="width: 36%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Field</p></th>
<th class="head"><p>Required</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">tableName</span></code></p></td>
<td><p>required</p></td>
<td><p>string</p></td>
<td><p>SEP table name defined by this file.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">schemaName</span></code></p></td>
<td><p>optional</p></td>
<td><p>string</p></td>
<td><p>Schema containing the table. If omitted, the default schema name is used.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">topicName</span></code></p></td>
<td><p>required</p></td>
<td><p>string</p></td>
<td><p>Kafka topic that is mapped.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">key</span></code></p></td>
<td><p>optional</p></td>
<td><p>JSON object</p></td>
<td><p>Field definitions for data columns mapped to the message key.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">message</span></code></p></td>
<td><p>optional</p></td>
<td><p>JSON object</p></td>
<td><p>Field definitions for data columns mapped to the message itself.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="key-and-message-in-kafka">
<h4 id="key-and-message-in-kafka">Key and message in Kafka<a class="headerlink" href="#key-and-message-in-kafka" title="Link to this heading">#</a></h4>
<p>Starting with Kafka 0.8, each message in a topic can have an optional key.
A table definition file contains sections for both key and message to map
the data onto table columns.</p>
<p>Each of the <code class="docutils literal notranslate"><span class="pre">key</span></code> and <code class="docutils literal notranslate"><span class="pre">message</span></code> fields in the table definition is a
JSON object that must contain two fields:</p>
<table>
<colgroup>
<col style="width: 27%"/>
<col style="width: 18%"/>
<col style="width: 18%"/>
<col style="width: 36%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Field</p></th>
<th class="head"><p>Required</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">dataFormat</span></code></p></td>
<td><p>required</p></td>
<td><p>string</p></td>
<td><p>Selects the decoder for this group of fields.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">fields</span></code></p></td>
<td><p>required</p></td>
<td><p>JSON array</p></td>
<td><p>A list of field definitions. Each field definition creates a new column in
the SEP table.</p></td>
</tr>
</tbody>
</table>
<p>Each field definition is a JSON object:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{
    "name": ...,
    "type": ...,
    "dataFormat": ...,
    "mapping": ...,
    "formatHint": ...,
    "hidden": ...,
    "comment": ...
}
</pre></div>
</div>
<table>
<colgroup>
<col style="width: 27%"/>
<col style="width: 18%"/>
<col style="width: 18%"/>
<col style="width: 36%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Field</p></th>
<th class="head"><p>Required</p></th>
<th class="head"><p>Type</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">name</span></code></p></td>
<td><p>required</p></td>
<td><p>string</p></td>
<td><p>Name of the column in the SEP table.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">type</span></code></p></td>
<td><p>required</p></td>
<td><p>string</p></td>
<td><p>SEP type of the column.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">dataFormat</span></code></p></td>
<td><p>optional</p></td>
<td><p>string</p></td>
<td><p>Selects the column decoder for this field. Defaults to the default decoder
for this row data format and column type.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">dataSchema</span></code></p></td>
<td><p>optional</p></td>
<td><p>string</p></td>
<td><p>The path or URL where the Avro schema resides. Used only for Avro decoder.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">mapping</span></code></p></td>
<td><p>optional</p></td>
<td><p>string</p></td>
<td><p>Mapping information for the column. This is decoder specific, see below.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">formatHint</span></code></p></td>
<td><p>optional</p></td>
<td><p>string</p></td>
<td><p>Sets a column-specific format hint to the column decoder.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">hidden</span></code></p></td>
<td><p>optional</p></td>
<td><p>boolean</p></td>
<td><p>Hides the column from <code class="docutils literal notranslate"><span class="pre">DESCRIBE</span> <span class="pre">&lt;table</span> <span class="pre">name&gt;</span></code> and <code class="docutils literal notranslate"><span class="pre">SELECT</span> <span class="pre">*</span></code>. Defaults to
<code class="docutils literal notranslate"><span class="pre">false</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">comment</span></code></p></td>
<td><p>optional</p></td>
<td><p>string</p></td>
<td><p>Adds a column comment, which is shown with <code class="docutils literal notranslate"><span class="pre">DESCRIBE</span> <span class="pre">&lt;table</span> <span class="pre">name&gt;</span></code>.</p></td>
</tr>
</tbody>
</table>
<p>There is no limit on field descriptions for either key or message.</p>
</section>
</section>
<section id="confluent-table-description-supplier">
<span id="id2"></span><h3 id="confluent-table-description-supplier">Confluent table description supplier<a class="headerlink" href="#confluent-table-description-supplier" title="Link to this heading">#</a></h3>
<p>The Confluent table description supplier uses the <a class="reference external" href="https://docs.confluent.io/1.0/schema-registry/docs/intro.html">Confluent Schema
Registry</a> to
discover table definitions. It is only tested to work with the Confluent Schema
Registry.</p>
<p>The benefits of using the Confluent table description supplier over the file
table description supplier are:</p>
<ul class="simple">
<li><p>New tables can be defined without a cluster restart.</p></li>
<li><p>Schema updates are detected automatically.</p></li>
<li><p>There is no need to define tables manually.</p></li>
<li><p>Some Protobuf specific types like <code class="docutils literal notranslate"><span class="pre">oneof</span></code> and <code class="docutils literal notranslate"><span class="pre">any</span></code> are supported and mapped
to JSON.</p></li>
</ul>
<p>When using Protobuf decoder with the Confluent table description supplier, some
additional steps are necessary. For details, refer to <a class="reference internal" href="#kafka-requirements"><span class="std std-ref">Requirements</span></a>.</p>
<p>To use the schema registry, set the <code class="docutils literal notranslate"><span class="pre">kafka.table-description-supplier</span></code> property
to <code class="docutils literal notranslate"><span class="pre">CONFLUENT</span></code> . You must also configure the additional properties in the
following table:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Inserts are not supported. The only data format supported is AVRO.</p>
</div>
<table id="id9">
<caption><span class="caption-text">Confluent table description supplier properties</span><a class="headerlink" href="#id9" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 30%"/>
<col style="width: 55%"/>
<col style="width: 15%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property name</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>Default value</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.confluent-schema-registry-url</span></code></p></td>
<td><p>Comma-separated list of URL addresses for the Confluent schema registry. For
example,
<code class="docutils literal notranslate"><span class="pre">http://schema-registry-1.example.org:8081,http://schema-registry-2.example.org:8081</span></code></p></td>
<td></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.confluent-schema-registry-client-cache-size</span></code></p></td>
<td><p>The maximum number of subjects that can be stored in the local cache. The
cache stores the schemas locally by subjectId, and is provided by the
Confluent <code class="docutils literal notranslate"><span class="pre">CachingSchemaRegistry</span></code> client.</p></td>
<td><p>1000</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.empty-field-strategy</span></code></p></td>
<td><p>Avro allows empty struct fields, but this is not allowed in SEP. There
are three strategies for handling empty struct fields:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IGNORE</span></code> - Ignore structs with no fields. This propagates to parents.
For example, an array of structs with no fields is ignored.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">FAIL</span></code> - Fail the query if a struct with no fields is defined.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">MARK</span></code> - Add a marker field named <code class="docutils literal notranslate"><span class="pre">$empty_field_marker</span></code>, which of type
boolean with a null value. This may be desired if the struct represents
a marker field.</p></li>
</ul>
<p>This can also be modified with the <code class="docutils literal notranslate"><span class="pre">empty_field_strategy</span></code> session property.</p>
</td>
<td><p><code class="docutils literal notranslate"><span class="pre">IGNORE</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.confluent-subjects-cache-refresh-interval</span></code></p></td>
<td><p>The interval used for refreshing the list of subjects and the definition
of the schema for the subject in the subject’s cache.</p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">1s</span></code></p></td>
</tr>
</tbody>
</table>
<section id="confluent-subject-to-table-name-mapping">
<h4 id="confluent-subject-to-table-name-mapping">Confluent subject to table name mapping<a class="headerlink" href="#confluent-subject-to-table-name-mapping" title="Link to this heading">#</a></h4>
<p>The <a class="reference external" href="https://docs.confluent.io/platform/current/schema-registry/serdes-develop/index.html#sr-schemas-subject-name-strategy">subject naming
strategy</a>
determines how a subject is resolved from the table name.</p>
<p>The default strategy is the <code class="docutils literal notranslate"><span class="pre">TopicNameStrategy</span></code>, where the key subject is
defined as <code class="docutils literal notranslate"><span class="pre">&lt;topic-name&gt;-key</span></code> and the value subject is defined as
<code class="docutils literal notranslate"><span class="pre">&lt;topic-name&gt;-value</span></code>. If other strategies are used there is no way to
determine the subject name beforehand, so it must be specified manually in the
table name.</p>
<p>To manually specify the key and value subjects, append to the topic name.
For example: <code class="docutils literal notranslate"><span class="pre">&lt;topic</span> <span class="pre">name&gt;&amp;key-subject=&lt;key</span> <span class="pre">subject&gt;&amp;value-subject=&lt;value</span> <span class="pre">subject&gt;</span></code>. Both the <code class="docutils literal notranslate"><span class="pre">key-subject</span></code> and <code class="docutils literal notranslate"><span class="pre">value-subject</span></code> parameters are
optional. If neither are specified, then the default <code class="docutils literal notranslate"><span class="pre">TopicNameStrategy</span></code> is
used to resolve the subject name via the topic name. Note that a case
insensitive match must be done. Identifiers cannot contain upper case
characters.</p>
</section>
<section id="protobuf-specific-type-handling-in-confluent-table-description-supplier">
<h4 id="protobuf-specific-type-handling-in-confluent-table-description-supplier">Protobuf-specific type handling in Confluent table description supplier<a class="headerlink" href="#protobuf-specific-type-handling-in-confluent-table-description-supplier" title="Link to this heading">#</a></h4>
<p>When using the Confluent table description supplier, the following Protobuf
specific types are supported in addition to the <a class="reference internal" href="#kafka-protobuf-decoding"><span class="std std-ref">normally supported
types</span></a>:</p>
<section id="oneof">
<h5 id="oneof">oneof<a class="headerlink" href="#oneof" title="Link to this heading">#</a></h5>
<p>Protobuf schemas containing <code class="docutils literal notranslate"><span class="pre">oneof</span></code> fields are mapped to a <code class="docutils literal notranslate"><span class="pre">JSON</span></code> field in
Trino.</p>
<p>For example, given the following Protobuf schema:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>syntax = "proto3";

message schema {
    oneof test_oneof_column {
        string string_column = 1;
        uint32 integer_column = 2;
        uint64 long_column = 3;
        double double_column = 4;
        float float_column = 5;
        bool boolean_column = 6;
    }
}
</pre></div>
</div>
<p>The corresponding Trino row is a <code class="docutils literal notranslate"><span class="pre">JSON</span></code> field <code class="docutils literal notranslate"><span class="pre">test_oneof_column</span></code> containing a
JSON object with a single key. The value of the key matches the name of the
<code class="docutils literal notranslate"><span class="pre">oneof</span></code> type that is present.</p>
<p>In the previous example, if the Protobuf message has the <code class="docutils literal notranslate"><span class="pre">test_oneof_column</span></code>
containing <code class="docutils literal notranslate"><span class="pre">string_column</span></code> set to a value <code class="docutils literal notranslate"><span class="pre">Trino</span></code> then the corresponding Trino
row includes a column named <code class="docutils literal notranslate"><span class="pre">test_oneof_column</span></code> with the value <code class="docutils literal notranslate"><span class="pre">JSON</span> <span class="pre">'{"string_column":</span> <span class="pre">"Trino"}'</span></code>.</p>
</section>
</section>
</section>
</section>
<section id="kafka-inserts">
<span id="kafka-sql-inserts"></span><h2 id="kafka-inserts">Kafka inserts<a class="headerlink" href="#kafka-inserts" title="Link to this heading">#</a></h2>
<p>The Kafka connector supports the use of <a class="reference internal" href="../sql/insert.html"><span class="doc std std-doc">INSERT</span></a> statements to write
data to a Kafka topic. Table column data is mapped to Kafka messages as defined
in the <a class="reference internal" href="#table-definition-files">table definition file</a>. There are
five supported data formats for key and message encoding:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#raw-encoder"><span class="std std-ref">raw format</span></a></p></li>
<li><p><a class="reference internal" href="#csv-encoder"><span class="std std-ref">CSV format</span></a></p></li>
<li><p><a class="reference internal" href="#json-encoder"><span class="std std-ref">JSON format</span></a></p></li>
<li><p><a class="reference internal" href="#avro-encoder"><span class="std std-ref">Avro format</span></a></p></li>
<li><p><a class="reference internal" href="#kafka-protobuf-encoding"><span class="std std-ref">Protobuf format</span></a></p></li>
</ul>
<p>These data formats each have an encoder that maps column values into bytes to be
sent to a Kafka topic.</p>
<p>SEP supports at-least-once delivery for Kafka producers. This means that
messages are guaranteed to be sent to Kafka topics at least once. If a producer
acknowledgement times out, or if the producer receives an error, it might retry
sending the message. This could result in a duplicate message being sent to the
Kafka topic.</p>
<p>The Kafka connector does not allow the user to define which partition will be
used as the target for a message. If a message includes a key, the producer will
use a hash algorithm to choose the target partition for the message. The same
key will always be assigned the same partition.</p>
</section>
<section id="type-mapping">
<span id="kafka-type-mapping"></span><h2 id="type-mapping">Type mapping<a class="headerlink" href="#type-mapping" title="Link to this heading">#</a></h2>
<p>Because Trino and Kafka each support types that the other does not, this
connector <a class="reference internal" href="../language/types.html#type-mapping-overview"><span class="std std-ref">maps some types</span></a> when reading
(<a class="reference internal" href="#kafka-row-decoding"><span class="std std-ref">decoding</span></a>) or writing (<a class="reference internal" href="#kafka-row-encoding"><span class="std std-ref">encoding</span></a>)
data. Type mapping depends on the format (Raw, Avro, JSON, CSV).</p>
<section id="row-encoding">
<span id="kafka-row-encoding"></span><h3 id="row-encoding">Row encoding<a class="headerlink" href="#row-encoding" title="Link to this heading">#</a></h3>
<p>Encoding is required to allow writing data; it defines how table columns in
Trino map to Kafka keys and message data.</p>
<p>The Kafka connector contains the following encoders:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#raw-encoder"><span class="std std-ref">raw encoder</span></a> - Table columns are mapped to a Kafka
message as raw bytes.</p></li>
<li><p><a class="reference internal" href="#csv-encoder"><span class="std std-ref">CSV encoder</span></a> - Kafka message is formatted as a
comma-separated value.</p></li>
<li><p><a class="reference internal" href="#json-encoder"><span class="std std-ref">JSON encoder</span></a> - Table columns are mapped to JSON
fields.</p></li>
<li><p><a class="reference internal" href="#avro-encoder"><span class="std std-ref">Avro encoder</span></a> - Table columns are mapped to Avro
fields based on an Avro schema.</p></li>
<li><p><a class="reference internal" href="#kafka-protobuf-encoding"><span class="std std-ref">Protobuf encoder</span></a> - Table columns are mapped to
Protobuf fields based on a Protobuf schema.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>A <a class="reference internal" href="#table-definition-files">table definition file</a> must be defined
for the encoder to work.</p>
</div>
<section id="raw-encoder">
<span id="id3"></span><h4 id="raw-encoder">Raw encoder<a class="headerlink" href="#raw-encoder" title="Link to this heading">#</a></h4>
<p>The raw encoder formats the table columns as raw bytes using the mapping
information specified in the
<a class="reference internal" href="#table-definition-files">table definition file</a>.</p>
<p>The following field attributes are supported:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dataFormat</span></code> - Specifies the width of the column data type.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">type</span></code> - Trino data type.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mapping</span></code> - start and optional end position of bytes to convert
(specified as <code class="docutils literal notranslate"><span class="pre">start</span></code> or <code class="docutils literal notranslate"><span class="pre">start:end</span></code>).</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">dataFormat</span></code> attribute selects the number of bytes converted.
If absent, <code class="docutils literal notranslate"><span class="pre">BYTE</span></code> is assumed. All values are signed.</p>
<p>Supported values:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">BYTE</span></code> - one byte</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SHORT</span></code> - two bytes (big-endian)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">INT</span></code> - four bytes (big-endian)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LONG</span></code> - eight bytes (big-endian)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">FLOAT</span></code> - four bytes (IEEE 754 format, big-endian)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code> - eight bytes (IEEE 754 format, big-endian)</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">type</span></code> attribute defines the Trino data type.</p>
<p>Different values of <code class="docutils literal notranslate"><span class="pre">dataFormat</span></code> are supported, depending on the Trino data
type:</p>
<table>
<colgroup>
<col style="width: 50%"/>
<col style="width: 50%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Trino data type</p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">dataFormat</span></code> values</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">BIGINT</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">BYTE</span></code>, <code class="docutils literal notranslate"><span class="pre">SHORT</span></code>, <code class="docutils literal notranslate"><span class="pre">INT</span></code>, <code class="docutils literal notranslate"><span class="pre">LONG</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">INTEGER</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">BYTE</span></code>, <code class="docutils literal notranslate"><span class="pre">SHORT</span></code>, <code class="docutils literal notranslate"><span class="pre">INT</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">SMALLINT</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">BYTE</span></code>, <code class="docutils literal notranslate"><span class="pre">SHORT</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">TINYINT</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">BYTE</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">REAL</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">FLOAT</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">FLOAT</span></code>, <code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">BOOLEAN</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">BYTE</span></code>, <code class="docutils literal notranslate"><span class="pre">SHORT</span></code>, <code class="docutils literal notranslate"><span class="pre">INT</span></code>, <code class="docutils literal notranslate"><span class="pre">LONG</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code> / <code class="docutils literal notranslate"><span class="pre">VARCHAR(x)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">BYTE</span></code></p></td>
</tr>
</tbody>
</table>
<p>No other types are supported.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">mapping</span></code> attribute specifies the range of bytes in a key or
message used for encoding.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Both a start and end position must be defined for <code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code> types.
Otherwise, there is no way to know how many bytes the message contains. The
raw format mapping information is static and cannot be dynamically changed
to fit the variable width of some Trino data types.</p>
</div>
<p>If only a start position is given:</p>
<ul class="simple">
<li><p>For fixed width types, the appropriate number of bytes are used for the
specified <code class="docutils literal notranslate"><span class="pre">dataFormat</span></code> (see above).</p></li>
</ul>
<p>If both a start and end position are given, then:</p>
<ul class="simple">
<li><p>For fixed width types, the size must be equal to number of bytes used by
specified <code class="docutils literal notranslate"><span class="pre">dataFormat</span></code>.</p></li>
<li><p>All bytes between start (inclusive) and end (exclusive) are used.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>All mappings must include a start position for encoding to work.</p>
</div>
<p>The encoding for numeric data types (<code class="docutils literal notranslate"><span class="pre">BIGINT</span></code>, <code class="docutils literal notranslate"><span class="pre">INTEGER</span></code>, <code class="docutils literal notranslate"><span class="pre">SMALLINT</span></code>,
<code class="docutils literal notranslate"><span class="pre">TINYINT</span></code>, <code class="docutils literal notranslate"><span class="pre">REAL</span></code>, <code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code>) is straightforward. All numeric types use
big-endian. Floating point types use IEEE 754 format.</p>
<p>Example raw field definition in a <a class="reference internal" href="#table-definition-files">table definition file</a>
for a Kafka message:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">"tableName"</span><span class="p">:</span><span class="w"> </span><span class="s2">"example_table_name"</span><span class="p">,</span>
<span class="w">  </span><span class="nt">"schemaName"</span><span class="p">:</span><span class="w"> </span><span class="s2">"example_schema_name"</span><span class="p">,</span>
<span class="w">  </span><span class="nt">"topicName"</span><span class="p">:</span><span class="w"> </span><span class="s2">"example_topic_name"</span><span class="p">,</span>
<span class="w">  </span><span class="nt">"key"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="s2">"..."</span><span class="w"> </span><span class="p">},</span>
<span class="w">  </span><span class="nt">"message"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">"dataFormat"</span><span class="p">:</span><span class="w"> </span><span class="s2">"raw"</span><span class="p">,</span>
<span class="w">    </span><span class="nt">"fields"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field1"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BIGINT"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"dataFormat"</span><span class="p">:</span><span class="w"> </span><span class="s2">"LONG"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"mapping"</span><span class="p">:</span><span class="w"> </span><span class="s2">"0"</span>
<span class="w">      </span><span class="p">},</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field2"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"INTEGER"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"dataFormat"</span><span class="p">:</span><span class="w"> </span><span class="s2">"INT"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"mapping"</span><span class="p">:</span><span class="w"> </span><span class="s2">"8"</span>
<span class="w">      </span><span class="p">},</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field3"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"SMALLINT"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"dataFormat"</span><span class="p">:</span><span class="w"> </span><span class="s2">"LONG"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"mapping"</span><span class="p">:</span><span class="w"> </span><span class="s2">"12"</span>
<span class="w">      </span><span class="p">},</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field4"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"VARCHAR(6)"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"dataFormat"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BYTE"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"mapping"</span><span class="p">:</span><span class="w"> </span><span class="s2">"20:26"</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Columns should be defined in the same order they are mapped. There can be no
gaps or overlaps between column mappings. The width of the column as defined by
the column mapping must be equivalent to the width of the <code class="docutils literal notranslate"><span class="pre">dataFormat</span></code> for all
types except for variable width types.</p>
<p>Example insert query for the above table definition:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">INSERT</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">example_raw_table</span><span class="w"> </span><span class="p">(</span><span class="n">field1</span><span class="p">,</span><span class="w"> </span><span class="n">field2</span><span class="p">,</span><span class="w"> </span><span class="n">field3</span><span class="p">,</span><span class="w"> </span><span class="n">field4</span><span class="p">)</span>
<span class="w">  </span><span class="k">VALUES</span><span class="w"> </span><span class="p">(</span><span class="mi">123456789</span><span class="p">,</span><span class="w"> </span><span class="mi">123456</span><span class="p">,</span><span class="w"> </span><span class="mi">1234</span><span class="p">,</span><span class="w"> </span><span class="s1">'abcdef'</span><span class="p">);</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The raw encoder requires the field size to be known ahead of time, including
for variable width data types like <code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code>. It also disallows inserting
values that do not match the width defined in the table definition
file. This is done to ensure correctness, as otherwise longer values are
truncated, and shorter values are read back incorrectly due to an undefined
padding character.</p>
</div>
</section>
<section id="csv-encoder">
<span id="id4"></span><h4 id="csv-encoder">CSV encoder<a class="headerlink" href="#csv-encoder" title="Link to this heading">#</a></h4>
<p>The CSV encoder formats the values for each row as a line of
comma-separated-values (CSV) using UTF-8 encoding. The CSV line is formatted
with a comma <code class="docutils literal notranslate"><span class="pre">,</span></code> as the column delimiter.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">type</span></code> and <code class="docutils literal notranslate"><span class="pre">mapping</span></code> attributes must be defined for each field:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">type</span></code> - Trino data type</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mapping</span></code> - The integer index of the column in the CSV line (the first
column is 0, the second is 1, and so on)</p></li>
</ul>
<p><code class="docutils literal notranslate"><span class="pre">dataFormat</span></code> and <code class="docutils literal notranslate"><span class="pre">formatHint</span></code> are not supported and must be omitted.</p>
<p>The following Trino data types are supported by the CSV encoder:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">BIGINT</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">INTEGER</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SMALLINT</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TINYINT</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">REAL</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">BOOLEAN</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code> / <code class="docutils literal notranslate"><span class="pre">VARCHAR(x)</span></code></p></li>
</ul>
<p>No other types are supported.</p>
<p>Column values are converted to strings before they are formatted as a CSV line.</p>
<p>The following is an example CSV field definition in a <a class="reference internal" href="#table-definition-files">table definition
file</a> for a Kafka message:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">"tableName"</span><span class="p">:</span><span class="w"> </span><span class="s2">"example_table_name"</span><span class="p">,</span>
<span class="w">  </span><span class="nt">"schemaName"</span><span class="p">:</span><span class="w"> </span><span class="s2">"example_schema_name"</span><span class="p">,</span>
<span class="w">  </span><span class="nt">"topicName"</span><span class="p">:</span><span class="w"> </span><span class="s2">"example_topic_name"</span><span class="p">,</span>
<span class="w">  </span><span class="nt">"key"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="s2">"..."</span><span class="w"> </span><span class="p">},</span>
<span class="w">  </span><span class="nt">"message"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">"dataFormat"</span><span class="p">:</span><span class="w"> </span><span class="s2">"csv"</span><span class="p">,</span>
<span class="w">    </span><span class="nt">"fields"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field1"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BIGINT"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"mapping"</span><span class="p">:</span><span class="w"> </span><span class="s2">"0"</span>
<span class="w">      </span><span class="p">},</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field2"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"VARCHAR"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"mapping"</span><span class="p">:</span><span class="w"> </span><span class="s2">"1"</span>
<span class="w">      </span><span class="p">},</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field3"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BOOLEAN"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"mapping"</span><span class="p">:</span><span class="w"> </span><span class="s2">"2"</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Example insert query for the above table definition:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">INSERT</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">example_csv_table</span><span class="w"> </span><span class="p">(</span><span class="n">field1</span><span class="p">,</span><span class="w"> </span><span class="n">field2</span><span class="p">,</span><span class="w"> </span><span class="n">field3</span><span class="p">)</span>
<span class="w">  </span><span class="k">VALUES</span><span class="w"> </span><span class="p">(</span><span class="mi">123456789</span><span class="p">,</span><span class="w"> </span><span class="s1">'example text'</span><span class="p">,</span><span class="w"> </span><span class="k">TRUE</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="json-encoder">
<span id="id5"></span><h4 id="json-encoder">JSON encoder<a class="headerlink" href="#json-encoder" title="Link to this heading">#</a></h4>
<p>The JSON encoder maps table columns to JSON fields defined in the
<a class="reference internal" href="#table-definition-files">table definition file</a> according to
<span class="target" id="index-0"></span><a class="rfc reference external" href="https://datatracker.ietf.org/doc/html/rfc4627.html"><strong>RFC 4627</strong></a>.</p>
<p>For fields, the following attributes are supported:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">type</span></code> - Trino data type of column.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mapping</span></code> - A slash-separated list of field names to select a field from the
JSON object.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dataFormat</span></code> - Name of formatter. Required for temporal types.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">formatHint</span></code> - Pattern to format temporal data. Only use with
<code class="docutils literal notranslate"><span class="pre">custom-date-time</span></code> formatter.</p></li>
</ul>
<p>The following Trino data types are supported by the JSON encoder:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">BIGINT</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">INTEGER</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SMALLINT</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TINYINT</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">REAL</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">BOOLEAN</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DATE</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TIME</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TIME</span> <span class="pre">WITH</span> <span class="pre">TIME</span> <span class="pre">ZONE</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TIMESTAMP</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">TIMESTAMP</span> <span class="pre">WITH</span> <span class="pre">TIME</span> <span class="pre">ZONE</span></code></p></li>
</ul>
<p>No other types are supported.</p>
<p>The following <code class="docutils literal notranslate"><span class="pre">dataFormats</span></code> are available for temporal data:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">iso8601</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rfc2822</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">custom-date-time</span></code> - Formats temporal data according to
<a class="reference external" href="https://www.joda.org/joda-time/key_format.html">Joda Time</a>
pattern given by <code class="docutils literal notranslate"><span class="pre">formatHint</span></code> field.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">milliseconds-since-epoch</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">seconds-since-epoch</span></code></p></li>
</ul>
<p>All temporal data in Kafka supports milliseconds precision.</p>
<p>The following table defines which temporal data types are supported by
<code class="docutils literal notranslate"><span class="pre">dataFormats</span></code>:</p>
<table>
<colgroup>
<col style="width: 40%"/>
<col style="width: 60%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Trino data type</p></th>
<th class="head"><p>Decoding rules</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">DATE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">custom-date-time</span></code>, <code class="docutils literal notranslate"><span class="pre">iso8601</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">TIME</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">custom-date-time</span></code>, <code class="docutils literal notranslate"><span class="pre">iso8601</span></code>, <code class="docutils literal notranslate"><span class="pre">milliseconds-since-epoch</span></code>,
<code class="docutils literal notranslate"><span class="pre">seconds-since-epoch</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">TIME</span> <span class="pre">WITH</span> <span class="pre">TIME</span> <span class="pre">ZONE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">custom-date-time</span></code>, <code class="docutils literal notranslate"><span class="pre">iso8601</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">TIMESTAMP</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">custom-date-time</span></code>, <code class="docutils literal notranslate"><span class="pre">iso8601</span></code>, <code class="docutils literal notranslate"><span class="pre">rfc2822</span></code>, <code class="docutils literal notranslate"><span class="pre">milliseconds-since-epoch</span></code>,
<code class="docutils literal notranslate"><span class="pre">seconds-since-epoch</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">TIMESTAMP</span> <span class="pre">WITH</span> <span class="pre">TIME</span> <span class="pre">ZONE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">custom-date-time</span></code>, <code class="docutils literal notranslate"><span class="pre">iso8601</span></code>, <code class="docutils literal notranslate"><span class="pre">rfc2822</span></code>, <code class="docutils literal notranslate"><span class="pre">milliseconds-since-epoch</span></code>,
<code class="docutils literal notranslate"><span class="pre">seconds-since-epoch</span></code></p></td>
</tr>
</tbody>
</table>
<p>The following is an example JSON field definition in a <a class="reference internal" href="#table-definition-files">table definition
file</a> for a Kafka message:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">"tableName"</span><span class="p">:</span><span class="w"> </span><span class="s2">"example_table_name"</span><span class="p">,</span>
<span class="w">  </span><span class="nt">"schemaName"</span><span class="p">:</span><span class="w"> </span><span class="s2">"example_schema_name"</span><span class="p">,</span>
<span class="w">  </span><span class="nt">"topicName"</span><span class="p">:</span><span class="w"> </span><span class="s2">"example_topic_name"</span><span class="p">,</span>
<span class="w">  </span><span class="nt">"key"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="s2">"..."</span><span class="w"> </span><span class="p">},</span>
<span class="w">  </span><span class="nt">"message"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">"dataFormat"</span><span class="p">:</span><span class="w"> </span><span class="s2">"json"</span><span class="p">,</span>
<span class="w">    </span><span class="nt">"fields"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field1"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BIGINT"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"mapping"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field1"</span>
<span class="w">      </span><span class="p">},</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field2"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"VARCHAR"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"mapping"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field2"</span>
<span class="w">      </span><span class="p">},</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field3"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"TIMESTAMP"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"dataFormat"</span><span class="p">:</span><span class="w"> </span><span class="s2">"custom-date-time"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"formatHint"</span><span class="p">:</span><span class="w"> </span><span class="s2">"yyyy-dd-MM HH:mm:ss.SSS"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"mapping"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field3"</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The following shows an example insert query for the preceding table definition:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">INSERT</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">example_json_table</span><span class="w"> </span><span class="p">(</span><span class="n">field1</span><span class="p">,</span><span class="w"> </span><span class="n">field2</span><span class="p">,</span><span class="w"> </span><span class="n">field3</span><span class="p">)</span>
<span class="w">  </span><span class="k">VALUES</span><span class="w"> </span><span class="p">(</span><span class="mi">123456789</span><span class="p">,</span><span class="w"> </span><span class="s1">'example text'</span><span class="p">,</span><span class="w"> </span><span class="k">TIMESTAMP</span><span class="w"> </span><span class="s1">'2020-07-15 01:02:03.456'</span><span class="p">);</span>
</pre></div>
</div>
</section>
<section id="avro-encoder">
<span id="id6"></span><h4 id="avro-encoder">Avro encoder<a class="headerlink" href="#avro-encoder" title="Link to this heading">#</a></h4>
<p>The Avro encoder serializes rows to Avro records as defined by the
<a class="reference external" href="https://avro.apache.org/docs/current/">Avro schema</a>.
Trino does not support schemaless Avro encoding.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The Avro schema is encoded with the table column values in each Kafka message.</p>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">dataSchema</span></code> must be defined in the table definition file to use the Avro
encoder. It points to the location of the Avro schema file for the key or
message.</p>
<p>Avro schema files can be retrieved via HTTP or HTTPS from remote server with the
syntax:</p>
<p><code class="docutils literal notranslate"><span class="pre">"dataSchema":</span> <span class="pre">"http://example.org/schema/avro_data.avsc"</span></code></p>
<p>Local files need to be available on all Trino nodes and use an absolute path in
the syntax, for example:</p>
<p><code class="docutils literal notranslate"><span class="pre">"dataSchema":</span> <span class="pre">"/usr/local/schema/avro_data.avsc"</span></code></p>
<p>The following field attributes are supported:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code> - Name of the column in the Trino table.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">type</span></code> - Trino data type of column.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mapping</span></code> - A slash-separated list of field names to select a field from the
Avro schema. If the field specified in <code class="docutils literal notranslate"><span class="pre">mapping</span></code> does not exist
in the original Avro schema, then a write operation fails.</p></li>
</ul>
<p>The following table lists supported Trino data types, which can be used in
<code class="docutils literal notranslate"><span class="pre">type</span></code> for the equivalent Avro field type.</p>
<table>
<colgroup>
<col style="width: 50%"/>
<col style="width: 50%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Trino data type</p></th>
<th class="head"><p>Avro data type</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">BIGINT</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">INT</span></code>, <code class="docutils literal notranslate"><span class="pre">LONG</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">REAL</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">FLOAT</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">FLOAT</span></code>, <code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">BOOLEAN</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">BOOLEAN</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code> / <code class="docutils literal notranslate"><span class="pre">VARCHAR(x)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">STRING</span></code></p></td>
</tr>
</tbody>
</table>
<p>No other types are supported.</p>
<p>The following example shows an Avro field definition in a <a class="reference internal" href="#table-definition-files">table definition
file</a> for a Kafka message:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">"tableName"</span><span class="p">:</span><span class="w"> </span><span class="s2">"example_table_name"</span><span class="p">,</span>
<span class="w">  </span><span class="nt">"schemaName"</span><span class="p">:</span><span class="w"> </span><span class="s2">"example_schema_name"</span><span class="p">,</span>
<span class="w">  </span><span class="nt">"topicName"</span><span class="p">:</span><span class="w"> </span><span class="s2">"example_topic_name"</span><span class="p">,</span>
<span class="w">  </span><span class="nt">"key"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="s2">"..."</span><span class="w"> </span><span class="p">},</span>
<span class="w">  </span><span class="nt">"message"</span><span class="p">:</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="nt">"dataFormat"</span><span class="p">:</span><span class="w"> </span><span class="s2">"avro"</span><span class="p">,</span>
<span class="w">    </span><span class="nt">"dataSchema"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/avro_message_schema.avsc"</span><span class="p">,</span>
<span class="w">    </span><span class="nt">"fields"</span><span class="p">:</span>
<span class="w">    </span><span class="p">[</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field1"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BIGINT"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"mapping"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field1"</span>
<span class="w">      </span><span class="p">},</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field2"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"VARCHAR"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"mapping"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field2"</span>
<span class="w">      </span><span class="p">},</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field3"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BOOLEAN"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"mapping"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field3"</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>In the following example, an Avro schema definition for the preceding table
definition is shown:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">"type"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"record"</span><span class="p">,</span>
<span class="w">  </span><span class="nt">"name"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"example_avro_message"</span><span class="p">,</span>
<span class="w">  </span><span class="nt">"namespace"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"io.trino.plugin.kafka"</span><span class="p">,</span>
<span class="w">  </span><span class="nt">"fields"</span><span class="w"> </span><span class="p">:</span>
<span class="w">  </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">"name"</span><span class="p">:</span><span class="s2">"field1"</span><span class="p">,</span>
<span class="w">      </span><span class="nt">"type"</span><span class="p">:[</span><span class="s2">"null"</span><span class="p">,</span><span class="w"> </span><span class="s2">"long"</span><span class="p">],</span>
<span class="w">      </span><span class="nt">"default"</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field2"</span><span class="p">,</span>
<span class="w">      </span><span class="nt">"type"</span><span class="p">:[</span><span class="s2">"null"</span><span class="p">,</span><span class="w"> </span><span class="s2">"string"</span><span class="p">],</span>
<span class="w">      </span><span class="nt">"default"</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span>
<span class="w">    </span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span>
<span class="w">      </span><span class="nt">"name"</span><span class="p">:</span><span class="s2">"field3"</span><span class="p">,</span>
<span class="w">      </span><span class="nt">"type"</span><span class="p">:[</span><span class="s2">"null"</span><span class="p">,</span><span class="w"> </span><span class="s2">"boolean"</span><span class="p">],</span>
<span class="w">      </span><span class="nt">"default"</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">],</span>
<span class="w">  </span><span class="nt">"doc:"</span><span class="w"> </span><span class="p">:</span><span class="w"> </span><span class="s2">"A basic avro schema"</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The following is an example insert query for the preceding table definition:</p>
<blockquote>
<div><dl class="simple myst">
<dt>INSERT INTO example_avro_table (field1, field2, field3)</dt><dd><p>VALUES (123456789, ‘example text’, FALSE);</p>
</dd>
</dl>
</div></blockquote>
</section>
<section id="protobuf-encoder">
<span id="kafka-protobuf-encoding"></span><h4 id="protobuf-encoder">Protobuf encoder<a class="headerlink" href="#protobuf-encoder" title="Link to this heading">#</a></h4>
<p>The Protobuf encoder serializes rows to Protobuf DynamicMessages as defined by
the <a class="reference external" href="https://developers.google.com/protocol-buffers/docs/overview">Protobuf schema</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The Protobuf schema is encoded with the table column values in each Kafka message.</p>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">dataSchema</span></code> must be defined in the table definition file to use the
Protobuf encoder. It points to the location of the <code class="docutils literal notranslate"><span class="pre">proto</span></code> file for the key
or message.</p>
<p>Protobuf schema files can be retrieved via HTTP or HTTPS from a remote server
with the syntax:</p>
<p><code class="docutils literal notranslate"><span class="pre">"dataSchema":</span> <span class="pre">"http://example.org/schema/schema.proto"</span></code></p>
<p>Local files need to be available on all Trino nodes and use an absolute path in
the syntax, for example:</p>
<p><code class="docutils literal notranslate"><span class="pre">"dataSchema":</span> <span class="pre">"/usr/local/schema/schema.proto"</span></code></p>
<p>The following field attributes are supported:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code> - Name of the column in the Trino table.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">type</span></code> - Trino type of column.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mapping</span></code> - slash-separated list of field names to select a field from the
Protobuf schema. If the field specified in <code class="docutils literal notranslate"><span class="pre">mapping</span></code> does not exist in the
original Protobuf schema, then a write operation fails.</p></li>
</ul>
<p>The following table lists supported Trino data types, which can be used in <code class="docutils literal notranslate"><span class="pre">type</span></code>
for the equivalent Protobuf field type.</p>
<table>
<colgroup>
<col style="width: 50%"/>
<col style="width: 50%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Trino data type</p></th>
<th class="head"><p>Protobuf data type</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">BOOLEAN</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">bool</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">INTEGER</span> </code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int32</span></code>, <code class="docutils literal notranslate"><span class="pre">uint32</span></code>, <code class="docutils literal notranslate"><span class="pre">sint32</span></code>, <code class="docutils literal notranslate"><span class="pre">fixed32</span></code>, <code class="docutils literal notranslate"><span class="pre">sfixed32</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">BIGINT</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int64</span></code>, <code class="docutils literal notranslate"><span class="pre">uint64</span></code>, <code class="docutils literal notranslate"><span class="pre">sint64</span></code>, <code class="docutils literal notranslate"><span class="pre">fixed64</span></code>, <code class="docutils literal notranslate"><span class="pre">sfixed64</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">double</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">REAL</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">float</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code> / <code class="docutils literal notranslate"><span class="pre">VARCHAR(x)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">string</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">VARBINARY</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">bytes</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">ROW</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Message</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">ARRAY</span></code></p></td>
<td><p>Protobuf type with <code class="docutils literal notranslate"><span class="pre">repeated</span></code> field</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">MAP</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Map</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">TIMESTAMP</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Timestamp</span></code>, predefined in <code class="docutils literal notranslate"><span class="pre">timestamp.proto</span></code></p></td>
</tr>
</tbody>
</table>
<p>The following example shows a Protobuf field definition in a <a class="reference internal" href="#table-definition-files">table definition
file</a> for a Kafka message:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">"tableName"</span><span class="p">:</span><span class="w"> </span><span class="s2">"example_table_name"</span><span class="p">,</span>
<span class="w">  </span><span class="nt">"schemaName"</span><span class="p">:</span><span class="w"> </span><span class="s2">"example_schema_name"</span><span class="p">,</span>
<span class="w">  </span><span class="nt">"topicName"</span><span class="p">:</span><span class="w"> </span><span class="s2">"example_topic_name"</span><span class="p">,</span>
<span class="w">  </span><span class="nt">"key"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="s2">"..."</span><span class="w"> </span><span class="p">},</span>
<span class="w">  </span><span class="nt">"message"</span><span class="p">:</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">    </span><span class="nt">"dataFormat"</span><span class="p">:</span><span class="w"> </span><span class="s2">"protobuf"</span><span class="p">,</span>
<span class="w">    </span><span class="nt">"dataSchema"</span><span class="p">:</span><span class="w"> </span><span class="s2">"/message_schema.proto"</span><span class="p">,</span>
<span class="w">    </span><span class="nt">"fields"</span><span class="p">:</span>
<span class="w">    </span><span class="p">[</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field1"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BIGINT"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"mapping"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field1"</span>
<span class="w">      </span><span class="p">},</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field2"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"VARCHAR"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"mapping"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field2"</span>
<span class="w">      </span><span class="p">},</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">        </span><span class="nt">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field3"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"BOOLEAN"</span><span class="p">,</span>
<span class="w">        </span><span class="nt">"mapping"</span><span class="p">:</span><span class="w"> </span><span class="s2">"field3"</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">    </span><span class="p">]</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>In the following example, a Protobuf schema definition for the preceding table
definition is shown:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>syntax = "proto3";

message schema {
  uint64 field1 = 1 ;
  string field2 = 2;
  bool field3 = 3;
}
</pre></div>
</div>
<p>The following is an example insert query for the preceding table definition:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">INSERT</span><span class="w"> </span><span class="k">INTO</span><span class="w"> </span><span class="n">example_protobuf_table</span><span class="w"> </span><span class="p">(</span><span class="n">field1</span><span class="p">,</span><span class="w"> </span><span class="n">field2</span><span class="p">,</span><span class="w"> </span><span class="n">field3</span><span class="p">)</span>
<span class="w">  </span><span class="k">VALUES</span><span class="w"> </span><span class="p">(</span><span class="mi">123456789</span><span class="p">,</span><span class="w"> </span><span class="s1">'example text'</span><span class="p">,</span><span class="w"> </span><span class="k">FALSE</span><span class="p">);</span>
</pre></div>
</div>
</section>
</section>
<section id="row-decoding">
<span id="kafka-row-decoding"></span><h3 id="row-decoding">Row decoding<a class="headerlink" href="#row-decoding" title="Link to this heading">#</a></h3>
<p>For key and message, a decoder is used to map message and key data onto table
columns.</p>
<p>The Kafka connector contains the following decoders:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">raw</span></code> - Kafka message is not interpreted; ranges of raw message bytes are
mapped to table columns.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">csv</span></code> - Kafka message is interpreted as comma separated message, and fields
are mapped to table columns.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">json</span></code> - Kafka message is parsed as JSON, and JSON fields are mapped to table
columns.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">avro</span></code> - Kafka message is parsed based on an Avro schema, and Avro fields are
mapped to table columns.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">protobuf</span></code> - Kafka message is parsed based on a Protobuf schema, and Protobuf
fields are mapped to table columns.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If no table definition file exists for a table, the <code class="docutils literal notranslate"><span class="pre">dummy</span></code> decoder is used,
which does not expose any columns.</p>
</div>
<section id="raw-decoder">
<h4 id="raw-decoder">Raw decoder<a class="headerlink" href="#raw-decoder" title="Link to this heading">#</a></h4>
<p>The raw decoder supports reading of raw byte-based values from Kafka message
or key, and converting it into Trino columns.</p>
<p>For fields, the following attributes are supported:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">dataFormat</span></code> - Selects the width of the data type converted.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">type</span></code> - Trino data type. See table later min this document for list of
supported data types.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mapping</span></code> - <code class="docutils literal notranslate"><span class="pre">&lt;start&gt;[:&lt;end&gt;]</span></code> - Start and end position of bytes to convert
(optional).</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">dataFormat</span></code> attribute selects the number of bytes converted.
If absent, <code class="docutils literal notranslate"><span class="pre">BYTE</span></code> is assumed. All values are signed.</p>
<p>Supported values are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">BYTE</span></code> - one byte</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SHORT</span></code> - two bytes (big-endian)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">INT</span></code> - four bytes (big-endian)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">LONG</span></code> - eight bytes (big-endian)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">FLOAT</span></code> - four bytes (IEEE 754 format)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code> - eight bytes (IEEE 754 format)</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">type</span></code> attribute defines the Trino data type on which the value is mapped.</p>
<p>Depending on the Trino type assigned to a column, different values of dataFormat
can be used:</p>
<table>
<colgroup>
<col style="width: 50%"/>
<col style="width: 50%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Trino data type</p></th>
<th class="head"><p>Allowed <code class="docutils literal notranslate"><span class="pre">dataFormat</span></code> values</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">BIGINT</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">BYTE</span></code>, <code class="docutils literal notranslate"><span class="pre">SHORT</span></code>, <code class="docutils literal notranslate"><span class="pre">INT</span></code>, <code class="docutils literal notranslate"><span class="pre">LONG</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">INTEGER</span> </code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">BYTE</span></code>, <code class="docutils literal notranslate"><span class="pre">SHORT</span></code>, <code class="docutils literal notranslate"><span class="pre">INT</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">SMALLINT</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">BYTE</span></code>, <code class="docutils literal notranslate"><span class="pre">SHORT</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">TINYINT</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">BYTE</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code>, <code class="docutils literal notranslate"><span class="pre">FLOAT</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">BOOLEAN</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">BYTE</span></code>, <code class="docutils literal notranslate"><span class="pre">SHORT</span></code>, <code class="docutils literal notranslate"><span class="pre">INT</span></code>, <code class="docutils literal notranslate"><span class="pre">LONG</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code> / <code class="docutils literal notranslate"><span class="pre">VARCHAR(x)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">BYTE</span></code></p></td>
</tr>
</tbody>
</table>
<p>No other types are supported.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">mapping</span></code> attribute specifies the range of the bytes in a key or message
used for decoding. It can be one or two numbers separated by a colon
(<code class="docutils literal notranslate"><span class="pre">&lt;start&gt;[:&lt;end&gt;]</span></code>).</p>
<p>If only a start position is given:</p>
<ul class="simple">
<li><p>For fixed width types, the column will use the appropriate number of bytes for
the specified <code class="docutils literal notranslate"><span class="pre">dataFormat</span></code> (see above).</p></li>
<li><p>When <code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code> value is decoded, all bytes from start position till the end of
the message will be used.</p></li>
</ul>
<p>If start and end position are given:</p>
<ul class="simple">
<li><p>For fixed width types, the size must be equal to number of bytes used by
specified <code class="docutils literal notranslate"><span class="pre">dataFormat</span></code>.</p></li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code> all bytes between start (inclusive) and end (exclusive) are
used.</p></li>
</ul>
<p>If no <code class="docutils literal notranslate"><span class="pre">mapping</span></code> attribute is specified, it is equivalent to setting start
position to 0 and leaving end position undefined.</p>
<p>The decoding scheme of numeric data types (<code class="docutils literal notranslate"><span class="pre">BIGINT</span></code>, <code class="docutils literal notranslate"><span class="pre">INTEGER</span></code>, <code class="docutils literal notranslate"><span class="pre">SMALLINT</span></code>,
<code class="docutils literal notranslate"><span class="pre">TINYINT</span></code>, <code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code>) is straightforward. A sequence of bytes is read from input
message and decoded according to either:</p>
<ul class="simple">
<li><p>big-endian encoding (for integer types)</p></li>
<li><p>IEEE 754 format for (for <code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code>).</p></li>
</ul>
<p>Length of decoded byte sequence is implied by the <code class="docutils literal notranslate"><span class="pre">dataFormat</span></code>.</p>
<p>For <code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code> data type a sequence of bytes is interpreted according to UTF-8
encoding.</p>
</section>
<section id="csv-decoder">
<h4 id="csv-decoder">CSV decoder<a class="headerlink" href="#csv-decoder" title="Link to this heading">#</a></h4>
<p>The CSV decoder converts the bytes representing a message or key into a string
using UTF-8 encoding and then interprets the result as a CSV, comma-separated
value line.</p>
<p>For fields, the <code class="docutils literal notranslate"><span class="pre">type</span></code> and <code class="docutils literal notranslate"><span class="pre">mapping</span></code> attributes must be defined:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">type</span></code> - Trino data type. See the following table for a list of supported data
types.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mapping</span></code> - The index of the field in the CSV record.</p></li>
</ul>
<p>The <code class="docutils literal notranslate"><span class="pre">dataFormat</span></code> and <code class="docutils literal notranslate"><span class="pre">formatHint</span></code> attributes are not supported and must be
omitted.</p>
<p>Table below lists supported Trino types, which can be used in <code class="docutils literal notranslate"><span class="pre">type</span></code> and
decoding scheme:</p>
<table>
<colgroup>
<col style="width: 50%"/>
<col style="width: 50%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Trino data type</p></th>
<th class="head"><p>Decoding rules</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">BIGINT</span></code>, <code class="docutils literal notranslate"><span class="pre">INTEGER</span></code>, <code class="docutils literal notranslate"><span class="pre">SMALLINT</span></code>, <code class="docutils literal notranslate"><span class="pre">TINYINT</span></code></p></td>
<td><p>Decoded using Java <code class="docutils literal notranslate"><span class="pre">Long.parseLong()</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code></p></td>
<td><p>Decoded using Java <code class="docutils literal notranslate"><span class="pre">Double.parseDouble()</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">BOOLEAN</span></code></p></td>
<td><p>“true” character sequence maps to <code class="docutils literal notranslate"><span class="pre">true</span></code>; Other character sequences map to
<code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code>, <code class="docutils literal notranslate"><span class="pre">VARCHAR(x)</span></code></p></td>
<td><p>Used as is</p></td>
</tr>
</tbody>
</table>
<p>No other types are supported.</p>
</section>
<section id="json-decoder">
<h4 id="json-decoder">JSON decoder<a class="headerlink" href="#json-decoder" title="Link to this heading">#</a></h4>
<p>The JSON decoder converts the bytes representing a message or key into a JSON
according to <span class="target" id="index-1"></span><a class="rfc reference external" href="https://datatracker.ietf.org/doc/html/rfc4627.html"><strong>RFC 4627</strong></a>. Note that the message or key <em>MUST</em> convert into a
JSON object, not an array or simple type.</p>
<p>For fields, the following attributes are supported:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">type</span></code> - Trino data type of column.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">dataFormat</span></code> - Field decoder to be used for column.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mapping</span></code> - slash-separated list of field names to select a field from the
JSON object.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">formatHint</span></code> - Only for <code class="docutils literal notranslate"><span class="pre">custom-date-time</span></code>.</p></li>
</ul>
<p>The JSON decoder supports multiple field decoders, with <code class="docutils literal notranslate"><span class="pre">_default</span></code> being used
for standard table columns and a number of decoders for date- and time-based
types.</p>
<p>The following table lists Trino data types, which can be used as in <code class="docutils literal notranslate"><span class="pre">type</span></code>, and
matching field decoders, which can be specified via <code class="docutils literal notranslate"><span class="pre">dataFormat</span></code> attribute.</p>
<table>
<colgroup>
<col style="width: 50%"/>
<col style="width: 50%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Trino data type</p></th>
<th class="head"><p>Allowed <code class="docutils literal notranslate"><span class="pre">dataFormat</span></code> values</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">BIGINT</span></code>, <code class="docutils literal notranslate"><span class="pre">INTEGER</span></code>, <code class="docutils literal notranslate"><span class="pre">SMALLINT</span></code>, <code class="docutils literal notranslate"><span class="pre">TINYINT</span></code>, <code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code>, <code class="docutils literal notranslate"><span class="pre">BOOLEAN</span></code>, <code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code>, <code class="docutils literal notranslate"><span class="pre">VARCHAR(x)</span></code></p></td>
<td><p>Default field decoder (omitted <code class="docutils literal notranslate"><span class="pre">dataFormat</span></code> attribute)</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">DATE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">custom-date-time</span></code>, <code class="docutils literal notranslate"><span class="pre">iso8601</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">TIME</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">custom-date-time</span></code>, <code class="docutils literal notranslate"><span class="pre">iso8601</span></code>, <code class="docutils literal notranslate"><span class="pre">milliseconds-since-epoch</span></code>, <code class="docutils literal notranslate"><span class="pre">seconds-since-epoch</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">TIME</span> <span class="pre">WITH</span> <span class="pre">TIME</span> <span class="pre">ZONE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">custom-date-time</span></code>, <code class="docutils literal notranslate"><span class="pre">iso8601</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">TIMESTAMP</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">custom-date-time</span></code>, <code class="docutils literal notranslate"><span class="pre">iso8601</span></code>, <code class="docutils literal notranslate"><span class="pre">rfc2822</span></code>, <code class="docutils literal notranslate"><span class="pre">milliseconds-since-epoch</span></code>, <code class="docutils literal notranslate"><span class="pre">seconds-since-epoch</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">TIMESTAMP</span> <span class="pre">WITH</span> <span class="pre">TIME</span> <span class="pre">ZONE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">custom-date-time</span></code>, <code class="docutils literal notranslate"><span class="pre">iso8601</span></code>, <code class="docutils literal notranslate"><span class="pre">rfc2822</span></code>, <code class="docutils literal notranslate"><span class="pre">milliseconds-since-epoch</span></code> <code class="docutils literal notranslate"><span class="pre">seconds-since-epoch</span></code></p></td>
</tr>
</tbody>
</table>
<p>No other types are supported.</p>
<section id="default-field-decoder">
<h5 id="default-field-decoder">Default field decoder<a class="headerlink" href="#default-field-decoder" title="Link to this heading">#</a></h5>
<p>This is the standard field decoder, supporting all the Trino physical data
types. A field value is transformed under JSON conversion rules into boolean,
long, double or string values. For non-date/time based columns, this decoder
should be used.</p>
</section>
<section id="date-and-time-decoders">
<h5 id="date-and-time-decoders">Date and time decoders<a class="headerlink" href="#date-and-time-decoders" title="Link to this heading">#</a></h5>
<p>To convert values from JSON objects into Trino <code class="docutils literal notranslate"><span class="pre">DATE</span></code>, <code class="docutils literal notranslate"><span class="pre">TIME</span></code>, <code class="docutils literal notranslate"><span class="pre">TIME</span> <span class="pre">WITH</span> <span class="pre">TIME</span> <span class="pre">ZONE</span></code>, <code class="docutils literal notranslate"><span class="pre">TIMESTAMP</span></code> or <code class="docutils literal notranslate"><span class="pre">TIMESTAMP</span> <span class="pre">WITH</span> <span class="pre">TIME</span> <span class="pre">ZONE</span></code> columns, special decoders must
be selected using the <code class="docutils literal notranslate"><span class="pre">dataFormat</span></code> attribute of a field definition.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">iso8601</span></code> - Text based, parses a text field as an ISO 8601 timestamp.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">rfc2822</span></code> - Text based, parses a text field as an <span class="target" id="index-2"></span><a class="rfc reference external" href="https://datatracker.ietf.org/doc/html/rfc2822.html"><strong>RFC 2822</strong></a> timestamp.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">custom-date-time</span></code> - Text based, parses a text field according to Joda format
pattern : specified via <code class="docutils literal notranslate"><span class="pre">formatHint</span></code> attribute. Format pattern should conform
to
<a class="reference external" href="https://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html">https://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html</a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">milliseconds-since-epoch</span></code> - Number-based; interprets a text or number as
number of milliseconds since the epoch.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">seconds-since-epoch</span></code> - Number-based; interprets a text or number as number of
milliseconds since the epoch.</p></li>
</ul>
<p>For <code class="docutils literal notranslate"><span class="pre">TIMESTAMP</span> <span class="pre">WITH</span> <span class="pre">TIME</span> <span class="pre">ZONE</span></code> and <code class="docutils literal notranslate"><span class="pre">TIME</span> <span class="pre">WITH</span> <span class="pre">TIME</span> <span class="pre">ZONE</span></code> data types, if timezone
information is present in decoded value, it will be used as Trino value.
Otherwise result time zone will be set to <code class="docutils literal notranslate"><span class="pre">UTC</span></code>.</p>
</section>
</section>
<section id="avro-decoder">
<h4 id="avro-decoder">Avro decoder<a class="headerlink" href="#avro-decoder" title="Link to this heading">#</a></h4>
<p>The Avro decoder converts the bytes representing a message or key in Avro format
based on a schema. The message must have the Avro schema embedded. Trino does
not support schemaless Avro decoding.</p>
<p>For key/message, using <code class="docutils literal notranslate"><span class="pre">avro</span></code> decoder, the <code class="docutils literal notranslate"><span class="pre">dataSchema</span></code> must be defined. This
should point to the location of a valid Avro schema file of the message which
needs to be decoded. This location can be a remote web server (For example,
<code class="docutils literal notranslate"><span class="pre">dataSchema:</span> <span class="pre">'http://example.org/schema/avro_data.avsc'</span></code>) or local file
system(For example, <code class="docutils literal notranslate"><span class="pre">dataSchema:</span> <span class="pre">'/usr/local/schema/avro_data.avsc'</span></code>). The
decoder fails if this location is not accessible from the Trino coordinator
node.</p>
<p>For fields, the following attributes are supported:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code> - Name of the column in the Trino table.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">type</span></code> - Trino data type of column.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mapping</span></code> - A slash-separated list of field names to select a field from the
Avro schema. If field specified in <code class="docutils literal notranslate"><span class="pre">mapping</span></code> does not exist in the original
Avro schema, then a read operation returns <code class="docutils literal notranslate"><span class="pre">NULL</span></code>.</p></li>
</ul>
<p>The following table lists the supported Trino types which can be used in <code class="docutils literal notranslate"><span class="pre">type</span></code>
for the equivalent Avro field types:</p>
<table>
<colgroup>
<col style="width: 50%"/>
<col style="width: 50%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Trino data type</p></th>
<th class="head"><p>Allowed Avro data type</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">BIGINT</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">INT</span></code>, <code class="docutils literal notranslate"><span class="pre">LONG</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code>, <code class="docutils literal notranslate"><span class="pre">FLOAT</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">BOOLEAN</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">BOOLEAN</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code>, <code class="docutils literal notranslate"><span class="pre">VARCHAR(x)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">STRING</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">VARBINARY</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">FIXED</span></code>, <code class="docutils literal notranslate"><span class="pre">BYTES</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">ARRAY</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">ARRAY</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">MAP</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">MAP</span></code></p></td>
</tr>
</tbody>
</table>
<p>No other types are supported.</p>
<section id="avro-schema-evolution">
<h5 id="avro-schema-evolution">Avro schema evolution<a class="headerlink" href="#avro-schema-evolution" title="Link to this heading">#</a></h5>
<p>The Avro decoder supports schema evolution feature with backward compatibility.
With backward compatibility, a newer schema can be used to read Avro data
created with an older schema. Any change in the Avro schema must also be
reflected in Trino’s topic definition file. Newly added/renamed fields <em>must</em>
have a default value in the Avro schema file.</p>
<p>The schema evolution behavior is as follows:</p>
<ul class="simple">
<li><p>Column added in new schema: Data created with an older schema produces a
<em>default</em> value when the table is using the new schema.</p></li>
<li><p>Column removed in new schema: Data created with an older schema no longer
outputs the data from the column that was removed.</p></li>
<li><p>Column is renamed in the new schema: This is equivalent to removing the column
and adding a new one, and data created with an older schema produces a
<em>default</em> value when table is using the new schema.</p></li>
<li><p>Changing type of column in the new schema: If the type coercion is supported
by Avro, then the conversion happens. An error is thrown for incompatible
types.</p></li>
</ul>
</section>
</section>
<section id="protobuf-decoder">
<span id="kafka-protobuf-decoding"></span><h4 id="protobuf-decoder">Protobuf decoder<a class="headerlink" href="#protobuf-decoder" title="Link to this heading">#</a></h4>
<p>The Protobuf decoder converts the bytes representing a message or key in
Protobuf formatted message based on a schema.</p>
<p>For key/message, using the <code class="docutils literal notranslate"><span class="pre">protobuf</span></code> decoder, the <code class="docutils literal notranslate"><span class="pre">dataSchema</span></code> must be defined.
It points to the location of a valid <code class="docutils literal notranslate"><span class="pre">proto</span></code> file of the message which needs to
be decoded. This location can be a remote web server, <code class="docutils literal notranslate"><span class="pre">dataSchema:</span> <span class="pre">'http://example.org/schema/schema.proto'</span></code>,  or local file, <code class="docutils literal notranslate"><span class="pre">dataSchema:</span> <span class="pre">'/usr/local/schema/schema.proto'</span></code>. The decoder fails if the location is not
accessible from the coordinator.</p>
<p>For fields, the following attributes are supported:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">name</span></code> - Name of the column in the Trino table.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">type</span></code> - Trino data type of column.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">mapping</span></code> - slash-separated list of field names to select a field from the
Protobuf schema. If field specified in <code class="docutils literal notranslate"><span class="pre">mapping</span></code> does not exist in the
original <code class="docutils literal notranslate"><span class="pre">proto</span></code> file then a read operation returns NULL.</p></li>
</ul>
<p>The following table lists the supported Trino types which can be used in <code class="docutils literal notranslate"><span class="pre">type</span></code>
for the equivalent Protobuf field types:</p>
<table>
<colgroup>
<col style="width: 50%"/>
<col style="width: 50%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Trino data type</p></th>
<th class="head"><p>Allowed Protobuf data type</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">BOOLEAN</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">bool</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">INTEGER</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int32</span></code>, <code class="docutils literal notranslate"><span class="pre">uint32</span></code>, <code class="docutils literal notranslate"><span class="pre">sint32</span></code>, <code class="docutils literal notranslate"><span class="pre">fixed32</span></code>, <code class="docutils literal notranslate"><span class="pre">sfixed32</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">BIGINT</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">int64</span></code>, <code class="docutils literal notranslate"><span class="pre">uint64</span></code>, <code class="docutils literal notranslate"><span class="pre">sint64</span></code>, <code class="docutils literal notranslate"><span class="pre">fixed64</span></code>, <code class="docutils literal notranslate"><span class="pre">sfixed64</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">DOUBLE</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">double</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">REAL</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">float</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">VARCHAR</span></code> / <code class="docutils literal notranslate"><span class="pre">VARCHAR(x)</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">string</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">VARBINARY</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">bytes</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">ROW</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Message</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">ARRAY</span></code></p></td>
<td><p>Protobuf type with <code class="docutils literal notranslate"><span class="pre">repeated</span></code> field</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">MAP</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Map</span></code></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">TIMESTAMP</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">Timestamp</span></code>, predefined in <code class="docutils literal notranslate"><span class="pre">timestamp.proto</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">JSON</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">oneof</span></code> (Confluent table supplier only), <code class="docutils literal notranslate"><span class="pre">Any</span></code></p></td>
</tr>
</tbody>
</table>
<section id="any">
<h5 id="any">any<a class="headerlink" href="#any" title="Link to this heading">#</a></h5>
<p>Message types with an <a class="reference external" href="https://protobuf.dev/programming-guides/proto3/#any">Any</a>
field contain an arbitrary serialized message as bytes and a type URL to resolve
that message’s type with a scheme of <code class="docutils literal notranslate"><span class="pre">file://</span></code>, <code class="docutils literal notranslate"><span class="pre">http://</span></code>, or <code class="docutils literal notranslate"><span class="pre">https://</span></code>.
The connector reads the contents of the URL to create the type descriptor
for the <code class="docutils literal notranslate"><span class="pre">Any</span></code> message and convert the message to JSON. This behavior is enabled
by setting <code class="docutils literal notranslate"><span class="pre">kafka.protobuf-any-support-enabled</span></code> to <code class="docutils literal notranslate"><span class="pre">true</span></code>.</p>
<p>The descriptors for each distinct URL are cached for performance reasons and
any modifications made to the type returned by the URL requires a restart of
Trino.</p>
<p>For example, the following Protobuf schema defines <code class="docutils literal notranslate"><span class="pre">MyMessage</span></code> with three
columns:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>syntax = "proto3";

message MyMessage {
  string stringColumn = 1;
  uint32 integerColumn = 2;
  uint64 longColumn = 3;
}
</pre></div>
</div>
<p>And a separate schema which uses an <code class="docutils literal notranslate"><span class="pre">Any</span></code> type which is a packed message
of the above type and a valid URL:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>syntax = "proto3";

import "google/protobuf/any.proto";

message schema {
    google.protobuf.Any any_message = 1;
}
</pre></div>
</div>
<p>The corresponding Trino column is named <code class="docutils literal notranslate"><span class="pre">any_message</span></code> of type <code class="docutils literal notranslate"><span class="pre">JSON</span></code>
containing a JSON-serialized representation of the Protobuf message:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>{
  "@type":"file:///path/to/schemas/MyMessage",
  "longColumn":"493857959588286460",
  "numberColumn":"ONE",
  "stringColumn":"Trino"
}
</pre></div>
</div>
</section>
<section id="protobuf-schema-evolution">
<h5 id="protobuf-schema-evolution">Protobuf schema evolution<a class="headerlink" href="#protobuf-schema-evolution" title="Link to this heading">#</a></h5>
<p>The Protobuf decoder supports the schema evolution feature with backward
compatibility. With backward compatibility, a newer schema can be used to read
Protobuf data created with an older schema. Any change in the Protobuf schema
must also be reflected in the topic definition file.</p>
<p>The schema evolution behavior is as follows:</p>
<ul class="simple">
<li><p>Column added in new schema: Data created with an older schema produces a
<em>default</em> value when the table is using the new schema.</p></li>
<li><p>Column removed in new schema: Data created with an older schema no longer
outputs the data from the column that was removed.</p></li>
<li><p>Column is renamed in the new schema: This is equivalent to removing the column
and adding a new one, and data created with an older schema produces a
<em>default</em> value when table is using the new schema.</p></li>
<li><p>Changing type of column in the new schema: If the type coercion is supported
by Protobuf, then the conversion happens. An error is thrown for incompatible
types.</p></li>
</ul>
<p><strong>Limitations</strong></p>
<ul class="simple">
<li><p>Protobuf Timestamp has a nanosecond precision but Trino supports
decoding/encoding at microsecond precision.</p></li>
</ul>
</section>
</section>
</section>
</section>
<section id="sql-support">
<span id="kafka-sql-support"></span><h2 id="sql-support">SQL support<a class="headerlink" href="#sql-support" title="Link to this heading">#</a></h2>
<p>The connector provides read and write access to data and metadata in SEP
tables populated by Kafka topics. See <a class="reference internal" href="#kafka-row-decoding"><span class="std std-ref">Row decoding</span></a> for more
information.</p>
<p>In addition to the <a class="reference internal" href="../language/sql-support.html#sql-globally-available"><span class="std std-ref">globally available</span></a> and <a class="reference internal" href="../language/sql-support.html#sql-read-operations"><span class="std std-ref">read
operation</span></a> statements, the connector supports the following
features:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../sql/insert.html"><span class="doc std std-doc">INSERT</span></a>, encoded to a specified data format.
<a class="reference internal" href="#kafka-sql-inserts"><span class="std std-ref">Kafka inserts</span></a>.</p></li>
</ul>
</section>
<section id="performance">
<h2 id="performance">Performance<a class="headerlink" href="#performance" title="Link to this heading">#</a></h2>
<p>The connector includes a number of performance improvements, detailed in the
following sections.</p>
<section id="parallelism">
<h3 id="parallelism">Parallelism<a class="headerlink" href="#parallelism" title="Link to this heading">#</a></h3>
<p>The connector reads and writes message data from Kafka topics in parallel across
workers. The size of data sets for this parallelization is configurable and can
therefore be adapted to your specific needs.</p>
<p>For a detailed example, see the <a class="reference internal" href="kafka-tutorial.html"><span class="doc std std-doc">Kafka connector tutorial</span></a>.</p>
</section>
<section id="starburst-cached-views">
<h3 id="starburst-cached-views">Starburst Cached Views<a class="headerlink" href="#starburst-cached-views" title="Link to this heading">#</a></h3>
<p>The connector supports <a class="reference internal" href="../admin/table-scan-redirection.html"><span class="doc std std-doc">table scan redirection</span></a>
to improve performance and reduce load on the data source.</p>
</section>
</section>
<section id="security">
<h2 id="security">Security<a class="headerlink" href="#security" title="Link to this heading">#</a></h2>
<p>The connector includes a number of security-related features, detailed in the
following sections.</p>
<section id="password-credential-pass-through">
<span id="kafka-password-credential-pass-through"></span><h3 id="password-credential-pass-through">Password credential pass-through<a class="headerlink" href="#password-credential-pass-through" title="Link to this heading">#</a></h3>
<p>The connector supports <a class="reference internal" href="../security/password-passthrough.html"><span class="doc std std-doc">password credential
pass-through</span></a>. To enable it, edit the catalog
properties file to include the authentication type:</p>
<div class="highlight-properties notranslate"><div class="highlight"><pre><span></span><span class="na">kafka.authentication.type</span><span class="o">=</span><span class="s">PASSWORD_PASS_THROUGH</span>
</pre></div>
</div>
<p>For more information about configurations and limitations, see
<a class="reference internal" href="../security/password-passthrough.html"><span class="doc std std-doc">Password credential pass-through</span></a>.</p>
</section>
<section id="tls-ssl-encryption">
<span id="kafka-ssl-encryption"></span><h3 id="tls-ssl-encryption">TLS/SSL encryption<a class="headerlink" href="#tls-ssl-encryption" title="Link to this heading">#</a></h3>
<p>By default, the connector communicates with the Kafka server using the
<code class="docutils literal notranslate"><span class="pre">PLAINTEXT</span></code> protocol. This means sent data is not encrypted.</p>
<p>To encrypt the communication between the connector and the server, change the
<code class="docutils literal notranslate"><span class="pre">kafka-security-protocol</span></code> configuration property to:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">SSL</span></code> - to connect to the server without any authentication or
when using <a class="reference internal" href="#kafka-ssl-authentication"><span class="std std-ref">SSL authentication (2-way SSL)</span></a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">SASL_SSL</span></code> - to connect to the server using <a class="reference internal" href="#kafka-sasl-authentication"><span class="std std-ref">SASL
authentication</span></a>.</p></li>
</ul>
<p>In addition, you can set following optional configuration properties:</p>
<table id="id10">
<caption><span class="caption-text">Optional SSL encryption configuration properties</span><a class="headerlink" href="#id10" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 40%"/>
<col style="width: 60%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property name</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.ssl.truststore.location</span></code></p></td>
<td><p>Location of the truststore file.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.ssl.truststore.password</span></code></p></td>
<td><p>Password to the truststore file.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.endpoint-identification-algorithm</span></code></p></td>
<td><p>The endpoint identification algorithm used by SEP to validate the
server host name. The default value is <code class="docutils literal notranslate"><span class="pre">HTTPS</span></code>. SEP verifies
that the broker host name matches the host name in the broker’s
certificate. To disable server host name verification use <code class="docutils literal notranslate"><span class="pre">disabled</span></code>.</p></td>
</tr>
</tbody>
</table>
<p>You can see a full example configuration with <code class="docutils literal notranslate"><span class="pre">SSL</span></code> encryption in the
following snippet:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>connector.name=kafka
...
kafka.security-protocol=SSL
kafka.ssl.truststore.location=/etc/secrets/kafka.broker.truststore.jks
kafka.ssl.truststore.password=truststore_password
</pre></div>
</div>
</section>
<section id="tls-ssl-authentication">
<span id="kafka-ssl-authentication"></span><h3 id="tls-ssl-authentication">TLS/SSL authentication<a class="headerlink" href="#tls-ssl-authentication" title="Link to this heading">#</a></h3>
<p>The connector supports TLS/SSL authentication to the Kafka server/broker, also
called 2-way authentication.</p>
<p>To use TLS/SSL authentication, add the following configuration properties to
your catalog configuration file.</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>kafka.security-protocol=SSL
</pre></div>
</div>
<p>You must set the following required configuration properties:</p>
<table id="id11">
<caption><span class="caption-text">Required settings</span><a class="headerlink" href="#id11" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 40%"/>
<col style="width: 60%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property name</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.ssl.keystore.location</span></code></p></td>
<td><p>Location of the keystore file.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.ssl.keystore.password</span></code></p></td>
<td><p>Password to the keystore file.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.ssl.key.password</span></code></p></td>
<td><p>Password of the private key stored in the keystore file.</p></td>
</tr>
</tbody>
</table>
<p>The following snippet provides a full example configuration using the SSL
authentication:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>connector.name=kafka
...
kafka.security-protocol=SSL
kafka.ssl.keystore.location=/etc/secrets/kafka.broker.keystore.jks
kafka.ssl.keystore.password=keystore_password
kafka.ssl.key.password=private_key_password
</pre></div>
</div>
</section>
<section id="sasl-authentication">
<span id="kafka-sasl-authentication"></span><h3 id="sasl-authentication">SASL authentication<a class="headerlink" href="#sasl-authentication" title="Link to this heading">#</a></h3>
<p>The connector supports SASL authentication to the Kafka server using one of the
supported authentication types in the following table:</p>
<table id="id12">
<caption><span class="caption-text">Authentication types</span><a class="headerlink" href="#id12" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 30%"/>
<col style="width: 30%"/>
<col style="width: 40%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Authentication type name</p></th>
<th class="head"><p>Corresponding Kafka SASL mechanism</p></th>
<th class="head"><p>Documentation</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">PASSWORD</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">PLAIN</span></code></p></td>
<td><p><a class="reference internal" href="#kafka-password-authentication"><span class="std std-ref">Password authentication</span></a></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">KERBEROS</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">GSSAPI</span></code></p></td>
<td><p><a class="reference internal" href="#kafka-kerberos-authentication"><span class="std std-ref">Kerberos authentication</span></a></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">OAUTH2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">OAUTHBEARER</span></code></p></td>
<td><p><a class="reference internal" href="#kafka-oauth2-authentication"><span class="std std-ref">OAuth 2.0 authentication</span></a></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">DELEGATED-OAUTH2</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">OAUTHBEARER</span></code></p></td>
<td><p><a class="reference internal" href="#kafka-oauth2-passthrough"><span class="std std-ref">OAuth 2.0 token pass-through</span></a></p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">SCRAM_SHA_256</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">SCRAM-SHA-256</span></code></p></td>
<td><p><a class="reference internal" href="#kafka-scram-authentication"><span class="std std-ref">SCRAM authentication</span></a></p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">SCRAM_SHA_512</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">SCRAM-SHA-512</span></code></p></td>
<td><p><a class="reference internal" href="#kafka-scram-authentication"><span class="std std-ref">SCRAM authentication</span></a></p></td>
</tr>
</tbody>
</table>
<p>SASL authentication can be enabled for both <code class="docutils literal notranslate"><span class="pre">PLAINTEXT</span></code> and <code class="docutils literal notranslate"><span class="pre">SSL</span></code> protocols
by setting <code class="docutils literal notranslate"><span class="pre">kafka.security-protocol</span></code> to <code class="docutils literal notranslate"><span class="pre">SASL_PLAINTEXT</span></code> and <code class="docutils literal notranslate"><span class="pre">SASL_SSL</span></code>
respectively.</p>
<p>Example configuration of the Kerberos authentication over TLS/SSL:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>kafka.security-protocol=SASL_SSL
kafka.authentication.type=KERBEROS
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If the SASL authentication type is enabled, then the SSL client
authentication (2-way authentication) is disabled, but the client still
verifies the server certificate (1-way authentication).</p>
</div>
<section id="password-authentication">
<span id="kafka-password-authentication"></span><h4 id="password-authentication">Password authentication<a class="headerlink" href="#password-authentication" title="Link to this heading">#</a></h4>
<p>The password authentication is simple username and password authentication using
the SASL <code class="docutils literal notranslate"><span class="pre">PLAIN</span></code> authentication type to authenticate.</p>
<p>Password authentication should only be used with <a class="reference internal" href="#kafka-ssl-encryption"><span class="std std-ref">SSL
encryption</span></a> enabled to ensure that the password is not
sent without encryption.</p>
<p>Add the following configuration to your catalog properties file to use the
password authentication:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>kafka.security-protocol=SASL_SSL
kafka.authentication.type=PASSWORD
</pre></div>
</div>
<p>Set the following required configuration properties:</p>
<table id="id13">
<caption><span class="caption-text">Required settings</span><a class="headerlink" href="#id13" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 40%"/>
<col style="width: 60%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property name</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.authentication.username</span></code></p></td>
<td><p>User name for Kafka access.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.authentication.password</span></code></p></td>
<td><p>Password for the user.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="kerberos-authentication">
<span id="kafka-kerberos-authentication"></span><h4 id="kerberos-authentication">Kerberos authentication<a class="headerlink" href="#kerberos-authentication" title="Link to this heading">#</a></h4>
<p>The <a class="reference internal" href="../security/kerberos.html"><span class="doc std std-doc">Kerberos authentication</span></a> uses the Kerberos service and the SASL <code class="docutils literal notranslate"><span class="pre">GSSAPI</span></code>
authentication type to authenticate. Add the following configuration to your
catalog properties file to use the Kerberos authentication type:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>kafka.security-protocol=SASL_SSL
kafka.authentication.type=KERBEROS
</pre></div>
</div>
<p>Set the following required configuration properties:</p>
<table id="id14">
<caption><span class="caption-text">Required settings</span><a class="headerlink" href="#id14" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 40%"/>
<col style="width: 60%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property Name</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.authentication.client.principal</span></code></p></td>
<td><p>Kerberos client principal name.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.authentication.client.keytab</span></code></p></td>
<td><p>Kerberos client keytab location.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.authentication.config</span></code></p></td>
<td><p>Kerberos service file location, typically <code class="docutils literal notranslate"><span class="pre">/etc/krb5.conf</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.authentication.service-name</span></code></p></td>
<td><p>Kerberos principal name of the Kafka service.</p></td>
</tr>
</tbody>
</table>
<p>Example configuration using the Kerberos authentication:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>connector.name=kafka
...
kafka.security-protocol=SASL_SSL
kafka.authentication.type=KERBEROS
kafka.authentication.client.principal=kafka/broker1.your.org@YOUR.ORG
kafka.authentication.client.keytab=/etc/secrets/kafka_client.keytab
kafka.authentication.config=/etc/krb5.conf
kafka.authentication.service-name=kafka
</pre></div>
</div>
</section>
<section id="oauth-2-0-authentication">
<span id="kafka-oauth2-authentication"></span><h4 id="oauth-2-0-authentication">OAuth 2.0 authentication<a class="headerlink" href="#oauth-2-0-authentication" title="Link to this heading">#</a></h4>
<p>The OAuth 2.0 authentication uses an access token obtained from an OAuth
2.0-compliant authorization server and SASL <code class="docutils literal notranslate"><span class="pre">OAUTHBEARER</span></code> authentication type
to authenticate the Kafka connector. Only the client credentials flow is
currently supported.</p>
<p>Add the following configuration to your catalog properties file to use the
OAuth 2.0 authentication:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>kafka.security-protocol=SASL_SSL
kafka.authentication.type=OAUTH2
</pre></div>
</div>
<p>Set the following required configuration properties:</p>
<table id="id15">
<caption><span class="caption-text">Required settings</span><a class="headerlink" href="#id15" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 40%"/>
<col style="width: 60%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property name</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.authentication.oauth2.token-url</span></code></p></td>
<td><p>The token URL of an OAuth 2.0-compliant authorization server.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.authentication.oauth2.client-id</span></code></p></td>
<td><p>ID of the Kafka connector OAuth2 client.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.authentication.oauth2.client-secret</span></code></p></td>
<td><p>Secret for the client.</p></td>
</tr>
</tbody>
</table>
<p>If the authorization server is using SSL with a self-signed certificate, set the
additional properties to use a custom truststore while validating the
certificate:</p>
<table id="id16">
<caption><span class="caption-text">Additional settings</span><a class="headerlink" href="#id16" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 40%"/>
<col style="width: 60%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property name</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.authentication.oauth2.ssl.truststore.path</span></code></p></td>
<td><p>Location of the SSL truststore file used to verify the OAUTH2
authorization server certificate.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.authentication.oauth2.ssl.truststore.password</span></code></p></td>
<td><p>Password to the truststore file.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.authentication.oauth2.ssl.truststore.type</span></code></p></td>
<td><p>Type of the truststore file, supported values are: <code class="docutils literal notranslate"><span class="pre">JKS</span></code> and <code class="docutils literal notranslate"><span class="pre">PKCS12</span></code>.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="oauth-2-0-token-pass-through">
<span id="kafka-oauth2-passthrough"></span><h4 id="oauth-2-0-token-pass-through">OAuth 2.0 token pass-through<a class="headerlink" href="#oauth-2-0-token-pass-through" title="Link to this heading">#</a></h4>
<p>The Kafka connector supports <a class="reference internal" href="../security/oauth2-passthrough.html"><span class="doc std std-doc">OAuth 2.0 token pass-through</span></a>.</p>
<p>Configure this option the same as <a class="reference internal" href="#kafka-oauth2-authentication"><span class="std std-ref">OAuth 2.0 authentication</span></a>, except
for the additional settings described in this section.</p>
<p>Set the authentication type in the coordinator’s <a class="reference internal" href="../installation/deployment.html#config-properties"><span class="std std-ref">config properties
file</span></a>:</p>
<div class="highlight-properties notranslate"><div class="highlight"><pre><span></span><span class="na">http-server.authentication.type</span><span class="o">=</span><span class="s">DELEGATED-OAUTH2</span>
</pre></div>
</div>
<p>Additionally, enable <code class="docutils literal notranslate"><span class="pre">OAUTH2_PASSTHROUGH</span></code> in the catalog properties file using
the Kafka connector:</p>
<div class="highlight-properties notranslate"><div class="highlight"><pre><span></span><span class="na">kafka.authentication.type</span><span class="o">=</span><span class="s">OAUTH2_PASSTHROUGH</span>
</pre></div>
</div>
<p>In addition, the SASL mechanism must be enabled with
<code class="docutils literal notranslate"><span class="pre">kafka.security-protocol=SASL_SSL</span></code> or
<code class="docutils literal notranslate"><span class="pre">kafka.security-protocol=SASL_PLAINTEXT</span></code> as described in the previous section.</p>
</section>
<section id="scram-authentication">
<span id="kafka-scram-authentication"></span><h4 id="scram-authentication">SCRAM authentication<a class="headerlink" href="#scram-authentication" title="Link to this heading">#</a></h4>
<p>Salted Challenge Response Authentication Mechanism (SCRAM), or SASL/SCRAM, is a
family of SASL mechanisms that addresses the security concerns with traditional
mechanisms that perform username/password authentication like PLAIN. Kafka
supports SCRAM-SHA-256 and SCRAM-SHA-512. All examples below use SCRAM-SHA-256,
but you can substitute the configuration for SCRAM-SHA-512 as needed.</p>
<p>Add the following configuration to your catalog properties file to use the SCRAM
authentication:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>kafka.security-protocol=SASL_SSL
kafka.authentication.type=SCRAM_SHA_256
</pre></div>
</div>
<p>Set the following required configuration properties:</p>
<table id="id17">
<caption><span class="caption-text">Required settings</span><a class="headerlink" href="#id17" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 40%"/>
<col style="width: 60%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property name</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.authentication.username</span></code></p></td>
<td><p>The user name.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.authentication.password</span></code></p></td>
<td><p>The password.</p></td>
</tr>
</tbody>
</table>
<p>(kafka-schema-registry-security)</p>
</section>
</section>
</section>
<section id="security-for-schema-registry-access">
<h2 id="security-for-schema-registry-access">Security for schema registry access<a class="headerlink" href="#security-for-schema-registry-access" title="Link to this heading">#</a></h2>
<p>The connector supports <a class="reference internal" href="#kafka-table-schema-registry"><span class="std std-ref">table schema and schema registry
usage</span></a>, and includes a number of security-related
features, detailed in the following sections.</p>
<section id="id7">
<h3 id="id7">TLS/SSL authentication<a class="headerlink" href="#id7" title="Link to this heading">#</a></h3>
<p>Typically, your schema registry is secured with TLS/SSL, and therefore accessed
securely with the HTTPS protocol. The connector supports the <em>2-way
authentication</em> used by the protocol, if you enable the HTTPS protocol in your
catalog properties file:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>kafka.confluent-schema-registry.security-protocol=HTTPS
</pre></div>
</div>
<p>If your TLS certificates on the schema registry and on SEP are signed by a
certificate authority, it is recognized as such, and no further configuration is
necessary.</p>
<p>If you use a custom certificate, you must configure the truststore and keystore
to use on SEP after adding the relevant certificates to these files. After
creating these files, you must place them on your cluster nodes and configure
the relevant properties:</p>
<table id="id18">
<caption><span class="caption-text">Truststore and keystore properties</span><a class="headerlink" href="#id18" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 40%"/>
<col style="width: 60%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property name</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.confluent-schema-registry.ssl.truststore.location</span></code></p></td>
<td><p>Location of the truststore file. Absolute path or relative path to
<code class="docutils literal notranslate"><span class="pre">etc</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.confluent-schema-registry.ssl.truststore.password</span></code></p></td>
<td><p>Password to the truststore file.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.confluent-schema-registry.ssl.truststore.type</span></code></p></td>
<td><p>The file format of truststore key, <code class="docutils literal notranslate"><span class="pre">JKS</span></code> or <code class="docutils literal notranslate"><span class="pre">PKCS12</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.confluent-schema-registry.ssl.keystore.location</span></code></p></td>
<td><p>Location of the keystore file. Absolute path or relative path to
<code class="docutils literal notranslate"><span class="pre">etc</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.confluent-schema-registry.ssl.keystore.password</span></code></p></td>
<td><p>Password to the keystore file.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.confluent-schema-registry.ssl.keystore.type</span></code></p></td>
<td><p>The file format of keystore key. <code class="docutils literal notranslate"><span class="pre">JKS</span></code> or <code class="docutils literal notranslate"><span class="pre">PKCS12</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.confluent-schema-registry.ssl.key.password</span></code></p></td>
<td><p>Password of the private key stored in the keystore file.</p></td>
</tr>
</tbody>
</table>
<p>You can use the <a class="reference internal" href="../security/secrets.html"><span class="doc std std-doc">secrets support</span></a> to avoid plain text
password values in the catalog file.</p>
</section>
<section id="basic-authentication">
<h3 id="basic-authentication">Basic authentication<a class="headerlink" href="#basic-authentication" title="Link to this heading">#</a></h3>
<p>The schema registry can be configured to require users to authenticate using a
username and password via the basic HTTP authentication type. The connector
supports the <em>Basic authentication</em> used by the schema registry, if you enable
the <code class="docutils literal notranslate"><span class="pre">PASSWORD</span></code> authentication type and relevant properties in your catalog
properties file:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>kafka.confluent-schema-registry.authentication.type=PASSWORD
kafka.confluent-schema-registry.authentication.username=examplename
kafka.confluent-schema-registry.authentication.password=examplepassword
</pre></div>
</div>
</section>
<section id="id8">
<h3 id="id8">Kerberos authentication<a class="headerlink" href="#id8" title="Link to this heading">#</a></h3>
<p>The schema registry can be configured to use the Kerberos service and the SASL
<code class="docutils literal notranslate"><span class="pre">GSSAPI</span></code> authentication type.  Add the following configuration to your catalog
properties file to use the Kerberos authentication type for the schema registry:</p>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>kafka.confluent-schema-registry.authentication.type=KERBEROS
kafka.confluent-schema-registry.authentication.client.principal=kafka/host.your.org@YOUR.ORG
kafka.confluent-schema-registry.authentication.client.keytab=/etc/secrets/kafka_client.keytab
kafka.confluent-schema-registry.authentication.config=/etc/krb5.conf
kafka.confluent-schema-registry.authentication.service-name=kafka
</pre></div>
</div>
</section>
</section>
<section id="cloudera-schema-registry">
<h2 id="cloudera-schema-registry">Cloudera schema registry<a class="headerlink" href="#cloudera-schema-registry" title="Link to this heading">#</a></h2>
<p>To use the Cloudera (CDP) schema registry, the following properties must be set:</p>
<div class="highlight-properties notranslate"><div class="highlight"><pre><span></span><span class="na">kafka.table-description-supplier</span><span class="o">=</span><span class="s">cloudera</span>
<span class="na">kafka.cloudera-schema-registry-url</span><span class="o">=</span><span class="s">http://schema-registry.example.com:8081/api/v1</span>
</pre></div>
</div>
<p>To configure Kerberos authentication with a CDP schema registry, you must
include the following additional properties:</p>
<div class="highlight-properties notranslate"><div class="highlight"><pre><span></span><span class="na">kafka.cloudera-schema-registry.authentication.type</span><span class="o">=</span><span class="s">KERBEROS</span>
<span class="na">kafka.cloudera-schema-registry.authentication.client.principal</span><span class="o">=</span><span class="s">kafka/broker1.example.com@EXAMPLE.COM</span>
<span class="na">kafka.cloudera-schema-registry.authentication.client.keytab</span><span class="o">=</span><span class="s">/etc/kafka/kerberos/broker1.keytab</span>
<span class="na">kafka.cloudera-schema-registry.authentication.config</span><span class="o">=</span><span class="s">/etc/krb5.conf</span>
<span class="na">kafka.cloudera-schema-registry.authentication.service-name</span><span class="o">=</span><span class="s">kafka</span>
</pre></div>
</div>
<p>The full list of configuration properties is as follows:</p>
<table id="id19">
<caption><span class="caption-text">CDP schema registry properties</span><a class="headerlink" href="#id19" title="Link to this table">#</a></caption>
<colgroup>
<col style="width: 40%"/>
<col style="width: 60%"/>
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Property name</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.cloudera-schema-registry-url</span></code></p></td>
<td><p>URL for Cloudera Schema Registry, for example:
http://example.com:8080/api/v1.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.cloudera-schema-registry.authentication.type</span></code></p></td>
<td><p>Credential source for schema registry. Valid values are <code class="docutils literal notranslate"><span class="pre">KERBEROS</span></code> and
<code class="docutils literal notranslate"><span class="pre">NONE</span></code>.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.cloudera-subjects-cache-refresh-interval</span></code></p></td>
<td><p>The interval at which the topic to subjects cache will be refreshed.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.empty-field-strategy</span></code></p></td>
<td><p>How to handle struct types with no fields. Valid values are:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">IGNORE</span></code> - ignore structs with no fields. This strategy propagates to
parents.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">FAIL</span></code> - fail the query if a struct with no fields is defined.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DUMMY</span></code> - add a boolean field named <code class="docutils literal notranslate"><span class="pre">dummy</span></code>, which is <code class="docutils literal notranslate"><span class="pre">null</span></code>. This may be
desired if the struct represents a marker field.</p></li>
</ul>
</td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.cloudera-schema-registry.authentication.client.principal</span></code></p></td>
<td><p>Kerberos client principal name.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.cloudera-schema-registry.authentication.client.keytab</span></code></p></td>
<td><p>Kerberos client keytab location.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.cloudera-schema-registry.authentication.config</span></code></p></td>
<td><p>Kerberos service file location, typically <code class="docutils literal notranslate"><span class="pre">/etc/krb5.conf</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">kafka.cloudera-schema-registry.authentication.service-name</span></code></p></td>
<td><p>Kerberos principal name of the Kafka service.</p></td>
</tr>
</tbody>
</table>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>The connector only supports CDP Schema Registry Kafka messages serialized using
protocol ID 3 (<code class="docutils literal notranslate"><span class="pre">VERSION_ID_AS_INT_PROTOCOL</span></code>). Attempting to use other protocols
results in an error.</p>
</div>
</section>
</section>


          </article>
        </div>
      </div>
    </main>
  </div>
<div class="md-grid md-main__inner" style="height: auto;">
  <div class="md-content">
    <div class="feedback-container md-content__inner md-typeset">
      <div class="feedback-thumbs">
        <p>Is the information on this page helpful?</p>
        <p class="feedback-option" title="yes">Yes</p>
        <p class="feedback-option" title="no">No</p>
      </div>
      <div class="feedback-message">
        <textarea class="feedback-body" placeholder="Additional feedback"></textarea>
        <button type="button" onclick="sendMessage()" class="feedback-button">Email</button>
        <a onclick="skip()" class="feedback-skip">Cancel</a>
      </div>
    </div>
  </div>
</div>

<script async src="https://www.googletagmanager.com/gtag/js?id="></script>
<script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', '');
</script>
<script>
function feedback() {
  var feedbackValue = "";
  var feedbackThumbs = document.querySelector(".feedback-thumbs");
  var feedbackMessage = document.querySelector(".feedback-message");
  var initialFeedbackMessageContents = feedbackMessage.innerHTML;
  var feedbackAnswer = localStorage.getItem('feedback-answer-' + window.location.pathname);
  var options = Array.from(document.querySelectorAll(".feedback-option"));

  if (feedbackAnswer) {
    Object.keys(options).map(i => options[i].getAttribute('title') == JSON.parse(feedbackAnswer)
      ? options[i].classList.add('active')
      : null
    );
  }

  var clickFunction = function(event){
    var page = window.location.pathname;
    var value = event.currentTarget.getAttribute('title');
    var eventValue = value == 'yes' ? 1 : 0;

    if(!event.currentTarget.classList.contains('active')) {
      localStorage.setItem('feedback-answer-' + page, JSON.stringify(value == 'yes' ? 'yes' : 'no'));
      feedbackValue = value;

      gtag('event', 'feedback', {
        'event_category': 'Docs Feedback',
        'event_label': page,
        'event_value': eventValue,
      });

      Object.keys(options).map(i => options[i].classList.remove('active'));
      event.currentTarget.classList.add('active');

      feedbackThumbs.style.display = "none";
      feedbackMessage.style.display = "flex";
    };
  };

  skip = function() {
    feedbackMessage.style.display = "none";
    feedbackThumbs.style.display = "flex";
    feedbackMessage.innerHTML = initialFeedbackMessageContents;
  }

  sendMessage = function(){
    var feedbackBody = document.querySelector(".feedback-body").value;

    if (feedbackBody) {
      var message = "Page url: " + window.location.pathname + "\n\n"
        + "Feedback positive?: " + feedbackValue + "\n\n" +  "Feedback Message: " + feedbackBody;
      var link = "mailto:docs-feedback@starburst.io?subject=" + encodeURIComponent("Feedback")+"&body="
        + encodeURIComponent(message);

      window.location.href = link;
      feedbackMessage.innerHTML = "<p>Thank you!</p>";

      setTimeout(function(){
          skip();
      }, 5000);
    } else {
      if(!document.querySelector("#feedback-skip")) {
        var alertMessage = document.createElement("p");
        alertMessage.id = "feedback-skip";
        alertMessage.style.color = "red";
        alertMessage.style.position = "absolute";
        alertMessage.style.bottom = "-0.5rem";
        alertMessage.innerHTML = "Please provide a message.";
        feedbackMessage.appendChild(alertMessage);

        setTimeout(function(){
          alertMessage.remove();
        }, 3000);
      }
    }
  }

  Object.keys(options).map(i => options[i].addEventListener('click', clickFunction , false));
}

feedback();
</script>

  <footer class="md-footer">
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
          
            <a href="starburst-greenplum.html" title="Starburst Greenplum connector"
               class="md-flex md-footer-nav__link md-footer-nav__link--prev"
               rel="prev">
              <div class="md-flex__cell md-flex__cell--shrink">
                <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
              </div>
              <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
                <span class="md-flex__ellipsis">
                  <span
                      class="md-footer-nav__direction"> "Previous" </span> Starburst Greenplum connector </span>
              </div>
            </a>
          
          
            <a href="kafka-tutorial.html" title="Kafka connector tutorial"
               class="md-flex md-footer-nav__link md-footer-nav__link--next"
               rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title"><span
                class="md-flex__ellipsis"> <span
                class="md-footer-nav__direction"> "Next" </span> Kafka connector tutorial </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink"><i
                class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          
        </a>
        
      </nav>
    </div>
    <div class="md-footer-meta md-typeset">
      <div class="md-footer-meta__inner md-grid">
        <div class="md-footer-copyright">
        </div>
      </div>
    </div>
  </footer>
  <script src="../_static/javascripts/application.js"></script>
  <script>app.initialize({version: "1.0.4", url: {base: ".."}})</script>
<!-- custom footer should go here in time -->
<div class="page-footer">
  <div class="container md-grid">
    <div class="row">
      <div class="col-md-3">
        <p style="font-weight:900">Resources</p>
        <ul>
          <li class="footer-item"><a href="https://docs.starburst.io/latest/index.html">Starburst Enterprise reference documentation</a></li>
          <li class="footer-item"><a href="/videos/index.html">Video library</a></li>
          <li class="footer-item"><a href="/glossary.html">Glossary</a></li>
          <li class="footer-item"><a href="https://www.starburst.io/info/oreilly-trino-guide/" target="_blank">Free O'Reilly book - Trino: The Definitive Guide</a></li>
          <li class="footer-item"><a href="https://trino.io/broadcast/" target="_blank">Trino Community Broadcast</a></li>
          <li class="footer-item"><a href="https://blog.starburstdata.com/" target="_blank">Starburst blog</a></li>
        </ul>
      </div>
      <div class="col-md-3">
        <p style="font-weight:900">Contact and more</p>
        <ul>
          <li class="footer-item"><a href="https://www.starburst.io" target="_blank">Starburst</a></li>
          <li class="footer-item"><a href="https://www.starburst.io/info/starburst-intro-and-demo/" target="_blank">Join our weekly demos</a></li>
          <li class="footer-item"><a href="https://www.starburst.io/#!" target="_blank">Start a trial</a></li>
          <li class="footer-item"><a href="/support.html" target="_blank">Get support</a></li>
          <li class="footer-item"><a href="https://www.starburst.io/contact/" target="_blank">Contact us</a></li>
        </ul>
      </div>
      <div class="col-md-3" style="text-align:right;">

        <a href="https://www.starburst.io/" target="_blank">
          <img src="../_static/img/Starburst_Logo_White+Blue.svg" height="34"
            alt="Starburst Enterprise 468-e.6 LTS logo">
        </a>
        <li class="footer-item" style="padding-right:10px;">
          <a href="/disclaimers.html#copyright">Copyright © 2017-2025<br> Starburst Data</a>
        </li>
        <li class="footer-item" style="padding-right:10px;">
          <a href="/disclaimers.html#trademarks">Trademark information</a>
        </li>
      </div>
    </div>
  </div>
</div>
<script src="https://docs.starburst.io/468-e/_static/algolia.js"></script>
<script src="https://docs.starburst.io/468-e/_static/searchbox.js" data-versions="{'Latest LTS (468-e)': '/468-e/', '462-e LTS': '/462-e/', '453-e LTS': '/453-e/', '443-e LTS': '/443-e/', 'Latest STS (472-e)': '/472-e/', '471-e STS': '/471-e/'}"></script>
<script src="https://docs.starburst.io/468-e/_static/searchresults.js" data-versions="{'Latest LTS (468-e)': '/468-e/', '462-e LTS': '/462-e/', '453-e LTS': '/453-e/', '443-e LTS': '/443-e/', 'Latest STS (472-e)': '/472-e/', '471-e STS': '/471-e/'}"></script>
  </body>
</html>